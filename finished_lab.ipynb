{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXyd9cOl6z6h"
      },
      "source": [
        "# Tuning Neural Networks with Regularization - Lab \n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this lab, you'll use a train-test partition as well as a validation set to get better insights about how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. \n",
        "\n",
        "## Objectives\n",
        "\n",
        "You will be able to:\n",
        "\n",
        "- Apply early stopping criteria with a neural network \n",
        "- Apply L1, L2, and dropout regularization on a neural network  \n",
        "- Examine the effects of training with more data on a neural network  \n",
        "\n",
        "\n",
        "## Load the Data\n",
        "\n",
        "Run the following cell to import some of the libraries and classes you'll need in this lab. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eapA8o9K6z6k"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjOCd8Dk6z6l"
      },
      "source": [
        "The data is stored in the file `'Bank_complaints.csv'`. Load and preview the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qoB26uQG6z6m"
      },
      "outputs": [],
      "source": [
        "# Load and preview the dataset\n",
        "df = pd.read_csv('Bank_complaints.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lMORazdX70d8",
        "outputId": "e25626cb-1c97-4bb5-fd9e-f57692c9d7d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7590fd4c-08b8-4324-b25e-e585204b68e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product</th>\n",
              "      <th>Consumer complaint narrative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Student loan</td>\n",
              "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Student loan</td>\n",
              "      <td>I am being contacted by a debt collector for p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Student loan</td>\n",
              "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Student loan</td>\n",
              "      <td>Navient has sytematically and illegally failed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Student loan</td>\n",
              "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7590fd4c-08b8-4324-b25e-e585204b68e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7590fd4c-08b8-4324-b25e-e585204b68e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7590fd4c-08b8-4324-b25e-e585204b68e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        Product                       Consumer complaint narrative\n",
              "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
              "1  Student loan  I am being contacted by a debt collector for p...\n",
              "2  Student loan  I cosigned XXXX student loans at SallieMae for...\n",
              "3  Student loan  Navient has sytematically and illegally failed...\n",
              "4  Student loan  My wife became eligible for XXXX Loan Forgiven..."
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al4sS3o_8MPh",
        "outputId": "e6af3a51-80a2-4eb7-bd47-753c44ff6291"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 60000 entries, 0 to 59999\n",
            "Data columns (total 2 columns):\n",
            " #   Column                        Non-Null Count  Dtype \n",
            "---  ------                        --------------  ----- \n",
            " 0   Product                       60000 non-null  object\n",
            " 1   Consumer complaint narrative  60000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 937.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlPwHclf6z6m"
      },
      "source": [
        "## Preprocessing Overview\n",
        "\n",
        "Before you begin to practice some of your new tools such as regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
        "\n",
        "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
        "* Train - test split\n",
        "* One-hot encoding your complaint text\n",
        "* Transforming your category labels \n",
        "\n",
        "## Preprocessing: Generate a Random Sample\n",
        "\n",
        "Since you have quite a bit of data and training neural networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your model's performance change as you increase (or decrease) the size of your dataset?  \n",
        "\n",
        "- Generate a random sample of 10,000 observations using seed 123 for consistency of results. \n",
        "- Split this sample into `X` and `y` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jGVfiO-16z6n"
      },
      "outputs": [],
      "source": [
        "# Downsample the data\n",
        "df_sample = df.sample(10000,random_state=123)\n",
        "\n",
        "# Split the data into X and y\n",
        "y = df_sample['Product']\n",
        "X = df_sample['Consumer complaint narrative']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybL7He2a6z6n"
      },
      "source": [
        "## Train-test split\n",
        "\n",
        "- Split the data into training and test sets \n",
        "- Assign 1500 obervations to the test set and use 42 as the seed "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lgZ1k-0E6z6o"
      },
      "outputs": [],
      "source": [
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.15,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNfekPPR6z6o"
      },
      "source": [
        "## Validation set \n",
        "\n",
        "As mentioned in the previous lesson, it is good practice to set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test set can then be used to determine an unbiased perforance of the model. \n",
        "\n",
        "Run the cell below to further divide the training data into training and validation sets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mzFEYMbt6z6p"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and validation sets\n",
        "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDLpbB0h6z6p"
      },
      "source": [
        "## Preprocessing: One-hot Encoding the Complaints\n",
        "\n",
        "As before, you need to do some preprocessing before building a neural network model. \n",
        "\n",
        "- Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors \n",
        "- Transform the training, validate, and test sets "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OoHaqcOt6z6q"
      },
      "outputs": [],
      "source": [
        "# Use one-hot encoding to reformat the complaints into a matrix of vectors \n",
        "# Only keep the 2000 most common words \n",
        "\n",
        "tokenizer = Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(X_train_final)\n",
        "\n",
        "X_train_tokens = tokenizer.texts_to_matrix(X_train_final)\n",
        "X_val_tokens = tokenizer.texts_to_matrix(X_val)\n",
        "X_test_tokens = tokenizer.texts_to_matrix(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBuN2jft6z6q"
      },
      "source": [
        "## Preprocessing: Encoding the Products\n",
        "\n",
        "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
        "  \n",
        "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero. \n",
        "\n",
        "Transform the training, validate, and test sets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "f9rShVkG6z6q"
      },
      "outputs": [],
      "source": [
        "# Transform the product labels to numerical values\n",
        "lb = LabelBinarizer()\n",
        "lb.fit(y_train_final)\n",
        "\n",
        "y_train_lb = lb.transform(y_train_final)\n",
        "y_val_lb = lb.transform(y_val)\n",
        "y_test_lb = lb.transform(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpEqOAR26z6r"
      },
      "source": [
        "## A Baseline Model \n",
        "\n",
        "Rebuild a fully connected (Dense) layer network:  \n",
        "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions (since you are dealing with a multiclass problem, classifying the complaints into 7 classes) \n",
        "- Use a `'softmax'` activation function for the output layer  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3_h3OVB86z6r"
      },
      "outputs": [],
      "source": [
        "# Build a baseline neural network model using Keras\n",
        "random.seed(123)\n",
        "from keras import models\n",
        "from keras import layers\n",
        "baseline_model = models.Sequential()\n",
        "baseline_model.add(layers.Dense(50,activation='relu',input_shape=(2000,)))\n",
        "baseline_model.add(layers.Dense(25,activation='relu'))\n",
        "baseline_model.add(layers.Dense(7,activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJJFRM1t6z6r"
      },
      "source": [
        "### Compile the Model\n",
        "\n",
        "Compile this model with: \n",
        "\n",
        "- a stochastic gradient descent optimizer \n",
        "- `'categorical_crossentropy'` as the loss function \n",
        "- a focus on `'accuracy'` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uIgHZd2X6z6r"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "baseline_model.compile(loss='categorical_crossentropy',\n",
        "                       optimizer='SGD',\n",
        "                       metrics=['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFsgd6jo6z6r"
      },
      "source": [
        "### Train the Model\n",
        "\n",
        "- Train the model for 150 epochs in mini-batches of 256 samples \n",
        "- Include the `validation_data` argument to ensure you keep track of the validation loss  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-8QZGDF6z6r",
        "outputId": "522310bd-e8f6-487d-9947-fe5fa28def7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 1.9457 - acc: 0.1581 - val_loss: 1.9351 - val_acc: 0.1720\n",
            "Epoch 2/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.9272 - acc: 0.1937 - val_loss: 1.9210 - val_acc: 0.2030\n",
            "Epoch 3/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.9123 - acc: 0.2169 - val_loss: 1.9083 - val_acc: 0.2270\n",
            "Epoch 4/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.8975 - acc: 0.2336 - val_loss: 1.8939 - val_acc: 0.2420\n",
            "Epoch 5/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.8809 - acc: 0.2500 - val_loss: 1.8772 - val_acc: 0.2480\n",
            "Epoch 6/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.8618 - acc: 0.2664 - val_loss: 1.8573 - val_acc: 0.2740\n",
            "Epoch 7/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.8385 - acc: 0.2925 - val_loss: 1.8329 - val_acc: 0.3000\n",
            "Epoch 8/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.8107 - acc: 0.3173 - val_loss: 1.8035 - val_acc: 0.3240\n",
            "Epoch 9/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.7780 - acc: 0.3495 - val_loss: 1.7691 - val_acc: 0.3530\n",
            "Epoch 10/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.7395 - acc: 0.3779 - val_loss: 1.7291 - val_acc: 0.3800\n",
            "Epoch 11/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.6967 - acc: 0.4057 - val_loss: 1.6844 - val_acc: 0.4200\n",
            "Epoch 12/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.6501 - acc: 0.4284 - val_loss: 1.6372 - val_acc: 0.4430\n",
            "Epoch 13/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.6014 - acc: 0.4512 - val_loss: 1.5896 - val_acc: 0.4630\n",
            "Epoch 14/150\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 1.5515 - acc: 0.4817 - val_loss: 1.5418 - val_acc: 0.4800\n",
            "Epoch 15/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.5013 - acc: 0.5021 - val_loss: 1.4925 - val_acc: 0.5080\n",
            "Epoch 16/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.4514 - acc: 0.5269 - val_loss: 1.4481 - val_acc: 0.5160\n",
            "Epoch 17/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.4026 - acc: 0.5480 - val_loss: 1.4007 - val_acc: 0.5370\n",
            "Epoch 18/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3551 - acc: 0.5696 - val_loss: 1.3545 - val_acc: 0.5600\n",
            "Epoch 19/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.3087 - acc: 0.5853 - val_loss: 1.3101 - val_acc: 0.5830\n",
            "Epoch 20/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.2637 - acc: 0.6003 - val_loss: 1.2671 - val_acc: 0.5980\n",
            "Epoch 21/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.2208 - acc: 0.6201 - val_loss: 1.2248 - val_acc: 0.6120\n",
            "Epoch 22/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.1792 - acc: 0.6333 - val_loss: 1.1838 - val_acc: 0.6250\n",
            "Epoch 23/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.1398 - acc: 0.6463 - val_loss: 1.1467 - val_acc: 0.6370\n",
            "Epoch 24/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.1022 - acc: 0.6563 - val_loss: 1.1116 - val_acc: 0.6530\n",
            "Epoch 25/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.0669 - acc: 0.6697 - val_loss: 1.0806 - val_acc: 0.6590\n",
            "Epoch 26/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.0340 - acc: 0.6788 - val_loss: 1.0465 - val_acc: 0.6700\n",
            "Epoch 27/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.0030 - acc: 0.6857 - val_loss: 1.0199 - val_acc: 0.6810\n",
            "Epoch 28/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.9745 - acc: 0.6927 - val_loss: 0.9902 - val_acc: 0.6840\n",
            "Epoch 29/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.9473 - acc: 0.7021 - val_loss: 0.9646 - val_acc: 0.6930\n",
            "Epoch 30/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.9229 - acc: 0.7052 - val_loss: 0.9418 - val_acc: 0.6970\n",
            "Epoch 31/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8998 - acc: 0.7127 - val_loss: 0.9197 - val_acc: 0.6930\n",
            "Epoch 32/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.8780 - acc: 0.7173 - val_loss: 0.9045 - val_acc: 0.7090\n",
            "Epoch 33/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8588 - acc: 0.7229 - val_loss: 0.8862 - val_acc: 0.7130\n",
            "Epoch 34/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8403 - acc: 0.7257 - val_loss: 0.8685 - val_acc: 0.7120\n",
            "Epoch 35/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8233 - acc: 0.7308 - val_loss: 0.8572 - val_acc: 0.7110\n",
            "Epoch 36/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8073 - acc: 0.7349 - val_loss: 0.8404 - val_acc: 0.7220\n",
            "Epoch 37/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.7927 - acc: 0.7392 - val_loss: 0.8280 - val_acc: 0.7150\n",
            "Epoch 38/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.7790 - acc: 0.7412 - val_loss: 0.8197 - val_acc: 0.7160\n",
            "Epoch 39/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.7659 - acc: 0.7437 - val_loss: 0.8063 - val_acc: 0.7210\n",
            "Epoch 40/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.7539 - acc: 0.7496 - val_loss: 0.7971 - val_acc: 0.7260\n",
            "Epoch 41/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.7421 - acc: 0.7515 - val_loss: 0.7896 - val_acc: 0.7240\n",
            "Epoch 42/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.7316 - acc: 0.7557 - val_loss: 0.7782 - val_acc: 0.7240\n",
            "Epoch 43/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.7213 - acc: 0.7592 - val_loss: 0.7722 - val_acc: 0.7290\n",
            "Epoch 44/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.7114 - acc: 0.7620 - val_loss: 0.7663 - val_acc: 0.7290\n",
            "Epoch 45/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.7026 - acc: 0.7637 - val_loss: 0.7600 - val_acc: 0.7300\n",
            "Epoch 46/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.6933 - acc: 0.7696 - val_loss: 0.7525 - val_acc: 0.7290\n",
            "Epoch 47/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.6850 - acc: 0.7696 - val_loss: 0.7464 - val_acc: 0.7300\n",
            "Epoch 48/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.6767 - acc: 0.7719 - val_loss: 0.7425 - val_acc: 0.7270\n",
            "Epoch 49/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.6690 - acc: 0.7765 - val_loss: 0.7353 - val_acc: 0.7350\n",
            "Epoch 50/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.6616 - acc: 0.7771 - val_loss: 0.7284 - val_acc: 0.7380\n",
            "Epoch 51/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.6538 - acc: 0.7828 - val_loss: 0.7279 - val_acc: 0.7330\n",
            "Epoch 52/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.6475 - acc: 0.7848 - val_loss: 0.7206 - val_acc: 0.7450\n",
            "Epoch 53/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.6406 - acc: 0.7876 - val_loss: 0.7162 - val_acc: 0.7350\n",
            "Epoch 54/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.6337 - acc: 0.7885 - val_loss: 0.7165 - val_acc: 0.7410\n",
            "Epoch 55/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.6278 - acc: 0.7911 - val_loss: 0.7121 - val_acc: 0.7410\n",
            "Epoch 56/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.6212 - acc: 0.7911 - val_loss: 0.7063 - val_acc: 0.7450\n",
            "Epoch 57/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.6157 - acc: 0.7947 - val_loss: 0.7054 - val_acc: 0.7290\n",
            "Epoch 58/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.6096 - acc: 0.7961 - val_loss: 0.6998 - val_acc: 0.7360\n",
            "Epoch 59/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.6039 - acc: 0.7992 - val_loss: 0.6995 - val_acc: 0.7410\n",
            "Epoch 60/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.5977 - acc: 0.8009 - val_loss: 0.6928 - val_acc: 0.7390\n",
            "Epoch 61/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.5927 - acc: 0.8040 - val_loss: 0.6928 - val_acc: 0.7390\n",
            "Epoch 62/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.5873 - acc: 0.8051 - val_loss: 0.6923 - val_acc: 0.7460\n",
            "Epoch 63/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.5821 - acc: 0.8076 - val_loss: 0.6875 - val_acc: 0.7470\n",
            "Epoch 64/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.5767 - acc: 0.8077 - val_loss: 0.6836 - val_acc: 0.7420\n",
            "Epoch 65/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.5719 - acc: 0.8105 - val_loss: 0.6799 - val_acc: 0.7440\n",
            "Epoch 66/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.5669 - acc: 0.8144 - val_loss: 0.6808 - val_acc: 0.7400\n",
            "Epoch 67/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.5621 - acc: 0.8143 - val_loss: 0.6815 - val_acc: 0.7370\n",
            "Epoch 68/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.5575 - acc: 0.8161 - val_loss: 0.6762 - val_acc: 0.7490\n",
            "Epoch 69/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.5525 - acc: 0.8165 - val_loss: 0.6757 - val_acc: 0.7550\n",
            "Epoch 70/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.5480 - acc: 0.8188 - val_loss: 0.6736 - val_acc: 0.7410\n",
            "Epoch 71/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.5432 - acc: 0.8205 - val_loss: 0.6706 - val_acc: 0.7500\n",
            "Epoch 72/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.5389 - acc: 0.8205 - val_loss: 0.6670 - val_acc: 0.7370\n",
            "Epoch 73/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.5347 - acc: 0.8237 - val_loss: 0.6685 - val_acc: 0.7480\n",
            "Epoch 74/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.5301 - acc: 0.8249 - val_loss: 0.6652 - val_acc: 0.7450\n",
            "Epoch 75/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.5258 - acc: 0.8288 - val_loss: 0.6713 - val_acc: 0.7390\n",
            "Epoch 76/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.5221 - acc: 0.8304 - val_loss: 0.6659 - val_acc: 0.7490\n",
            "Epoch 77/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.5175 - acc: 0.8309 - val_loss: 0.6609 - val_acc: 0.7440\n",
            "Epoch 78/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.5135 - acc: 0.8332 - val_loss: 0.6649 - val_acc: 0.7480\n",
            "Epoch 79/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.5091 - acc: 0.8336 - val_loss: 0.6574 - val_acc: 0.7460\n",
            "Epoch 80/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.5055 - acc: 0.8341 - val_loss: 0.6583 - val_acc: 0.7470\n",
            "Epoch 81/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.5017 - acc: 0.8345 - val_loss: 0.6611 - val_acc: 0.7480\n",
            "Epoch 82/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4976 - acc: 0.8385 - val_loss: 0.6592 - val_acc: 0.7460\n",
            "Epoch 83/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4938 - acc: 0.8377 - val_loss: 0.6550 - val_acc: 0.7440\n",
            "Epoch 84/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.4902 - acc: 0.8413 - val_loss: 0.6553 - val_acc: 0.7450\n",
            "Epoch 85/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.4859 - acc: 0.8441 - val_loss: 0.6583 - val_acc: 0.7430\n",
            "Epoch 86/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4824 - acc: 0.8445 - val_loss: 0.6523 - val_acc: 0.7390\n",
            "Epoch 87/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4788 - acc: 0.8476 - val_loss: 0.6516 - val_acc: 0.7440\n",
            "Epoch 88/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4756 - acc: 0.8463 - val_loss: 0.6510 - val_acc: 0.7430\n",
            "Epoch 89/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4713 - acc: 0.8484 - val_loss: 0.6526 - val_acc: 0.7500\n",
            "Epoch 90/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4683 - acc: 0.8501 - val_loss: 0.6512 - val_acc: 0.7390\n",
            "Epoch 91/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4645 - acc: 0.8509 - val_loss: 0.6493 - val_acc: 0.7450\n",
            "Epoch 92/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4608 - acc: 0.8512 - val_loss: 0.6494 - val_acc: 0.7430\n",
            "Epoch 93/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.4571 - acc: 0.8541 - val_loss: 0.6547 - val_acc: 0.7410\n",
            "Epoch 94/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.4540 - acc: 0.8549 - val_loss: 0.6487 - val_acc: 0.7390\n",
            "Epoch 95/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4503 - acc: 0.8555 - val_loss: 0.6499 - val_acc: 0.7460\n",
            "Epoch 96/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4474 - acc: 0.8589 - val_loss: 0.6461 - val_acc: 0.7460\n",
            "Epoch 97/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4438 - acc: 0.8603 - val_loss: 0.6514 - val_acc: 0.7480\n",
            "Epoch 98/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4410 - acc: 0.8599 - val_loss: 0.6462 - val_acc: 0.7450\n",
            "Epoch 99/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4376 - acc: 0.8636 - val_loss: 0.6451 - val_acc: 0.7480\n",
            "Epoch 100/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4341 - acc: 0.8653 - val_loss: 0.6475 - val_acc: 0.7440\n",
            "Epoch 101/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4308 - acc: 0.8657 - val_loss: 0.6493 - val_acc: 0.7420\n",
            "Epoch 102/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4278 - acc: 0.8669 - val_loss: 0.6488 - val_acc: 0.7490\n",
            "Epoch 103/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4247 - acc: 0.8685 - val_loss: 0.6458 - val_acc: 0.7460\n",
            "Epoch 104/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.4214 - acc: 0.8684 - val_loss: 0.6442 - val_acc: 0.7460\n",
            "Epoch 105/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.4183 - acc: 0.8701 - val_loss: 0.6457 - val_acc: 0.7440\n",
            "Epoch 106/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4154 - acc: 0.8716 - val_loss: 0.6483 - val_acc: 0.7420\n",
            "Epoch 107/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4124 - acc: 0.8728 - val_loss: 0.6489 - val_acc: 0.7460\n",
            "Epoch 108/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4092 - acc: 0.8748 - val_loss: 0.6485 - val_acc: 0.7450\n",
            "Epoch 109/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.4061 - acc: 0.8732 - val_loss: 0.6465 - val_acc: 0.7510\n",
            "Epoch 110/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4033 - acc: 0.8767 - val_loss: 0.6451 - val_acc: 0.7470\n",
            "Epoch 111/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.4005 - acc: 0.8781 - val_loss: 0.6464 - val_acc: 0.7430\n",
            "Epoch 112/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3974 - acc: 0.8768 - val_loss: 0.6443 - val_acc: 0.7510\n",
            "Epoch 113/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.3943 - acc: 0.8793 - val_loss: 0.6467 - val_acc: 0.7450\n",
            "Epoch 114/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3916 - acc: 0.8804 - val_loss: 0.6446 - val_acc: 0.7490\n",
            "Epoch 115/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3889 - acc: 0.8821 - val_loss: 0.6506 - val_acc: 0.7500\n",
            "Epoch 116/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.3864 - acc: 0.8816 - val_loss: 0.6469 - val_acc: 0.7450\n",
            "Epoch 117/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3830 - acc: 0.8827 - val_loss: 0.6467 - val_acc: 0.7480\n",
            "Epoch 118/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3805 - acc: 0.8859 - val_loss: 0.6479 - val_acc: 0.7470\n",
            "Epoch 119/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3778 - acc: 0.8837 - val_loss: 0.6451 - val_acc: 0.7430\n",
            "Epoch 120/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3749 - acc: 0.8869 - val_loss: 0.6445 - val_acc: 0.7460\n",
            "Epoch 121/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3723 - acc: 0.8881 - val_loss: 0.6460 - val_acc: 0.7500\n",
            "Epoch 122/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3698 - acc: 0.8876 - val_loss: 0.6466 - val_acc: 0.7490\n",
            "Epoch 123/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3669 - acc: 0.8893 - val_loss: 0.6472 - val_acc: 0.7450\n",
            "Epoch 124/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3642 - acc: 0.8905 - val_loss: 0.6478 - val_acc: 0.7460\n",
            "Epoch 125/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3618 - acc: 0.8916 - val_loss: 0.6487 - val_acc: 0.7420\n",
            "Epoch 126/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3589 - acc: 0.8931 - val_loss: 0.6492 - val_acc: 0.7490\n",
            "Epoch 127/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3564 - acc: 0.8949 - val_loss: 0.6473 - val_acc: 0.7480\n",
            "Epoch 128/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3537 - acc: 0.8943 - val_loss: 0.6486 - val_acc: 0.7450\n",
            "Epoch 129/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3511 - acc: 0.8951 - val_loss: 0.6501 - val_acc: 0.7510\n",
            "Epoch 130/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3487 - acc: 0.8971 - val_loss: 0.6509 - val_acc: 0.7510\n",
            "Epoch 131/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3467 - acc: 0.8960 - val_loss: 0.6495 - val_acc: 0.7480\n",
            "Epoch 132/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.3440 - acc: 0.9007 - val_loss: 0.6531 - val_acc: 0.7470\n",
            "Epoch 133/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.3416 - acc: 0.8995 - val_loss: 0.6552 - val_acc: 0.7390\n",
            "Epoch 134/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3392 - acc: 0.8999 - val_loss: 0.6516 - val_acc: 0.7460\n",
            "Epoch 135/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.3363 - acc: 0.9009 - val_loss: 0.6533 - val_acc: 0.7500\n",
            "Epoch 136/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3341 - acc: 0.9013 - val_loss: 0.6527 - val_acc: 0.7420\n",
            "Epoch 137/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3317 - acc: 0.9015 - val_loss: 0.6548 - val_acc: 0.7530\n",
            "Epoch 138/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3293 - acc: 0.9048 - val_loss: 0.6542 - val_acc: 0.7440\n",
            "Epoch 139/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.3266 - acc: 0.9051 - val_loss: 0.6526 - val_acc: 0.7500\n",
            "Epoch 140/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.3244 - acc: 0.9061 - val_loss: 0.6525 - val_acc: 0.7510\n",
            "Epoch 141/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3226 - acc: 0.9063 - val_loss: 0.6557 - val_acc: 0.7470\n",
            "Epoch 142/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3197 - acc: 0.9061 - val_loss: 0.6567 - val_acc: 0.7510\n",
            "Epoch 143/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3176 - acc: 0.9076 - val_loss: 0.6572 - val_acc: 0.7470\n",
            "Epoch 144/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3153 - acc: 0.9089 - val_loss: 0.6609 - val_acc: 0.7470\n",
            "Epoch 145/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3128 - acc: 0.9091 - val_loss: 0.6580 - val_acc: 0.7510\n",
            "Epoch 146/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3108 - acc: 0.9104 - val_loss: 0.6577 - val_acc: 0.7520\n",
            "Epoch 147/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3087 - acc: 0.9103 - val_loss: 0.6582 - val_acc: 0.7440\n",
            "Epoch 148/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3064 - acc: 0.9107 - val_loss: 0.6578 - val_acc: 0.7500\n",
            "Epoch 149/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3040 - acc: 0.9129 - val_loss: 0.6557 - val_acc: 0.7520\n",
            "Epoch 150/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3025 - acc: 0.9125 - val_loss: 0.6593 - val_acc: 0.7510\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "baseline_model_val = baseline_model.fit(X_train_tokens,y_train_lb,\n",
        "                                        epochs=150,\n",
        "                                        batch_size=256,\n",
        "                                        validation_data=(X_val_tokens,y_val_lb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bng0HNq86z6s"
      },
      "source": [
        "### Model Performance\n",
        "\n",
        "The attribute `.history` (stored as a dictionary) contains four entries now: one per metric that was being monitored during training and validation. Print the keys of this dictionary for confirmation: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cA352i46z6s",
        "outputId": "e1cc3ce2-2a1c-4e85-8a33-3519ce30d100"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Access the history attribute and store the dictionary\n",
        "baseline_model_val_dict = baseline_model_val.history\n",
        "\n",
        "# Print the keys\n",
        "baseline_model_val_dict.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PrysaVS6z6s"
      },
      "source": [
        "Evaluate this model on the training data: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1NJjoqT6z6s",
        "outputId": "9d336e77-76b6-473d-cb0f-f709a280762d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235/235 [==============================] - 1s 5ms/step - loss: 0.3016 - acc: 0.9151\n",
            "----------\n",
            "Training Loss: 0.302 \n",
            "Training Accuracy: 0.915\n"
          ]
        }
      ],
      "source": [
        "results_train = baseline_model.evaluate(X_train_tokens,y_train_lb)\n",
        "print('----------')\n",
        "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCcgzI6x6z6s"
      },
      "source": [
        "Evaluate this model on the test data: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4pzGFnD6z6s",
        "outputId": "3e3073b8-055d-4c34-c333-436b02a4d36b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 3ms/step - loss: 0.6176 - acc: 0.7813\n",
            "----------\n",
            "Test Loss: 0.618 \n",
            "Test Accuracy: 0.781\n"
          ]
        }
      ],
      "source": [
        "results_test = baseline_model.evaluate(X_test_tokens,y_test_lb)\n",
        "print('----------')\n",
        "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-ew-uqc6z6s"
      },
      "source": [
        "### Plot the Results \n",
        "\n",
        "Plot the loss versus the number of epochs. Be sure to include the training and the validation loss in the same plot. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "tIRwEWft6z6s",
        "outputId": "cb603ddb-6d93-40e3-9aa1-a5ea78a96de3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7facdc564310>]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Loss vs number of epochs with train and validation sets\n",
        "\n",
        "plt.plot(range(1,151),baseline_model_val_dict['loss'],color='orange')\n",
        "plt.plot(range(1,151),baseline_model_val_dict['val_loss'],color='blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LL3nKzT6z6t"
      },
      "source": [
        "Create a second plot comparing training and validation accuracy to the number of epochs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "WlS8rg9Z6z6t",
        "outputId": "68b3961e-6943-491a-8e98-7e9cf863fa47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7facdc24a890>]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Accuracy vs number of epochs with train and validation sets\n",
        "plt.plot(range(1,151),baseline_model_val_dict['acc'],color='orange')\n",
        "plt.plot(range(1,151),baseline_model_val_dict['val_acc'],color='blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjvCxf_j6z6t"
      },
      "source": [
        "Did you notice an interesting pattern here? Although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss don't necessarily do the same. After a certain point, validation accuracy keeps swinging, which means that you're probably **overfitting** the model to the training data when you train for many epochs past a certain dropoff point. Let's tackle this now. You will now specify an early stopping point when training your model. \n",
        "\n",
        "\n",
        "## Early Stopping\n",
        "\n",
        "Overfitting neural networks is something you **_want_** to avoid at all costs. However, it's not possible to know in advance how many *epochs* you need to train your model on, and running the model multiple times with varying number of *epochs* maybe helpful, but is a time-consuming process. \n",
        "\n",
        "We've defined a model with the same architecture as above. This time specify an early stopping point when training the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SiYOtfR46z6t"
      },
      "outputs": [],
      "source": [
        "random.seed(123)\n",
        "model_2 = models.Sequential()\n",
        "model_2.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
        "model_2.add(layers.Dense(25, activation='relu'))\n",
        "model_2.add(layers.Dense(7, activation='softmax'))\n",
        "\n",
        "model_2.compile(optimizer='SGD', \n",
        "                loss='categorical_crossentropy', \n",
        "                metrics=['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEsec8IP6z6t"
      },
      "source": [
        "- Import `EarlyStopping` and `ModelCheckpoint` from `keras.callbacks` \n",
        "- Define a list, `early_stopping`: \n",
        "  - Monitor `'val_loss'` and continue training for 10 epochs before stopping \n",
        "  - Save the best model while monitoring `'val_loss'` \n",
        " \n",
        "> If you need help, consult [documentation](https://keras.io/callbacks/).   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QfeWfxrl6z6t"
      },
      "outputs": [],
      "source": [
        "# Import EarlyStopping and ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define the callbacks\n",
        "early_stopping = [EarlyStopping(monitor='val_loss',patience=10),\n",
        "                  ModelCheckpoint(filepath='best_model.h5', monitor='val_loss',\n",
        "                                  save_best_only=True)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wb3jbLH6z6t"
      },
      "source": [
        "Train `model_2`. Make sure you set the `callbacks` argument to `early_stopping`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIaH3lx16z6t",
        "outputId": "eb56fac2-f524-44d1-d3ac-72debe2fa148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 1.9625 - acc: 0.1505 - val_loss: 1.9482 - val_acc: 0.1390\n",
            "Epoch 2/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.9343 - acc: 0.1623 - val_loss: 1.9301 - val_acc: 0.1660\n",
            "Epoch 3/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.9167 - acc: 0.1789 - val_loss: 1.9154 - val_acc: 0.1860\n",
            "Epoch 4/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.9001 - acc: 0.2068 - val_loss: 1.8995 - val_acc: 0.1970\n",
            "Epoch 5/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.8817 - acc: 0.2331 - val_loss: 1.8817 - val_acc: 0.2300\n",
            "Epoch 6/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.8600 - acc: 0.2676 - val_loss: 1.8597 - val_acc: 0.2760\n",
            "Epoch 7/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.8347 - acc: 0.2985 - val_loss: 1.8344 - val_acc: 0.3050\n",
            "Epoch 8/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.8057 - acc: 0.3285 - val_loss: 1.8053 - val_acc: 0.3230\n",
            "Epoch 9/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.7730 - acc: 0.3583 - val_loss: 1.7724 - val_acc: 0.3580\n",
            "Epoch 10/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.7372 - acc: 0.3857 - val_loss: 1.7361 - val_acc: 0.3840\n",
            "Epoch 11/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.6980 - acc: 0.4109 - val_loss: 1.6971 - val_acc: 0.4090\n",
            "Epoch 12/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.6556 - acc: 0.4341 - val_loss: 1.6545 - val_acc: 0.4140\n",
            "Epoch 13/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.6101 - acc: 0.4604 - val_loss: 1.6105 - val_acc: 0.4270\n",
            "Epoch 14/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.5626 - acc: 0.4768 - val_loss: 1.5644 - val_acc: 0.4420\n",
            "Epoch 15/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.5142 - acc: 0.5015 - val_loss: 1.5147 - val_acc: 0.4620\n",
            "Epoch 16/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.4649 - acc: 0.5255 - val_loss: 1.4678 - val_acc: 0.4770\n",
            "Epoch 17/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.4159 - acc: 0.5347 - val_loss: 1.4185 - val_acc: 0.5070\n",
            "Epoch 18/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.3682 - acc: 0.5609 - val_loss: 1.3720 - val_acc: 0.5250\n",
            "Epoch 19/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.3217 - acc: 0.5761 - val_loss: 1.3273 - val_acc: 0.5470\n",
            "Epoch 20/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.2775 - acc: 0.5887 - val_loss: 1.2839 - val_acc: 0.5710\n",
            "Epoch 21/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.2352 - acc: 0.6033 - val_loss: 1.2448 - val_acc: 0.5930\n",
            "Epoch 22/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.1953 - acc: 0.6172 - val_loss: 1.2053 - val_acc: 0.6050\n",
            "Epoch 23/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.1583 - acc: 0.6291 - val_loss: 1.1709 - val_acc: 0.6070\n",
            "Epoch 24/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.1234 - acc: 0.6419 - val_loss: 1.1356 - val_acc: 0.6170\n",
            "Epoch 25/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.0904 - acc: 0.6524 - val_loss: 1.1055 - val_acc: 0.6300\n",
            "Epoch 26/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.0601 - acc: 0.6584 - val_loss: 1.0749 - val_acc: 0.6390\n",
            "Epoch 27/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.0308 - acc: 0.6640 - val_loss: 1.0485 - val_acc: 0.6440\n",
            "Epoch 28/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.0042 - acc: 0.6716 - val_loss: 1.0232 - val_acc: 0.6500\n",
            "Epoch 29/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.9789 - acc: 0.6789 - val_loss: 1.0007 - val_acc: 0.6530\n",
            "Epoch 30/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.9563 - acc: 0.6869 - val_loss: 0.9814 - val_acc: 0.6580\n",
            "Epoch 31/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.9342 - acc: 0.6919 - val_loss: 0.9581 - val_acc: 0.6690\n",
            "Epoch 32/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.9139 - acc: 0.6968 - val_loss: 0.9388 - val_acc: 0.6870\n",
            "Epoch 33/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.8943 - acc: 0.7037 - val_loss: 0.9225 - val_acc: 0.6870\n",
            "Epoch 34/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.8764 - acc: 0.7072 - val_loss: 0.9052 - val_acc: 0.6870\n",
            "Epoch 35/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.8590 - acc: 0.7108 - val_loss: 0.8911 - val_acc: 0.6880\n",
            "Epoch 36/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8432 - acc: 0.7149 - val_loss: 0.8774 - val_acc: 0.6880\n",
            "Epoch 37/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.8286 - acc: 0.7189 - val_loss: 0.8619 - val_acc: 0.7010\n",
            "Epoch 38/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.8135 - acc: 0.7247 - val_loss: 0.8511 - val_acc: 0.7040\n",
            "Epoch 39/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8000 - acc: 0.7281 - val_loss: 0.8403 - val_acc: 0.7060\n",
            "Epoch 40/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.7876 - acc: 0.7344 - val_loss: 0.8334 - val_acc: 0.7030\n",
            "Epoch 41/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.7752 - acc: 0.7348 - val_loss: 0.8172 - val_acc: 0.7150\n",
            "Epoch 42/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.7637 - acc: 0.7397 - val_loss: 0.8095 - val_acc: 0.7120\n",
            "Epoch 43/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.7523 - acc: 0.7425 - val_loss: 0.8006 - val_acc: 0.7060\n",
            "Epoch 44/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.7415 - acc: 0.7480 - val_loss: 0.7940 - val_acc: 0.7070\n",
            "Epoch 45/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.7319 - acc: 0.7509 - val_loss: 0.7854 - val_acc: 0.7060\n",
            "Epoch 46/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.7216 - acc: 0.7552 - val_loss: 0.7785 - val_acc: 0.7140\n",
            "Epoch 47/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.7120 - acc: 0.7565 - val_loss: 0.7721 - val_acc: 0.7100\n",
            "Epoch 48/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.7033 - acc: 0.7592 - val_loss: 0.7655 - val_acc: 0.7120\n",
            "Epoch 49/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.6947 - acc: 0.7628 - val_loss: 0.7597 - val_acc: 0.7180\n",
            "Epoch 50/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.6863 - acc: 0.7645 - val_loss: 0.7528 - val_acc: 0.7120\n",
            "Epoch 51/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.6777 - acc: 0.7684 - val_loss: 0.7488 - val_acc: 0.7130\n",
            "Epoch 52/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.6695 - acc: 0.7697 - val_loss: 0.7434 - val_acc: 0.7180\n",
            "Epoch 53/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.6622 - acc: 0.7708 - val_loss: 0.7380 - val_acc: 0.7190\n",
            "Epoch 54/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.6546 - acc: 0.7739 - val_loss: 0.7332 - val_acc: 0.7190\n",
            "Epoch 55/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.6474 - acc: 0.7779 - val_loss: 0.7291 - val_acc: 0.7230\n",
            "Epoch 56/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.6410 - acc: 0.7781 - val_loss: 0.7237 - val_acc: 0.7240\n",
            "Epoch 57/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.6339 - acc: 0.7808 - val_loss: 0.7199 - val_acc: 0.7250\n",
            "Epoch 58/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.6272 - acc: 0.7852 - val_loss: 0.7160 - val_acc: 0.7260\n",
            "Epoch 59/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.6205 - acc: 0.7873 - val_loss: 0.7143 - val_acc: 0.7220\n",
            "Epoch 60/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.6148 - acc: 0.7871 - val_loss: 0.7095 - val_acc: 0.7280\n",
            "Epoch 61/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.6085 - acc: 0.7884 - val_loss: 0.7043 - val_acc: 0.7240\n",
            "Epoch 62/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.6028 - acc: 0.7913 - val_loss: 0.7032 - val_acc: 0.7310\n",
            "Epoch 63/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.5962 - acc: 0.7932 - val_loss: 0.7024 - val_acc: 0.7290\n",
            "Epoch 64/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.5910 - acc: 0.7955 - val_loss: 0.6966 - val_acc: 0.7300\n",
            "Epoch 65/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.5854 - acc: 0.7979 - val_loss: 0.6952 - val_acc: 0.7340\n",
            "Epoch 66/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.5799 - acc: 0.8003 - val_loss: 0.6920 - val_acc: 0.7320\n",
            "Epoch 67/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5747 - acc: 0.8011 - val_loss: 0.6909 - val_acc: 0.7380\n",
            "Epoch 68/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5696 - acc: 0.8023 - val_loss: 0.6889 - val_acc: 0.7380\n",
            "Epoch 69/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.5640 - acc: 0.8075 - val_loss: 0.6862 - val_acc: 0.7280\n",
            "Epoch 70/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.5593 - acc: 0.8095 - val_loss: 0.6864 - val_acc: 0.7340\n",
            "Epoch 71/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.5542 - acc: 0.8108 - val_loss: 0.6805 - val_acc: 0.7340\n",
            "Epoch 72/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.5500 - acc: 0.8137 - val_loss: 0.6790 - val_acc: 0.7360\n",
            "Epoch 73/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.5446 - acc: 0.8141 - val_loss: 0.6790 - val_acc: 0.7390\n",
            "Epoch 74/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.5405 - acc: 0.8175 - val_loss: 0.6770 - val_acc: 0.7370\n",
            "Epoch 75/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.5356 - acc: 0.8197 - val_loss: 0.6762 - val_acc: 0.7380\n",
            "Epoch 76/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.5316 - acc: 0.8201 - val_loss: 0.6744 - val_acc: 0.7410\n",
            "Epoch 77/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.5265 - acc: 0.8201 - val_loss: 0.6737 - val_acc: 0.7390\n",
            "Epoch 78/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.5226 - acc: 0.8240 - val_loss: 0.6694 - val_acc: 0.7380\n",
            "Epoch 79/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.5180 - acc: 0.8243 - val_loss: 0.6683 - val_acc: 0.7410\n",
            "Epoch 80/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.5135 - acc: 0.8280 - val_loss: 0.6699 - val_acc: 0.7430\n",
            "Epoch 81/150\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.5098 - acc: 0.8296 - val_loss: 0.6654 - val_acc: 0.7430\n",
            "Epoch 82/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.5056 - acc: 0.8307 - val_loss: 0.6641 - val_acc: 0.7440\n",
            "Epoch 83/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.5015 - acc: 0.8324 - val_loss: 0.6674 - val_acc: 0.7440\n",
            "Epoch 84/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4975 - acc: 0.8336 - val_loss: 0.6616 - val_acc: 0.7460\n",
            "Epoch 85/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4937 - acc: 0.8369 - val_loss: 0.6603 - val_acc: 0.7470\n",
            "Epoch 86/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4898 - acc: 0.8365 - val_loss: 0.6570 - val_acc: 0.7480\n",
            "Epoch 87/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4859 - acc: 0.8396 - val_loss: 0.6619 - val_acc: 0.7390\n",
            "Epoch 88/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4822 - acc: 0.8420 - val_loss: 0.6599 - val_acc: 0.7460\n",
            "Epoch 89/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4782 - acc: 0.8416 - val_loss: 0.6552 - val_acc: 0.7430\n",
            "Epoch 90/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4747 - acc: 0.8425 - val_loss: 0.6542 - val_acc: 0.7440\n",
            "Epoch 91/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4712 - acc: 0.8468 - val_loss: 0.6551 - val_acc: 0.7460\n",
            "Epoch 92/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4673 - acc: 0.8460 - val_loss: 0.6527 - val_acc: 0.7450\n",
            "Epoch 93/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4634 - acc: 0.8481 - val_loss: 0.6547 - val_acc: 0.7440\n",
            "Epoch 94/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4600 - acc: 0.8497 - val_loss: 0.6585 - val_acc: 0.7440\n",
            "Epoch 95/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4569 - acc: 0.8516 - val_loss: 0.6530 - val_acc: 0.7420\n",
            "Epoch 96/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4530 - acc: 0.8536 - val_loss: 0.6543 - val_acc: 0.7490\n",
            "Epoch 97/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4497 - acc: 0.8528 - val_loss: 0.6525 - val_acc: 0.7430\n",
            "Epoch 98/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4461 - acc: 0.8559 - val_loss: 0.6508 - val_acc: 0.7430\n",
            "Epoch 99/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4429 - acc: 0.8567 - val_loss: 0.6534 - val_acc: 0.7430\n",
            "Epoch 100/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4395 - acc: 0.8563 - val_loss: 0.6479 - val_acc: 0.7420\n",
            "Epoch 101/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4363 - acc: 0.8603 - val_loss: 0.6501 - val_acc: 0.7420\n",
            "Epoch 102/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4332 - acc: 0.8616 - val_loss: 0.6475 - val_acc: 0.7460\n",
            "Epoch 103/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4299 - acc: 0.8628 - val_loss: 0.6491 - val_acc: 0.7430\n",
            "Epoch 104/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4265 - acc: 0.8632 - val_loss: 0.6482 - val_acc: 0.7450\n",
            "Epoch 105/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.4237 - acc: 0.8664 - val_loss: 0.6498 - val_acc: 0.7420\n",
            "Epoch 106/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4203 - acc: 0.8660 - val_loss: 0.6497 - val_acc: 0.7470\n",
            "Epoch 107/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.4174 - acc: 0.8676 - val_loss: 0.6478 - val_acc: 0.7410\n",
            "Epoch 108/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.4142 - acc: 0.8685 - val_loss: 0.6491 - val_acc: 0.7420\n",
            "Epoch 109/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.4110 - acc: 0.8716 - val_loss: 0.6476 - val_acc: 0.7440\n",
            "Epoch 110/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.4088 - acc: 0.8707 - val_loss: 0.6468 - val_acc: 0.7460\n",
            "Epoch 111/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.4053 - acc: 0.8709 - val_loss: 0.6492 - val_acc: 0.7430\n",
            "Epoch 112/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.4022 - acc: 0.8731 - val_loss: 0.6475 - val_acc: 0.7440\n",
            "Epoch 113/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3994 - acc: 0.8753 - val_loss: 0.6483 - val_acc: 0.7440\n",
            "Epoch 114/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.3967 - acc: 0.8761 - val_loss: 0.6467 - val_acc: 0.7470\n",
            "Epoch 115/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.3935 - acc: 0.8768 - val_loss: 0.6502 - val_acc: 0.7450\n",
            "Epoch 116/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3909 - acc: 0.8771 - val_loss: 0.6483 - val_acc: 0.7400\n",
            "Epoch 117/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3878 - acc: 0.8779 - val_loss: 0.6494 - val_acc: 0.7440\n",
            "Epoch 118/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3850 - acc: 0.8801 - val_loss: 0.6463 - val_acc: 0.7450\n",
            "Epoch 119/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3820 - acc: 0.8804 - val_loss: 0.6473 - val_acc: 0.7420\n",
            "Epoch 120/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.3797 - acc: 0.8820 - val_loss: 0.6461 - val_acc: 0.7380\n",
            "Epoch 121/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3764 - acc: 0.8815 - val_loss: 0.6456 - val_acc: 0.7450\n",
            "Epoch 122/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.3739 - acc: 0.8836 - val_loss: 0.6452 - val_acc: 0.7370\n",
            "Epoch 123/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.3712 - acc: 0.8853 - val_loss: 0.6445 - val_acc: 0.7450\n",
            "Epoch 124/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.3687 - acc: 0.8856 - val_loss: 0.6505 - val_acc: 0.7430\n",
            "Epoch 125/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3658 - acc: 0.8871 - val_loss: 0.6500 - val_acc: 0.7450\n",
            "Epoch 126/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.3630 - acc: 0.8871 - val_loss: 0.6477 - val_acc: 0.7390\n",
            "Epoch 127/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.3605 - acc: 0.8900 - val_loss: 0.6512 - val_acc: 0.7440\n",
            "Epoch 128/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3581 - acc: 0.8892 - val_loss: 0.6486 - val_acc: 0.7400\n",
            "Epoch 129/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3558 - acc: 0.8912 - val_loss: 0.6475 - val_acc: 0.7470\n",
            "Epoch 130/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3532 - acc: 0.8908 - val_loss: 0.6464 - val_acc: 0.7400\n",
            "Epoch 131/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3507 - acc: 0.8916 - val_loss: 0.6509 - val_acc: 0.7430\n",
            "Epoch 132/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3485 - acc: 0.8940 - val_loss: 0.6483 - val_acc: 0.7370\n",
            "Epoch 133/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3458 - acc: 0.8955 - val_loss: 0.6522 - val_acc: 0.7440\n"
          ]
        }
      ],
      "source": [
        "model_2_val = model_2.fit(X_train_tokens, \n",
        "                          y_train_lb, \n",
        "                          epochs=150, \n",
        "                          callbacks=early_stopping, \n",
        "                          batch_size=256, \n",
        "                          validation_data=(X_val_tokens, y_val_lb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVbTwNrY6z6t"
      },
      "source": [
        "Load the best (saved) model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "CLnpkg5l6z6t"
      },
      "outputs": [],
      "source": [
        "# Load the best (saved) model\n",
        "\n",
        "from keras.models import load_model\n",
        "saved_model = load_model('best_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w58ExSIi6z6t"
      },
      "source": [
        "Now, use this model to to calculate the training and test accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbQkDdF66z6u",
        "outputId": "91c81d81-af59-4d88-be62-13a1cc4c8886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235/235 [==============================] - 1s 2ms/step - loss: 0.3690 - acc: 0.8845\n",
            "Training Loss: 0.369 \n",
            "Training Accuracy: 0.885\n",
            "----------\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.6262 - acc: 0.7807\n",
            "Test Loss: 0.626 \n",
            "Test Accuracy: 0.781\n"
          ]
        }
      ],
      "source": [
        "results_train = saved_model.evaluate(X_train_tokens, y_train_lb)\n",
        "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
        "\n",
        "print('----------')\n",
        "\n",
        "results_test = saved_model.evaluate(X_test_tokens, y_test_lb)\n",
        "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzu2uN3s6z6u"
      },
      "source": [
        "Nicely done! Did you notice that the model didn't train for all 150 epochs? You reduced your training time. \n",
        "\n",
        "Now, take a look at how regularization techniques can further improve your model performance. \n",
        "\n",
        "## L2 Regularization \n",
        "\n",
        "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform. \n",
        "\n",
        "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
        "- Add L2 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfYZW7so6z6u",
        "outputId": "32837ae3-fd66-4704-c5c9-15ae67751933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "30/30 [==============================] - 1s 16ms/step - loss: 2.6059 - acc: 0.1437 - val_loss: 2.5925 - val_acc: 0.1480\n",
            "Epoch 2/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 2.5806 - acc: 0.1605 - val_loss: 2.5750 - val_acc: 0.1660\n",
            "Epoch 3/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 2.5619 - acc: 0.1893 - val_loss: 2.5591 - val_acc: 0.1900\n",
            "Epoch 4/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 2.5444 - acc: 0.2164 - val_loss: 2.5434 - val_acc: 0.2060\n",
            "Epoch 5/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 2.5265 - acc: 0.2395 - val_loss: 2.5268 - val_acc: 0.2330\n",
            "Epoch 6/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 2.5074 - acc: 0.2613 - val_loss: 2.5081 - val_acc: 0.2550\n",
            "Epoch 7/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.4868 - acc: 0.2765 - val_loss: 2.4868 - val_acc: 0.2860\n",
            "Epoch 8/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.4646 - acc: 0.3024 - val_loss: 2.4665 - val_acc: 0.2810\n",
            "Epoch 9/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.4409 - acc: 0.3187 - val_loss: 2.4420 - val_acc: 0.3010\n",
            "Epoch 10/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.4152 - acc: 0.3435 - val_loss: 2.4164 - val_acc: 0.3200\n",
            "Epoch 11/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.3876 - acc: 0.3620 - val_loss: 2.3898 - val_acc: 0.3430\n",
            "Epoch 12/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.3576 - acc: 0.3843 - val_loss: 2.3594 - val_acc: 0.3640\n",
            "Epoch 13/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.3252 - acc: 0.4084 - val_loss: 2.3263 - val_acc: 0.3860\n",
            "Epoch 14/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.2904 - acc: 0.4320 - val_loss: 2.2900 - val_acc: 0.4240\n",
            "Epoch 15/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.2534 - acc: 0.4580 - val_loss: 2.2541 - val_acc: 0.4570\n",
            "Epoch 16/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.2139 - acc: 0.4884 - val_loss: 2.2163 - val_acc: 0.4780\n",
            "Epoch 17/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.1720 - acc: 0.5157 - val_loss: 2.1735 - val_acc: 0.5080\n",
            "Epoch 18/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.1282 - acc: 0.5427 - val_loss: 2.1305 - val_acc: 0.5280\n",
            "Epoch 19/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.0822 - acc: 0.5675 - val_loss: 2.0850 - val_acc: 0.5540\n",
            "Epoch 20/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.0356 - acc: 0.5907 - val_loss: 2.0377 - val_acc: 0.5750\n",
            "Epoch 21/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.9880 - acc: 0.6076 - val_loss: 1.9924 - val_acc: 0.5870\n",
            "Epoch 22/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.9404 - acc: 0.6212 - val_loss: 1.9458 - val_acc: 0.5990\n",
            "Epoch 23/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.8932 - acc: 0.6413 - val_loss: 1.9024 - val_acc: 0.6140\n",
            "Epoch 24/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.8476 - acc: 0.6501 - val_loss: 1.8590 - val_acc: 0.6300\n",
            "Epoch 25/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.8034 - acc: 0.6609 - val_loss: 1.8188 - val_acc: 0.6370\n",
            "Epoch 26/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.7619 - acc: 0.6687 - val_loss: 1.7785 - val_acc: 0.6360\n",
            "Epoch 27/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.7223 - acc: 0.6755 - val_loss: 1.7401 - val_acc: 0.6420\n",
            "Epoch 28/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.6849 - acc: 0.6837 - val_loss: 1.7080 - val_acc: 0.6520\n",
            "Epoch 29/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.6502 - acc: 0.6907 - val_loss: 1.6730 - val_acc: 0.6570\n",
            "Epoch 30/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.6180 - acc: 0.6981 - val_loss: 1.6426 - val_acc: 0.6620\n",
            "Epoch 31/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.5885 - acc: 0.7021 - val_loss: 1.6184 - val_acc: 0.6670\n",
            "Epoch 32/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.5601 - acc: 0.7072 - val_loss: 1.5965 - val_acc: 0.6700\n",
            "Epoch 33/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.5346 - acc: 0.7133 - val_loss: 1.5699 - val_acc: 0.6730\n",
            "Epoch 34/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.5102 - acc: 0.7160 - val_loss: 1.5458 - val_acc: 0.6780\n",
            "Epoch 35/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.4877 - acc: 0.7191 - val_loss: 1.5279 - val_acc: 0.6840\n",
            "Epoch 36/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.4667 - acc: 0.7263 - val_loss: 1.5094 - val_acc: 0.6830\n",
            "Epoch 37/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.4466 - acc: 0.7271 - val_loss: 1.4884 - val_acc: 0.6840\n",
            "Epoch 38/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.4275 - acc: 0.7337 - val_loss: 1.4749 - val_acc: 0.6970\n",
            "Epoch 39/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.4102 - acc: 0.7339 - val_loss: 1.4555 - val_acc: 0.7000\n",
            "Epoch 40/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3937 - acc: 0.7364 - val_loss: 1.4394 - val_acc: 0.7030\n",
            "Epoch 41/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.3781 - acc: 0.7415 - val_loss: 1.4268 - val_acc: 0.7020\n",
            "Epoch 42/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.3626 - acc: 0.7467 - val_loss: 1.4237 - val_acc: 0.7020\n",
            "Epoch 43/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.3487 - acc: 0.7456 - val_loss: 1.4033 - val_acc: 0.7100\n",
            "Epoch 44/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.3352 - acc: 0.7501 - val_loss: 1.3914 - val_acc: 0.7120\n",
            "Epoch 45/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.3221 - acc: 0.7521 - val_loss: 1.3768 - val_acc: 0.7220\n",
            "Epoch 46/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.3095 - acc: 0.7567 - val_loss: 1.3684 - val_acc: 0.7150\n",
            "Epoch 47/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.2978 - acc: 0.7569 - val_loss: 1.3564 - val_acc: 0.7240\n",
            "Epoch 48/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.2861 - acc: 0.7585 - val_loss: 1.3458 - val_acc: 0.7310\n",
            "Epoch 49/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.2751 - acc: 0.7608 - val_loss: 1.3366 - val_acc: 0.7280\n",
            "Epoch 50/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.2647 - acc: 0.7635 - val_loss: 1.3324 - val_acc: 0.7260\n",
            "Epoch 51/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.2542 - acc: 0.7637 - val_loss: 1.3244 - val_acc: 0.7240\n",
            "Epoch 52/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.2445 - acc: 0.7691 - val_loss: 1.3154 - val_acc: 0.7250\n",
            "Epoch 53/150\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 1.2349 - acc: 0.7695 - val_loss: 1.3059 - val_acc: 0.7310\n",
            "Epoch 54/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.2257 - acc: 0.7719 - val_loss: 1.2999 - val_acc: 0.7290\n",
            "Epoch 55/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.2167 - acc: 0.7735 - val_loss: 1.2932 - val_acc: 0.7290\n",
            "Epoch 56/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.2081 - acc: 0.7779 - val_loss: 1.2839 - val_acc: 0.7330\n",
            "Epoch 57/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.1997 - acc: 0.7763 - val_loss: 1.2838 - val_acc: 0.7300\n",
            "Epoch 58/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.1915 - acc: 0.7801 - val_loss: 1.2710 - val_acc: 0.7340\n",
            "Epoch 59/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.1836 - acc: 0.7811 - val_loss: 1.2658 - val_acc: 0.7320\n",
            "Epoch 60/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.1756 - acc: 0.7831 - val_loss: 1.2656 - val_acc: 0.7340\n",
            "Epoch 61/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.1685 - acc: 0.7869 - val_loss: 1.2570 - val_acc: 0.7270\n",
            "Epoch 62/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.1607 - acc: 0.7872 - val_loss: 1.2497 - val_acc: 0.7340\n",
            "Epoch 63/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.1533 - acc: 0.7923 - val_loss: 1.2435 - val_acc: 0.7310\n",
            "Epoch 64/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.1464 - acc: 0.7925 - val_loss: 1.2417 - val_acc: 0.7320\n",
            "Epoch 65/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.1396 - acc: 0.7913 - val_loss: 1.2336 - val_acc: 0.7300\n",
            "Epoch 66/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.1326 - acc: 0.7963 - val_loss: 1.2315 - val_acc: 0.7320\n",
            "Epoch 67/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.1261 - acc: 0.7965 - val_loss: 1.2267 - val_acc: 0.7360\n",
            "Epoch 68/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.1194 - acc: 0.7987 - val_loss: 1.2233 - val_acc: 0.7360\n",
            "Epoch 69/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.1128 - acc: 0.8005 - val_loss: 1.2167 - val_acc: 0.7410\n",
            "Epoch 70/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.1067 - acc: 0.8012 - val_loss: 1.2112 - val_acc: 0.7360\n",
            "Epoch 71/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.1006 - acc: 0.8043 - val_loss: 1.2058 - val_acc: 0.7390\n",
            "Epoch 72/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.0941 - acc: 0.8063 - val_loss: 1.2069 - val_acc: 0.7370\n",
            "Epoch 73/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.0883 - acc: 0.8084 - val_loss: 1.2002 - val_acc: 0.7390\n",
            "Epoch 74/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.0825 - acc: 0.8079 - val_loss: 1.1962 - val_acc: 0.7400\n",
            "Epoch 75/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.0768 - acc: 0.8095 - val_loss: 1.1934 - val_acc: 0.7430\n",
            "Epoch 76/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.0709 - acc: 0.8101 - val_loss: 1.1892 - val_acc: 0.7430\n",
            "Epoch 77/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.0653 - acc: 0.8120 - val_loss: 1.1843 - val_acc: 0.7430\n",
            "Epoch 78/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.0595 - acc: 0.8133 - val_loss: 1.1844 - val_acc: 0.7450\n",
            "Epoch 79/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.0547 - acc: 0.8156 - val_loss: 1.1771 - val_acc: 0.7460\n",
            "Epoch 80/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.0489 - acc: 0.8155 - val_loss: 1.1737 - val_acc: 0.7460\n",
            "Epoch 81/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.0436 - acc: 0.8185 - val_loss: 1.1708 - val_acc: 0.7440\n",
            "Epoch 82/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.0382 - acc: 0.8208 - val_loss: 1.1661 - val_acc: 0.7440\n",
            "Epoch 83/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.0333 - acc: 0.8215 - val_loss: 1.1667 - val_acc: 0.7460\n",
            "Epoch 84/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.0283 - acc: 0.8237 - val_loss: 1.1597 - val_acc: 0.7460\n",
            "Epoch 85/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.0229 - acc: 0.8237 - val_loss: 1.1566 - val_acc: 0.7420\n",
            "Epoch 86/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.0188 - acc: 0.8260 - val_loss: 1.1567 - val_acc: 0.7480\n",
            "Epoch 87/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.0131 - acc: 0.8283 - val_loss: 1.1577 - val_acc: 0.7510\n",
            "Epoch 88/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.0085 - acc: 0.8309 - val_loss: 1.1520 - val_acc: 0.7520\n",
            "Epoch 89/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.0032 - acc: 0.8305 - val_loss: 1.1457 - val_acc: 0.7510\n",
            "Epoch 90/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.9983 - acc: 0.8307 - val_loss: 1.1463 - val_acc: 0.7490\n",
            "Epoch 91/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.9940 - acc: 0.8344 - val_loss: 1.1402 - val_acc: 0.7480\n",
            "Epoch 92/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.9893 - acc: 0.8351 - val_loss: 1.1395 - val_acc: 0.7500\n",
            "Epoch 93/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.9849 - acc: 0.8364 - val_loss: 1.1367 - val_acc: 0.7510\n",
            "Epoch 94/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.9801 - acc: 0.8372 - val_loss: 1.1359 - val_acc: 0.7460\n",
            "Epoch 95/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.9756 - acc: 0.8384 - val_loss: 1.1379 - val_acc: 0.7440\n",
            "Epoch 96/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.9712 - acc: 0.8397 - val_loss: 1.1280 - val_acc: 0.7440\n",
            "Epoch 97/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.9663 - acc: 0.8419 - val_loss: 1.1333 - val_acc: 0.7450\n",
            "Epoch 98/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.9622 - acc: 0.8432 - val_loss: 1.1233 - val_acc: 0.7540\n",
            "Epoch 99/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.9580 - acc: 0.8419 - val_loss: 1.1225 - val_acc: 0.7480\n",
            "Epoch 100/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.9536 - acc: 0.8440 - val_loss: 1.1168 - val_acc: 0.7550\n",
            "Epoch 101/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.9494 - acc: 0.8456 - val_loss: 1.1178 - val_acc: 0.7520\n",
            "Epoch 102/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.9451 - acc: 0.8465 - val_loss: 1.1177 - val_acc: 0.7480\n",
            "Epoch 103/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.9411 - acc: 0.8465 - val_loss: 1.1111 - val_acc: 0.7500\n",
            "Epoch 104/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.9370 - acc: 0.8472 - val_loss: 1.1092 - val_acc: 0.7500\n",
            "Epoch 105/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.9325 - acc: 0.8505 - val_loss: 1.1056 - val_acc: 0.7520\n",
            "Epoch 106/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.9289 - acc: 0.8504 - val_loss: 1.1076 - val_acc: 0.7440\n",
            "Epoch 107/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.9246 - acc: 0.8511 - val_loss: 1.1022 - val_acc: 0.7490\n",
            "Epoch 108/150\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.9208 - acc: 0.8511 - val_loss: 1.0985 - val_acc: 0.7520\n",
            "Epoch 109/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.9165 - acc: 0.8535 - val_loss: 1.1007 - val_acc: 0.7470\n",
            "Epoch 110/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.9128 - acc: 0.8544 - val_loss: 1.0943 - val_acc: 0.7530\n",
            "Epoch 111/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.9085 - acc: 0.8525 - val_loss: 1.0947 - val_acc: 0.7480\n",
            "Epoch 112/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.9051 - acc: 0.8565 - val_loss: 1.0920 - val_acc: 0.7480\n",
            "Epoch 113/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.9012 - acc: 0.8564 - val_loss: 1.0923 - val_acc: 0.7500\n",
            "Epoch 114/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8974 - acc: 0.8584 - val_loss: 1.0899 - val_acc: 0.7480\n",
            "Epoch 115/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.8937 - acc: 0.8593 - val_loss: 1.0865 - val_acc: 0.7520\n",
            "Epoch 116/150\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.8897 - acc: 0.8615 - val_loss: 1.0867 - val_acc: 0.7440\n",
            "Epoch 117/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.8862 - acc: 0.8597 - val_loss: 1.0841 - val_acc: 0.7470\n",
            "Epoch 118/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8826 - acc: 0.8640 - val_loss: 1.0828 - val_acc: 0.7440\n",
            "Epoch 119/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.8788 - acc: 0.8633 - val_loss: 1.0794 - val_acc: 0.7490\n",
            "Epoch 120/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.8753 - acc: 0.8627 - val_loss: 1.0787 - val_acc: 0.7470\n",
            "Epoch 121/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8721 - acc: 0.8635 - val_loss: 1.0805 - val_acc: 0.7440\n",
            "Epoch 122/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8683 - acc: 0.8661 - val_loss: 1.0772 - val_acc: 0.7460\n",
            "Epoch 123/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8649 - acc: 0.8675 - val_loss: 1.0772 - val_acc: 0.7490\n",
            "Epoch 124/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8612 - acc: 0.8659 - val_loss: 1.0788 - val_acc: 0.7490\n",
            "Epoch 125/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8578 - acc: 0.8669 - val_loss: 1.0733 - val_acc: 0.7480\n",
            "Epoch 126/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8542 - acc: 0.8677 - val_loss: 1.0694 - val_acc: 0.7460\n",
            "Epoch 127/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8509 - acc: 0.8696 - val_loss: 1.0663 - val_acc: 0.7510\n",
            "Epoch 128/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8475 - acc: 0.8695 - val_loss: 1.0699 - val_acc: 0.7480\n",
            "Epoch 129/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8440 - acc: 0.8723 - val_loss: 1.0635 - val_acc: 0.7440\n",
            "Epoch 130/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.8406 - acc: 0.8713 - val_loss: 1.0627 - val_acc: 0.7500\n",
            "Epoch 131/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.8374 - acc: 0.8709 - val_loss: 1.0621 - val_acc: 0.7490\n",
            "Epoch 132/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8342 - acc: 0.8736 - val_loss: 1.0602 - val_acc: 0.7470\n",
            "Epoch 133/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8310 - acc: 0.8739 - val_loss: 1.0602 - val_acc: 0.7490\n",
            "Epoch 134/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8277 - acc: 0.8753 - val_loss: 1.0570 - val_acc: 0.7520\n",
            "Epoch 135/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8248 - acc: 0.8755 - val_loss: 1.0549 - val_acc: 0.7500\n",
            "Epoch 136/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.8212 - acc: 0.8757 - val_loss: 1.0546 - val_acc: 0.7470\n",
            "Epoch 137/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8182 - acc: 0.8764 - val_loss: 1.0582 - val_acc: 0.7460\n",
            "Epoch 138/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8150 - acc: 0.8784 - val_loss: 1.0530 - val_acc: 0.7510\n",
            "Epoch 139/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8121 - acc: 0.8793 - val_loss: 1.0519 - val_acc: 0.7420\n",
            "Epoch 140/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8090 - acc: 0.8788 - val_loss: 1.0508 - val_acc: 0.7450\n",
            "Epoch 141/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.8058 - acc: 0.8796 - val_loss: 1.0474 - val_acc: 0.7460\n",
            "Epoch 142/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.8028 - acc: 0.8812 - val_loss: 1.0483 - val_acc: 0.7440\n",
            "Epoch 143/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.7997 - acc: 0.8816 - val_loss: 1.0467 - val_acc: 0.7480\n",
            "Epoch 144/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.7968 - acc: 0.8835 - val_loss: 1.0434 - val_acc: 0.7460\n",
            "Epoch 145/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.7938 - acc: 0.8831 - val_loss: 1.0428 - val_acc: 0.7470\n",
            "Epoch 146/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.7908 - acc: 0.8839 - val_loss: 1.0416 - val_acc: 0.7460\n",
            "Epoch 147/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.7880 - acc: 0.8853 - val_loss: 1.0428 - val_acc: 0.7440\n",
            "Epoch 148/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.7850 - acc: 0.8859 - val_loss: 1.0402 - val_acc: 0.7460\n",
            "Epoch 149/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.7820 - acc: 0.8869 - val_loss: 1.0404 - val_acc: 0.7480\n",
            "Epoch 150/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.7788 - acc: 0.8876 - val_loss: 1.0402 - val_acc: 0.7450\n"
          ]
        }
      ],
      "source": [
        "# Import regularizers\n",
        "from keras import regularizers\n",
        "random.seed(123)\n",
        "L2_model = models.Sequential()\n",
        "\n",
        "# Add the input and first hidden layer\n",
        "L2_model.add(layers.Dense(50, activation='relu', \n",
        "                          kernel_regularizer=regularizers.l2(0.005), \n",
        "                          input_shape=(2000,)))\n",
        "\n",
        "# Add another hidden layer\n",
        "L2_model.add(layers.Dense(25,activation='relu',\n",
        "                          kernel_regularizer=regularizers.l2(.005),\n",
        "                          ))\n",
        "\n",
        "# Add an output layer\n",
        "L2_model.add(layers.Dense(7, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "L2_model.compile(optimizer='SGD', \n",
        "                 loss='categorical_crossentropy', \n",
        "                 metrics=['acc'])\n",
        "\n",
        "# Train the model \n",
        "L2_model_val = L2_model.fit(X_train_tokens, \n",
        "                            y_train_lb, \n",
        "                            epochs=150, \n",
        "                            batch_size=256, \n",
        "                            validation_data=(X_val_tokens, y_val_lb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lumLPGPs6z6u"
      },
      "source": [
        "Now, look at the training as well as the validation accuracy for both the L2 and the baseline models. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "mZ8x8nUk6z6u",
        "outputId": "dc8ce81b-73a5-48dc-d95e-03f1977f5374"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# L2 model details\n",
        "L2_model_dict = L2_model_val.history\n",
        "L2_acc_values = L2_model_dict['acc'] \n",
        "L2_val_acc_values = L2_model_dict['val_acc']\n",
        "\n",
        "# Baseline model\n",
        "baseline_model_acc = baseline_model_val_dict['acc'] \n",
        "baseline_model_val_acc = baseline_model_val_dict['val_acc']\n",
        "\n",
        "# Plot the accuracy for these models\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "epochs = range(1, len(L2_acc_values) + 1)\n",
        "ax.plot(epochs, L2_acc_values, label='Training acc L2')\n",
        "ax.plot(epochs, L2_val_acc_values, label='Validation acc L2')\n",
        "ax.plot(epochs, baseline_model_acc, label='Training acc')\n",
        "ax.plot(epochs, baseline_model_val_acc, label='Validation acc')\n",
        "ax.set_title('Training & validation accuracy L2 vs regular')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2NmjNrT6z6u"
      },
      "source": [
        "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better.  \n",
        "\n",
        "\n",
        "## L1 Regularization\n",
        "\n",
        "Now have a look at L1 regularization. Will this work better? \n",
        "\n",
        "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
        "- Add L1 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w5Px8DC6z6u",
        "outputId": "a1cd649f-9318-4123-8dd2-efd0d1bdf3d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 16.0040 - acc: 0.1217 - val_loss: 15.5942 - val_acc: 0.1540\n",
            "Epoch 2/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 15.2404 - acc: 0.1609 - val_loss: 14.8538 - val_acc: 0.1890\n",
            "Epoch 3/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 14.5107 - acc: 0.1963 - val_loss: 14.1395 - val_acc: 0.2080\n",
            "Epoch 4/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 13.8060 - acc: 0.2217 - val_loss: 13.4483 - val_acc: 0.2150\n",
            "Epoch 5/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 13.1238 - acc: 0.2424 - val_loss: 12.7788 - val_acc: 0.2260\n",
            "Epoch 6/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 12.4626 - acc: 0.2585 - val_loss: 12.1293 - val_acc: 0.2400\n",
            "Epoch 7/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 11.8216 - acc: 0.2763 - val_loss: 11.4990 - val_acc: 0.2620\n",
            "Epoch 8/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 11.2000 - acc: 0.2968 - val_loss: 10.8879 - val_acc: 0.2900\n",
            "Epoch 9/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 10.5984 - acc: 0.3173 - val_loss: 10.2975 - val_acc: 0.3050\n",
            "Epoch 10/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 10.0168 - acc: 0.3428 - val_loss: 9.7263 - val_acc: 0.3460\n",
            "Epoch 11/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 9.4549 - acc: 0.3639 - val_loss: 9.1763 - val_acc: 0.3570\n",
            "Epoch 12/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 8.9130 - acc: 0.3817 - val_loss: 8.6457 - val_acc: 0.3750\n",
            "Epoch 13/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 8.3909 - acc: 0.4008 - val_loss: 8.1356 - val_acc: 0.3970\n",
            "Epoch 14/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 7.8893 - acc: 0.4204 - val_loss: 7.6462 - val_acc: 0.4200\n",
            "Epoch 15/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 7.4077 - acc: 0.4416 - val_loss: 7.1771 - val_acc: 0.4250\n",
            "Epoch 16/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 6.9465 - acc: 0.4521 - val_loss: 6.7276 - val_acc: 0.4600\n",
            "Epoch 17/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 6.5059 - acc: 0.4685 - val_loss: 6.2993 - val_acc: 0.4640\n",
            "Epoch 18/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 6.0868 - acc: 0.4887 - val_loss: 5.8938 - val_acc: 0.4750\n",
            "Epoch 19/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 5.6903 - acc: 0.5065 - val_loss: 5.5091 - val_acc: 0.4940\n",
            "Epoch 20/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 5.3156 - acc: 0.5216 - val_loss: 5.1482 - val_acc: 0.4970\n",
            "Epoch 21/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 4.9638 - acc: 0.5269 - val_loss: 4.8082 - val_acc: 0.5220\n",
            "Epoch 22/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 4.6343 - acc: 0.5457 - val_loss: 4.4931 - val_acc: 0.5280\n",
            "Epoch 23/150\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 4.3277 - acc: 0.5469 - val_loss: 4.1977 - val_acc: 0.5480\n",
            "Epoch 24/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 4.0428 - acc: 0.5623 - val_loss: 3.9246 - val_acc: 0.5610\n",
            "Epoch 25/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 3.7795 - acc: 0.5833 - val_loss: 3.6742 - val_acc: 0.5590\n",
            "Epoch 26/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 3.5378 - acc: 0.5809 - val_loss: 3.4439 - val_acc: 0.5700\n",
            "Epoch 27/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 3.3176 - acc: 0.5924 - val_loss: 3.2359 - val_acc: 0.5680\n",
            "Epoch 28/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 3.1188 - acc: 0.5945 - val_loss: 3.0472 - val_acc: 0.5840\n",
            "Epoch 29/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 2.9404 - acc: 0.5997 - val_loss: 2.8819 - val_acc: 0.5980\n",
            "Epoch 30/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 2.7832 - acc: 0.6101 - val_loss: 2.7331 - val_acc: 0.5990\n",
            "Epoch 31/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 2.6458 - acc: 0.6172 - val_loss: 2.6072 - val_acc: 0.5950\n",
            "Epoch 32/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.5291 - acc: 0.6141 - val_loss: 2.5008 - val_acc: 0.6000\n",
            "Epoch 33/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 2.4317 - acc: 0.6184 - val_loss: 2.4133 - val_acc: 0.6030\n",
            "Epoch 34/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 2.3530 - acc: 0.6229 - val_loss: 2.3432 - val_acc: 0.6060\n",
            "Epoch 35/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 2.2915 - acc: 0.6269 - val_loss: 2.2876 - val_acc: 0.6240\n",
            "Epoch 36/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.2448 - acc: 0.6319 - val_loss: 2.2470 - val_acc: 0.6300\n",
            "Epoch 37/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.2093 - acc: 0.6344 - val_loss: 2.2152 - val_acc: 0.6330\n",
            "Epoch 38/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.1797 - acc: 0.6439 - val_loss: 2.1878 - val_acc: 0.6340\n",
            "Epoch 39/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.1530 - acc: 0.6412 - val_loss: 2.1608 - val_acc: 0.6380\n",
            "Epoch 40/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.1282 - acc: 0.6477 - val_loss: 2.1387 - val_acc: 0.6370\n",
            "Epoch 41/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.1046 - acc: 0.6472 - val_loss: 2.1154 - val_acc: 0.6400\n",
            "Epoch 42/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.0823 - acc: 0.6507 - val_loss: 2.0917 - val_acc: 0.6420\n",
            "Epoch 43/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 2.0606 - acc: 0.6543 - val_loss: 2.0691 - val_acc: 0.6410\n",
            "Epoch 44/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.0399 - acc: 0.6551 - val_loss: 2.0470 - val_acc: 0.6460\n",
            "Epoch 45/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.0196 - acc: 0.6551 - val_loss: 2.0289 - val_acc: 0.6540\n",
            "Epoch 46/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 2.0001 - acc: 0.6584 - val_loss: 2.0078 - val_acc: 0.6600\n",
            "Epoch 47/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.9813 - acc: 0.6591 - val_loss: 1.9884 - val_acc: 0.6590\n",
            "Epoch 48/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.9627 - acc: 0.6609 - val_loss: 1.9687 - val_acc: 0.6640\n",
            "Epoch 49/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.9450 - acc: 0.6629 - val_loss: 1.9519 - val_acc: 0.6670\n",
            "Epoch 50/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.9280 - acc: 0.6621 - val_loss: 1.9353 - val_acc: 0.6600\n",
            "Epoch 51/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.9115 - acc: 0.6673 - val_loss: 1.9191 - val_acc: 0.6660\n",
            "Epoch 52/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.8959 - acc: 0.6664 - val_loss: 1.9026 - val_acc: 0.6680\n",
            "Epoch 53/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.8806 - acc: 0.6700 - val_loss: 1.8940 - val_acc: 0.6640\n",
            "Epoch 54/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.8662 - acc: 0.6696 - val_loss: 1.8742 - val_acc: 0.6660\n",
            "Epoch 55/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.8519 - acc: 0.6717 - val_loss: 1.8604 - val_acc: 0.6690\n",
            "Epoch 56/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.8378 - acc: 0.6728 - val_loss: 1.8450 - val_acc: 0.6720\n",
            "Epoch 57/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.8246 - acc: 0.6728 - val_loss: 1.8313 - val_acc: 0.6740\n",
            "Epoch 58/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.8119 - acc: 0.6744 - val_loss: 1.8188 - val_acc: 0.6760\n",
            "Epoch 59/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.7995 - acc: 0.6736 - val_loss: 1.8063 - val_acc: 0.6740\n",
            "Epoch 60/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.7871 - acc: 0.6761 - val_loss: 1.7965 - val_acc: 0.6750\n",
            "Epoch 61/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.7754 - acc: 0.6761 - val_loss: 1.7839 - val_acc: 0.6750\n",
            "Epoch 62/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.7641 - acc: 0.6785 - val_loss: 1.7720 - val_acc: 0.6780\n",
            "Epoch 63/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.7526 - acc: 0.6792 - val_loss: 1.7584 - val_acc: 0.6810\n",
            "Epoch 64/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.7421 - acc: 0.6803 - val_loss: 1.7499 - val_acc: 0.6780\n",
            "Epoch 65/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.7313 - acc: 0.6809 - val_loss: 1.7422 - val_acc: 0.6790\n",
            "Epoch 66/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.7210 - acc: 0.6837 - val_loss: 1.7291 - val_acc: 0.6770\n",
            "Epoch 67/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.7113 - acc: 0.6820 - val_loss: 1.7175 - val_acc: 0.6820\n",
            "Epoch 68/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.7015 - acc: 0.6849 - val_loss: 1.7098 - val_acc: 0.6790\n",
            "Epoch 69/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.6919 - acc: 0.6849 - val_loss: 1.7032 - val_acc: 0.6820\n",
            "Epoch 70/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.6828 - acc: 0.6877 - val_loss: 1.6912 - val_acc: 0.6800\n",
            "Epoch 71/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.6736 - acc: 0.6883 - val_loss: 1.6811 - val_acc: 0.6830\n",
            "Epoch 72/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.6646 - acc: 0.6901 - val_loss: 1.6708 - val_acc: 0.6830\n",
            "Epoch 73/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.6563 - acc: 0.6911 - val_loss: 1.6628 - val_acc: 0.6850\n",
            "Epoch 74/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.6473 - acc: 0.6921 - val_loss: 1.6537 - val_acc: 0.6830\n",
            "Epoch 75/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.6392 - acc: 0.6917 - val_loss: 1.6490 - val_acc: 0.6860\n",
            "Epoch 76/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.6307 - acc: 0.6929 - val_loss: 1.6386 - val_acc: 0.6850\n",
            "Epoch 77/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.6226 - acc: 0.6928 - val_loss: 1.6357 - val_acc: 0.6840\n",
            "Epoch 78/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.6148 - acc: 0.6940 - val_loss: 1.6289 - val_acc: 0.6840\n",
            "Epoch 79/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.6068 - acc: 0.6936 - val_loss: 1.6187 - val_acc: 0.6890\n",
            "Epoch 80/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.5990 - acc: 0.6949 - val_loss: 1.6120 - val_acc: 0.6860\n",
            "Epoch 81/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.5916 - acc: 0.6951 - val_loss: 1.6002 - val_acc: 0.6880\n",
            "Epoch 82/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.5841 - acc: 0.6957 - val_loss: 1.5946 - val_acc: 0.6880\n",
            "Epoch 83/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.5769 - acc: 0.6967 - val_loss: 1.5871 - val_acc: 0.6910\n",
            "Epoch 84/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.5705 - acc: 0.6961 - val_loss: 1.5792 - val_acc: 0.6950\n",
            "Epoch 85/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.5624 - acc: 0.6981 - val_loss: 1.5732 - val_acc: 0.6940\n",
            "Epoch 86/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.5557 - acc: 0.6995 - val_loss: 1.5662 - val_acc: 0.6940\n",
            "Epoch 87/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.5489 - acc: 0.6979 - val_loss: 1.5623 - val_acc: 0.6860\n",
            "Epoch 88/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.5420 - acc: 0.6995 - val_loss: 1.5531 - val_acc: 0.6890\n",
            "Epoch 89/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.5352 - acc: 0.7009 - val_loss: 1.5469 - val_acc: 0.6910\n",
            "Epoch 90/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.5282 - acc: 0.7011 - val_loss: 1.5462 - val_acc: 0.6870\n",
            "Epoch 91/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.5223 - acc: 0.7008 - val_loss: 1.5369 - val_acc: 0.6860\n",
            "Epoch 92/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.5154 - acc: 0.7012 - val_loss: 1.5275 - val_acc: 0.6950\n",
            "Epoch 93/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.5085 - acc: 0.7019 - val_loss: 1.5232 - val_acc: 0.6950\n",
            "Epoch 94/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.5025 - acc: 0.7033 - val_loss: 1.5173 - val_acc: 0.6910\n",
            "Epoch 95/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.4963 - acc: 0.7024 - val_loss: 1.5103 - val_acc: 0.6930\n",
            "Epoch 96/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.4901 - acc: 0.7028 - val_loss: 1.5053 - val_acc: 0.6960\n",
            "Epoch 97/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.4839 - acc: 0.7049 - val_loss: 1.5026 - val_acc: 0.6940\n",
            "Epoch 98/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.4779 - acc: 0.7039 - val_loss: 1.4925 - val_acc: 0.6920\n",
            "Epoch 99/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.4718 - acc: 0.7045 - val_loss: 1.4898 - val_acc: 0.6950\n",
            "Epoch 100/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.4660 - acc: 0.7044 - val_loss: 1.4835 - val_acc: 0.6920\n",
            "Epoch 101/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.4597 - acc: 0.7052 - val_loss: 1.4803 - val_acc: 0.6950\n",
            "Epoch 102/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.4551 - acc: 0.7045 - val_loss: 1.4690 - val_acc: 0.6970\n",
            "Epoch 103/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.4483 - acc: 0.7059 - val_loss: 1.4627 - val_acc: 0.6940\n",
            "Epoch 104/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.4428 - acc: 0.7068 - val_loss: 1.4600 - val_acc: 0.6900\n",
            "Epoch 105/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.4375 - acc: 0.7075 - val_loss: 1.4538 - val_acc: 0.7000\n",
            "Epoch 106/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.4319 - acc: 0.7059 - val_loss: 1.4487 - val_acc: 0.6960\n",
            "Epoch 107/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.4268 - acc: 0.7079 - val_loss: 1.4417 - val_acc: 0.6980\n",
            "Epoch 108/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.4215 - acc: 0.7088 - val_loss: 1.4399 - val_acc: 0.6930\n",
            "Epoch 109/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.4159 - acc: 0.7076 - val_loss: 1.4391 - val_acc: 0.6910\n",
            "Epoch 110/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.4109 - acc: 0.7085 - val_loss: 1.4323 - val_acc: 0.6930\n",
            "Epoch 111/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.4055 - acc: 0.7096 - val_loss: 1.4264 - val_acc: 0.6980\n",
            "Epoch 112/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.4006 - acc: 0.7073 - val_loss: 1.4169 - val_acc: 0.7000\n",
            "Epoch 113/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3952 - acc: 0.7091 - val_loss: 1.4116 - val_acc: 0.6940\n",
            "Epoch 114/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.3895 - acc: 0.7093 - val_loss: 1.4089 - val_acc: 0.6960\n",
            "Epoch 115/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3851 - acc: 0.7129 - val_loss: 1.4051 - val_acc: 0.6970\n",
            "Epoch 116/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3803 - acc: 0.7101 - val_loss: 1.4004 - val_acc: 0.6960\n",
            "Epoch 117/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3755 - acc: 0.7104 - val_loss: 1.3927 - val_acc: 0.6920\n",
            "Epoch 118/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3702 - acc: 0.7109 - val_loss: 1.3924 - val_acc: 0.7010\n",
            "Epoch 119/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.3663 - acc: 0.7119 - val_loss: 1.3957 - val_acc: 0.7010\n",
            "Epoch 120/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.3619 - acc: 0.7121 - val_loss: 1.3827 - val_acc: 0.6980\n",
            "Epoch 121/150\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 1.3566 - acc: 0.7131 - val_loss: 1.3811 - val_acc: 0.6930\n",
            "Epoch 122/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3522 - acc: 0.7148 - val_loss: 1.3725 - val_acc: 0.6970\n",
            "Epoch 123/150\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 1.3473 - acc: 0.7129 - val_loss: 1.3686 - val_acc: 0.6930\n",
            "Epoch 124/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.3436 - acc: 0.7115 - val_loss: 1.3650 - val_acc: 0.6930\n",
            "Epoch 125/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.3385 - acc: 0.7121 - val_loss: 1.3630 - val_acc: 0.6990\n",
            "Epoch 126/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.3347 - acc: 0.7136 - val_loss: 1.3610 - val_acc: 0.6980\n",
            "Epoch 127/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3305 - acc: 0.7144 - val_loss: 1.3512 - val_acc: 0.6970\n",
            "Epoch 128/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3260 - acc: 0.7136 - val_loss: 1.3459 - val_acc: 0.6960\n",
            "Epoch 129/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3217 - acc: 0.7143 - val_loss: 1.3502 - val_acc: 0.6970\n",
            "Epoch 130/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3179 - acc: 0.7129 - val_loss: 1.3418 - val_acc: 0.6940\n",
            "Epoch 131/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3133 - acc: 0.7152 - val_loss: 1.3353 - val_acc: 0.7000\n",
            "Epoch 132/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3093 - acc: 0.7156 - val_loss: 1.3315 - val_acc: 0.7020\n",
            "Epoch 133/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3050 - acc: 0.7153 - val_loss: 1.3282 - val_acc: 0.6990\n",
            "Epoch 134/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.3010 - acc: 0.7160 - val_loss: 1.3263 - val_acc: 0.7000\n",
            "Epoch 135/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.2971 - acc: 0.7155 - val_loss: 1.3216 - val_acc: 0.6980\n",
            "Epoch 136/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.2941 - acc: 0.7164 - val_loss: 1.3197 - val_acc: 0.7000\n",
            "Epoch 137/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.2898 - acc: 0.7173 - val_loss: 1.3154 - val_acc: 0.7000\n",
            "Epoch 138/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.2854 - acc: 0.7161 - val_loss: 1.3156 - val_acc: 0.6990\n",
            "Epoch 139/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.2830 - acc: 0.7181 - val_loss: 1.3182 - val_acc: 0.7010\n",
            "Epoch 140/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.2785 - acc: 0.7165 - val_loss: 1.3071 - val_acc: 0.7010\n",
            "Epoch 141/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.2752 - acc: 0.7191 - val_loss: 1.3052 - val_acc: 0.6990\n",
            "Epoch 142/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.2720 - acc: 0.7183 - val_loss: 1.2995 - val_acc: 0.7030\n",
            "Epoch 143/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.2680 - acc: 0.7203 - val_loss: 1.2961 - val_acc: 0.7010\n",
            "Epoch 144/150\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 1.2640 - acc: 0.7196 - val_loss: 1.2896 - val_acc: 0.6980\n",
            "Epoch 145/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.2607 - acc: 0.7193 - val_loss: 1.2875 - val_acc: 0.6990\n",
            "Epoch 146/150\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 1.2570 - acc: 0.7192 - val_loss: 1.2883 - val_acc: 0.7010\n",
            "Epoch 147/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.2540 - acc: 0.7189 - val_loss: 1.2801 - val_acc: 0.7010\n",
            "Epoch 148/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.2504 - acc: 0.7235 - val_loss: 1.2756 - val_acc: 0.7030\n",
            "Epoch 149/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.2476 - acc: 0.7205 - val_loss: 1.2744 - val_acc: 0.7020\n",
            "Epoch 150/150\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 1.2441 - acc: 0.7215 - val_loss: 1.2747 - val_acc: 0.6980\n"
          ]
        }
      ],
      "source": [
        "random.seed(123)\n",
        "L1_model = models.Sequential()\n",
        "\n",
        "# Add the input and first hidden layer\n",
        "L1_model.add(layers.Dense(50,\n",
        "                          activation='relu',\n",
        "                          kernel_regularizer=regularizers.l1(.005),\n",
        "                          input_shape=(2000,)))\n",
        "\n",
        "# Add a hidden layer\n",
        "L1_model.add(layers.Dense(25, activation='relu',\n",
        "                          kernel_regularizer=regularizers.l1(.005)))\n",
        "\n",
        "# Add an output layer\n",
        "L1_model.add(layers.Dense(7, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "L1_model.compile(optimizer='SGD', \n",
        "                 loss='categorical_crossentropy', \n",
        "                 metrics=['acc'])\n",
        "\n",
        "# Train the model \n",
        "L1_model_val = L1_model.fit(X_train_tokens, \n",
        "                            y_train_lb, \n",
        "                            epochs=150, \n",
        "                            batch_size=256, \n",
        "                            validation_data=(X_val_tokens, y_val_lb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAtdScGP6z6u"
      },
      "source": [
        "Plot the training as well as the validation accuracy for the L1 model: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "m8HR413g6z6u",
        "outputId": "9b14419a-3da7-4b62-a25e-c301fd3a443a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHwCAYAAACPE1g3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3xUZfb48c8zk957CARIKCkgPRRBmg1ERVEsiK7o2tuqq37RddW1bPvp6rqr7rJ2LLhYEBRwAQsIigSkd0IgIaT3PuX5/fFMGkkgwYSEcN6vV15kbj33zgw5c+bc5yqtNUIIIYQQQoiWsXR0AEIIIYQQQpxOJIEWQgghhBCiFSSBFkIIIYQQohUkgRZCCCGEEKIVJIEWQgghhBCiFSSBFkIIIYQQohUkgRbiNKWUWqaUurGtl+3MlFJzlFLf13tcqpTq05JlT2JfXeKcdXZKqX8ppX5/nPlPKaXeO5UxnWq/9BhPdA5/wXblPSBEM9w6OgAhziRKqdJ6D32AKsDheny71vr9lm5La31ReyzbWkqpEOAdYAJQBryktf5re+2vPq21X1tsRyn1FNBPa319vW232zkTdbTWd9T8rpSaBLyntY4+2e0ppTTQX2u9/5jpUcC/gSQgCojVWqee7H46k/rn8GTJe0CI1pEKtBCnkNbar+YHOAxcWm9abfKslDqdPtw+DHhhkpKBwNqODUccz2n22mpLTmA5cGVrV+zM50wpZe3oGIQ4E0kCLUQnoJSapJRKV0r9n1IqE3hLKRWslPpCKZWjlCpw/R5db51vlVK3uH6fo5T6Xin1vGvZg0qpi05y2Vil1GqlVIlSaqVS6pUTfL1sA7K11uVa6wKt9XETaKXUa0qp54+Z9rlS6kHX73OVUgdc+9+plJpxnG1ppVQ/1++hSqnFSqlipdRPQN9jlv27UirNNX+jUmq8a/pU4DHgGldLyJYmzplFKfW4UuqQUipbKfWuUirQNS/GFceNSqnDSqlcpdTvjhPzxUqpn11xpLkqf/Xnn6OUWqeUKnTNn+Oa7q2UesEVQ5HrOfSuee0cs41UpdT5rt+fUkp9rJR6TylVDMxRSo1SSv3g2sdRpdQ/lVIe9dYfqJRaoZTKV0plKaUeU0p1U0qVK6VC6y033PX6dD9m/15KqQqlVJjr8e+UUnalVIDr8TNKqZdcv7+tlHpWKeULLAO6u56HUqVUd9cmPVznvEQptUMpldTc+W2O1jpLa/0qsKEly7vO4f8ppbYCZUopN6XUmHrPzRZlKuY1yzf7vjnRc9TEvhcqpTJdz/NqpdTAevPedr2HliqlyoDJNefQNX9JvfNXqpRy1nsNdYr3gBBdgSTQQnQe3YAQoDdwG+b9+ZbrcS+gAvjncdYfDewBwoC/Am8opdRJLPsB8BMQCjwF3HCCuDcAs5RSvz7BcjU+xPyhVgBKqWDgQmCBa/4BYDwQCPwBeE+Zr99P5BWgElMJv9n1c2ycQzHn+ANgoVLKS2u9HPgj8JHrm4AhTWx7jutnMtAH8KPxc3EOEA+cBzyhlEpsJs4y4FdAEHAxcKdS6nIApVRvTBL5DyDcFe9m13rPAyOAsa5jeARTVW2Jy4CPXft8H9M29ADm+T/bFfNdrhj8gZWYam13oB+wSmudCXwLXF1vuzcAC7TWtvo701pXYs73RNekicAhYFy9x98ds04ZcBGQUe9bmQzX7OmY10cQsJjjvw/a0izMcxQERAJfAs9izv9DwCdKqXDXsq193xzPMqA/EAFswjxn9V0HPAf4Aw36/LXWl9b7lusqIBNY5ZrdWd4DQpz2JIEWovNwAk9qrau01hVa6zyt9Seuym4J5g/mxOOsf0hr/R+ttQPTkxyF+aPf4mWVUr2AkcATWutqrfX3mISlScpUf+cBk4C5SqmbXdM9lVLVNRWqY6wBNCZJBpgJ/FCTLGmtF2qtM7TWTq31R8A+YNRxjrvma+wrXXGXaa23u46rltb6Pdc5tWutXwA8MX/sW2I28DetdYrWuhR4FLhWNfxq/w+u520LsAVoKglBa/2t1nqb6/i2Yj5Q1Dyv1wErtdYfaq1trng3K6UsmA8Ev9FaH9FaO7TW67TWVS2M/wet9SLXPiu01hu11j+6zkUqpje4JoZLgEyt9Qta60qtdYnWer1r3jvA9VB7zmcB85vZ53fARNc5Ggy87HrshXmNrW5h7ADfa62Xul6v82nm3LaDl7XWaVrrCsxxL3XF4dRarwCSgWmtfd+ciNb6Tdd5r8Ik40OOeS99rrVe64qjsqltKKXiMM/X1VrrNNd2O8V7QIiuQBJoITqPnPp/DJVSPkqpf7u+Mi3GJBxBqvmex8yaX7TW5a5fm7vIrrlluwP59aYBpB0n5l8Di7XWqzFV5KddSfQYYIvWuujYFbTWGlNNnOWadB31KmxKqV8ppTa7viYvBM7CVEqPJxxzUXT9WA/VX0Ap9ZBSapfra/FCTIX7RNut0f2Y7R1y7a/+B5TMer+X08y5V0qNVkp9o0zrQxFwR704emIq8McKw/SZNzWvJRo8h0qpOGVagjJdr60/tiAGgM+BAUqpWOACoEhr/VMzy36H+WA1HNgGrMAk6WOA/VrrvFbEf+y59VKnpi+5/nnrDVxV87p0vYbOwXz4bO37pllKKatS6s/KtDEVA6muWfVfq8fdtivZ/hx43JXM10zvFO8BIboCSaCF6Dz0MY9/i6kOjdZaB2BGuQBori2jLRwFQpRSPvWm9TzO8m6AO4DW+iAwFfgL8Lrr3+Z8CMx0tSyMBj6B2haG/wD3AKFa6yBgOyc+5hzAfkysvWp+cfV6PoJpPwh2bbeo3naPPffHysAkUPW3bQeyTrBeUz7AVCd7aq0DgX/ViyONY3q3XXIx7SlNzSvDjOgC1FaGw49Z5tjjew3YjRmtIgDT/1o/hiaHBnR9wPsvphp7A81XnwHWYV6/M4DvtNY7MedtGse0bxwnzo5WP540YL7WOqjej6/W+s+c+H3TkueoxnWYlpvzMQluTM1qzcTVgOvbig+Ab7TW8+pN70zvASFOe5JAC9F5+WP6nguVGSruyfbeodb6EOZr6aeUUh5KqbOBS4+zyqeYfubLXUlBMear276YClRz+/kZkxS+DnyltS50zfLF/CHPAVBK3YSpQJ8obocrlqdclfsBQP3xa/0xf+xzADel1BNAQL35WUCMK/loyofAA8pcKOZHXb+o/USxNcEfU62sVEqNwiRMNd4HzldKXa3MRWuhSqmhWmsn8CbwN6VUd1eV8myllCewF1ORvViZi/kex3w1f6IYioFSpVQCcGe9eV8AUUqp+12tOP5KqdH15r+L6YWdznESaFc1diNwN3UJ8zpMxb25BDoLCG2m9ac1PJS5kLHmxwrm4kbqzo2n63FLvQdcqpSa4jr/XspcHBjdgvdNa54jf8zwlnmYpPuPrYgRTKuXL/CbJrbbWd4DQpz2JIEWovN6CfDGJJo/Yi7qOhVmYy4sy8NcMPUR5g96I1rrHzAJ4JOYatZqzIVmM4EPlVLDjrOfDzBVtg/qbW8n8ALwA+YP+iBaPizePZivjDOBtzEXYNb4CnP+9mK+eq6k4dfgC13/5imlNjWx7TcxyeJq4KBr/XtbGNex7sK0upQAT2AqugBorQ9jKrS/BfIxFxDW9JE+hGmF2OCa9xfA4mqTuQvzYeQIptrZYMSHJjyEed5KMBX/j+rFUIJpz7gUcy73YS4cq5m/FtOvv8mVOB7Pd5hvKH6q99ifZvqftda7MYlaiqtNontTy7XADsyHz5qfm1zTK4Casdh3ux63iKuP+DJMtT4H8/p5mLq/o82+b1r5HL2LeY0eAXZi3vutMQvTJlOg6kbimE3neg8IcdpTph1RCCGappT6CNittW73Crg4PSilvgY+0Fq/3tGxdFbyvhGia5MKtBCiAaXUSKVUX2XGfZ2Kqbot6ui4ROeglBqJuTDwoxMteyaR940QZ5ZOe3clIUSH6YbpJw7FfM18p6tnWZzhlFLvAJdjhtMr6eh4Ohl53whxBpEWDiGEEEIIIVpBWjiEEEIIIYRoBUmghRBCCCGEaIXTrgc6LCxMx8TEdHQYQgghhBCii9u4cWOu1rrRjY9OuwQ6JiaG5OTkjg5DCCGEEEJ0cUqpJse7lxYOIYQQQgghWkESaCGEEEIIIVpBEmghhBBCCCFa4bTrgW6KzWYjPT2dysrKjg5FtAMvLy+io6Nxd3fv6FCEEEIIIbpGAp2eno6/vz8xMTEopTo6HNGGtNbk5eWRnp5ObGxsR4cjhBBCCNE1WjgqKysJDQ2V5LkLUkoRGhoq3y4IIYQQotPoEgk0IMlzFybPrRBCCCE6ky6TQHekvLw8hg4dytChQ+nWrRs9evSofVxdXX3cdZOTk7nvvvtOuI+xY8e2Vbhtzs/Pr9G01atXM3z4cNzc3Pj44487ICohhBBCiPbRJXqgO1poaCibN28G4KmnnsLPz4+HHnqodr7dbsfNrelTnZSURFJS0gn3sW7durYJ9hTp1asXb7/9Ns8//3xHhyKEEEII0aakAt1O5syZwx133MHo0aN55JFH+Omnnzj77LMZNmwYY8eOZc+ePQB8++23XHLJJYBJvm+++WYmTZpEnz59ePnll2u3V1Pl/fbbb5k0aRIzZ84kISGB2bNno7UGYOnSpSQkJDBixAjuu+++2u3Wl5qayvjx4xk+fDjDhw9vkJj/5S9/YdCgQQwZMoS5c+cCsH//fs4//3yGDBnC8OHDOXDgQIuOPyYmhsGDB2OxyEtMCCGEEF1Ll6tA/2HJDnZmFLfpNgd0D+DJSwe2er309HTWrVuH1WqluLiYNWvW4ObmxsqVK3nsscf45JNPGq2ze/duvvnmG0pKSoiPj+fOO+9sNHzbzz//zI4dO+jevTvjxo1j7dq1JCUlcfvtt7N69WpiY2OZNWtWkzFFRESwYsUKvLy82LdvH7NmzSI5OZlly5bx+eefs379enx8fMjPzwdg9uzZzJ07lxkzZlBZWYnT6Wz1eRBCCCGE6Eq6XALdmVx11VVYrVYAioqKuPHGG9m3bx9KKWw2W5PrXHzxxXh6euLp6UlERARZWVlER0c3WGbUqFG104YOHUpqaip+fn706dOndqi3WbNmMW/evEbbt9ls3HPPPWzevBmr1crevXsBWLlyJTfddBM+Pj4AhISEUFJSwpEjR5gxYwZgxmMWQgghhDjTdbkE+mQqxe3F19e39vff//73TJ48mc8++4zU1FQmTZrU5Dqenp61v1utVux2+0kt05wXX3yRyMhItmzZgtPplKRYCCGEEKKVpEH1FCkqKqJHjx4AvP32222+/fj4eFJSUkhNTQXgo48+ajaOqKgoLBYL8+fPx+FwAHDBBRfw1ltvUV5eDkB+fj7+/v5ER0ezaNEiAKqqqmrnCyGEEEKcqSSBPkUeeeQRHn30UYYNG9aqinFLeXt78+qrrzJ16lRGjBiBv78/gYGBjZa76667eOeddxgyZAi7d++urZJPnTqV6dOnk5SUxNChQ2tHz5g/fz4vv/wygwcPZuzYsWRmZjbaZnl5OdHR0bU/f/vb39iwYQPR0dEsXLiQ22+/nYEDO883A0IIIYQQv4SqGcHhdJGUlKSTk5MbTNu1axeJiYkdFFHnUVpaip+fH1pr7r77bvr3788DDzzQ0WG1CXmOhRBCCHGqKaU2aq0bjTcsFegu5D//+Q9Dhw5l4MCBFBUVcfvtt3d0SEIIIYQQXU6Xu4jwTPbAAw90mYqzEEIIIbq2lJxSHvjvFo4WVjBnXAzXj+lNgJf7iVfsBCSBFkIIIYQQp4zWmo83pvPk4h14ulkY0D2Avy7fw2vfHOCGs3tzXmIk6QXlpOSUcTC3jNzSKj64dUxHh92AJNBCCCGEEAKtNekFFYT4euDrWZciVlQ7WL0vh+XbM1mzLwdPNyvdAr3MT4AX/l5ueLlb8XKzmH/drXi5W/B0t+LlZn739jC/Wy2K5/+3h883ZzA6NoS/XzuMboFebD9SxGvfHuC17w7w6rfmrsdKQY8gb/qE+1Fld+DpZu2oU9OIJNBCCCGEEF2A1hqtwWJRjeaVVtn5enc2B7JLGd47mJExwfh4mDSwqNzGJ5vSeX/9IQ7klAEQ4utBz2BvAn082HAwnwqbgyAfdybFhWNRiqNFlezKKObrXdlU2BytitOi4MEL4rh7cj+srljP6hHIK7OHczC3jL1ZJcSG+dIrxAcv986TNNcnCbQQQgghRCdTbXeSXVKJm8VCiK8HHm514z6UVNpIzS0nJbe0ts0hJbeUgzll2J2ahKgAzuoewMDugbhZFF/tyGTN/lyq7c7abbhbFUN7BhEZ4MXKXVlU2pwM7RnEU5cOoNzmIL2ggrT8crKLK7lyRA8uOiuKUbEhuFsbjz/hcGqq7A4qbU4qbQ7Xj5NKu/m9yuakot70wdGBnNWj8VC7ALFhvsSG+TY5rzORBLoNTJ48mblz5zJlypTaaS+99BJ79uzhtddea3KdSZMm8fzzz5OUlMS0adP44IMPCAoKarDMU089hZ+fHw899FCz+160aBFxcXEMGDAAgCeeeIIJEyZw/vnnt8GRtS0/Pz9KS0sbTFu9ejX3338/W7duZcGCBcycObODohNCCNFVlFbZ2ZCaT4iPB4N6BDZZkW2tKruDsioHwT7uKNX09rTWTc5zODXf78/lqx2ZZBdXUVxho6jCRkmlDatV4ePuhreHFW93K8WVNrKKK8ktrW6wDX8vN8L8PCmrspNdUlU7XSmIDvYmNsyPpN4hWC2KnRnFLN6SwfvrDwOmDeKGMb2ZelY3EqMC2HSogHUH8vjhQC7f789lxrBoZo/u1WxSeyJWi8LHww0fj5Na/bQkCXQbmDVrFgsWLGiQQC9YsIC//vWvLVp/6dKlJ73vRYsWcckll9Qm0E8//fRJb6sj9OrVi7fffrv2xi1CCCG6HqdTU2l31LYMtLWSShsHcspYdyCX1Xtz2HioAJvD3Oci3N+Tc+MjOC8xgnH9whr09jbF7nCy82gxPx3MZ+fRYtLzKzicX05WSSVag7e7lehgb3qG+BDi60FuaRWZRZVkFldSUmknLtKfoT2DGNYziJ4hPny9O4tFmzPIKanC39ON6BAfAr3d6B3qg7+XOw6nk/JqBxU2B+XVDiL8PRkcHUhkgOkvdmrIK60ir6ya3NIqvNyt9An3pU+YH33Cm29z0FqTll9Buc1OfKR/g8R+Qlw4E+LC2/ZJOMNIAt0GZs6cyeOPP051dTUeHh6kpqaSkZHB+PHjufPOO9mwYQMVFRXMnDmTP/zhD43Wj4mJITk5mbCwMJ577jneeecdIiIi6NmzJyNGjADMGM/z5s2jurqafv36MX/+fDZv3szixYv57rvvePbZZ/nkk0945plnuOSSS5g5cyarVq3ioYcewm63M3LkSF577TU8PT2JiYnhxhtvZMmSJdhsNhYuXEhCQkKDmFJTU7nhhhsoKzO9UP/85z8ZO3YsAH/5y1947733sFgsXHTRRfz5z39m//793HHHHeTk5GC1Wlm4cCF9+/Y94bmLiYkBwGKRIcmFEKIrWncgl6eX7GRfdinTBkVx6/hYBkcHnXhFTDKbXlDBwdwyDuWVUVJpp9zmoKLaQWmVnbT8clJyy8ipV5FNjArg5nNiGd8vnOySSlbtzmbptqN8lJyG1aIYEBXAyJgQRsYEE+rnSWZxJVlFlRwtqmRvVgmbDhdQXm16eiMDPOkd4svYfqH0DPYhwNudIwUVpBWUk5Zfzo6MIsL9PYkO9mZE72D8PN3YebSYL7Zm8OFPpvrrblVMio/gyuE9mJwQccouhFNK0SvU55Ts60zU9RLoZXMhc1vbbrPbILjoz83ODgkJYdSoUSxbtozLLruMBQsWcPXVV6OU4rnnniMkJASHw8F5553H1q1bGTx4cJPb2bhxIwsWLGDz5s3Y7XaGDx9em0BfccUV3HrrrQA8/vjjvPHGG9x7771Mnz69NmGur7Kykjlz5rBq1Sri4uL41a9+xWuvvcb9998PQFhYGJs2beLVV1/l+eef5/XXX2+wfkREBCtWrMDLy4t9+/Yxa9YskpOTWbZsGZ9//jnr16/Hx8eH/Px8AGbPns3cuXOZMWMGlZWVOJ1OhBBCnLnS8sv549JdLNueSY8gb2aN6snnP2ewZEsGo2JDuDqpJ24WRXm1g/JqO2VVDvLLqsgtqyavtIrskirS8strK8k13K0Kb3crPh5uRAd7MykunD7hfsSG+TK8VxARAV4Nlr9ieDTVdifJqfn8kJLHhtR83l9/iDfXHmywnI+HlZhQX64aEc3I2BCSeofQLbDhtlrK6dQczCvjQHYpSTEhhPieQb0NZ4iul0B3kJo2jpoE+o033gDgv//9L/PmzcNut3P06FF27tzZbAK9Zs0aZsyYgY+P+cQ4ffr02nnbt2/n8ccfp7CwkNLS0gbtIk3Zs2cPsbGxxMXFAXDjjTfyyiuv1CbQV1xxBQAjRozg008/bbS+zWbjnnvuYfPmzVitVvbu3QvAypUruemmm2pjDAkJoaSkhCNHjjBjxgwAvLxO7j8cIYQQ7cfp1GQWV5KSU0ZaQTlRgV6c1SOQMD/P2mW01uSUVrE/u7TBT0pOGd0CvZgxrAeXDulemxA6nZqdR4v5bm8OKTllVNjsroTYwea0QqxK8dsL4rh1Qh+83K3839QEPtqQxltrU3lo4ZZGMQZ6uxPq50GYryfxkf5cOKCbq13Bl5gwXwK93Zu8iO1EPNwsjO0Xxth+YYC5QG97RhGllXaiAr2IDPTC39Ot2d7m1rJYFH3D/egb7tcm2xOdT9dLoI9TKW5Pl112GQ888ACbNm2ivLycESNGcPDgQZ5//nk2bNhAcHAwc+bMobKy8qS2P2fOHBYtWsSQIUN4++23+fbbb39RvJ6e5j9Mq9WK3W5vNP/FF18kMjKSLVu24HQ6JSkWQohOwuZwklFYwdGiytre27IqO8N6BTEyJgR/153ctNbsyCjmqx2ZfLMnm/3ZpVTaGn87GBngSWJUAMUVNvZnl1JcWfc3wc/Tjb4RfoztG8quzBKeXLyDZ77YyaT4cPy93FmzL6f2YreoQC98PExl2NvDypXDo7nvvH5EBXrXbs/fy51bxvfhxrExHMgpxcNqqV3ex8N6UsnxyfBwszC8V/Ap2ZfomrpeAt1B/Pz8mDx5MjfffDOzZs0CoLi4GF9fXwIDA8nKymLZsmVMmjSp2W1MmDCBOXPm8Oijj2K321myZAm33347ACUlJURFRWGz2Xj//ffp0aMHAP7+/pSUlDTaVnx8PKmpqezfv7+2Z3rixIktPp6ioiKio6OxWCy88847OBymH+yCCy7g6aefZvbs2bUtHCEhIURHR7No0SIuv/xyqqqqcDgctVVqIYQQzbM7nDi0btQbW9MGsPlwIbuOFpOSa4YrO5xfjsPZsK1BKdDajIYwqEcg8ZH+rEvJJS2/AouCkTEhXD+6N7HhZoiwnsE+pBdUsCOjiB0ZxezOLCHQ243pQ7vTL9yPfhH+9IvwIzLAs0FVdtfRYj77+Qifbz6CzaEZ3z+MiXHhnNM/jAj/lhda3K0WEroF/LITJ0QHatcEWik1Ffg7YAVe11r/+Zj5LwKTXQ99gAitdcuuLOiEZs2axYwZM1iwYAEAQ4YMYdiwYSQkJNCzZ0/GjRt33PWHDx/ONddcw5AhQ4iIiGDkyJG185555hlGjx5NeHg4o0ePrk2ar732Wm699VZefvllPv7449rlvby8eOutt7jqqqtqLyK84447Wnwsd911F1deeSXvvvsuU6dOxdfXjMk4depUNm/eTFJSEh4eHkybNo0//vGPzJ8/n9tvv50nnngCd3d3Fi5cSJ8+fRpss7y8nOjo6NrHDz74IOPHj2fGjBkUFBSwZMkSnnzySXbs2NHiOIUQoqPsySxhyZYMVu7Kwt/Ljf6R/sRH+tM/0g+nE44WVZBVbCrE1XYn7laL60dRVGEjLd9cjHa0qBKHUxPq60FkgBdRgV5UO5xsSSusrQZ7uVuICfUlMcqfiwdF0TvUh6hA79q7wblZVO3QZOsO5PLF1gxGxoZwz+R+nJ8YSWi9No0aPUN8OLtvaKuOOTEqgMSoAB6bltjskG1CnAmU1vrES53MhpWyAnuBC4B0YAMwS2u9s5nl7wWGaa1vPt52k5KSdHJycoNpu3btIjExsU3iFp2TPMdCiPaitWZ/dikbUgvYkJrP3qwSogK96VtTrQ3xodrupLjSjN2bVVzJip1Z7M0qxaJgdGwoDqdmd2Zxg/aHGsE+7ni6WbE7nVTbndgcGj8vN3q6hkLrGeyDu9ViRoMoNqNBKGBIz0CG9gxiaM9g+kX41d6xTYhTpiAVNr4NEQMhbgp4tfG3Brn7YddiKMuFsP4QHg9h8eDbug927UkptVFrnXTs9PasQI8C9mutU1wBLAAuA5pMoIFZwJPtGI8QQoguRGvNwdwyjhRWYHM4qbZr7K4RgHw8rHi7u+HjYcVqUbU3riiutJFfZnMlqhVkFldxKK+MwnIbAGF+HiRGBXAor4zVe3OodjQ9otComBCeuWwgU8+KItzfszae7JIq9mWV4m5VdAv0IjLAq9PeirhT0xoO/wCVRXXTLO7Qeyx4nObtgfYqSPkOdn1u/o0eCeN/C93Oav99l2RBxs9AveKpuzf0HG3+reF0wPp/wdfPgq3cTLN6QJ9JkHgpDLwCPFtwgaTTCUc3Q2lW3TStTQy7lkDOLjPNzRvsFXXLhCfAxX+DmON/c9+R2jOB7gGk1XucDoxuakGlVG8gFvi6HeMRQgjRiZVW2dmZUUy3AC96hng3ag/QWrMvu5T1KXn8eDCfnw7mNxj/tzX8vdzoFmDaH6YO7MbwXsEkxQQTG+Zbu1+HU5NRaNosvNytBHq7E+DlToC3W5Nj+SqliAwwSfMpVXgY1v8bRt0Gwb3bd19aQ8Ym2LPMVAoHX9U++/nhFfjf7xpP9wmDsfdA0q/bvhra3ioKYfmjJnGsLgHPAOg9DvatgB2fQvw0k0j7RULuHsjZC3n7IKA7JE431dkaWkPmVtj1BRQ0HI4PDz8Ii4PwOPMcaQfs/igjY5UAACAASURBVBJ2Loa09TRInmu4+0LchSY5DuoNyx6BIxuh/xS4+HkoyYSdn5vY9/0PVjwBY+4yrznvYzpvHXbz4WfXEvNTktF4f8pijj3pr5BwCfhHQVEa5O6FnN3w0zx4exok3QznPwVeJ3eHxPbUni0cM4GpWutbXI9vAEZrre9pYtn/A6K11vc2s63bgNsAevXqNeLQoUMN5svX+12fPMdCdD05JVV8vTuLjYcK2JxWyL7sUmr+JPUI8mZs31DG9AmlpNLGjyn5/JSaT35Z3YgPo2NDGN0nlH4RfrW9xe5WC06tqag2N9sor3bg1JoAb3eTAHu7E+TtfsK70Z02tIZ3p8PB1SYJOu/3Jqmx1EvwK4shazv0SAK3kxyPOHMb/Py+SYiK0+umT34cJj78y47hWNm74N8Toe9kmDS3bnpZHvz4KhxYZRKq0XfA2HvB0/+X79NeBZ/fDftXQmj/uuQzPN4ko0G94Zfc8KssD+Zfbo5tyLUw4DKInQBunlBRAOvnmWOrLGy4nldgXRU+LM4k0vZK8zwUHjKJaFAv82+NigLzc6zIQSZB7jPR7LdGaQ7sWQq7v4CyHDPNJxQu+iucdaW5QrWG1pC+Ab5/0azj4Q8jbwavIFfyu8f8W10Kbl7Q73yzz7C4htsJ7Am+Yc2fr+oy+OaP5pz4dYOLX4CEaS07122suRaO9kygzwae0lpPcT1+FEBr/acmlv0ZuFtrve5E222uBzohIUEuZuiitNbs3r1bEmghThNVdgeH88wd4o4UVODv5UaYnyehfh54u1tZsy+X5dsz2XAoH61Nj/CQnkEM7RnEoB6BZBRWsO5AHj+k5NW2VkQHezM6NpTRfUIYExvaZIX6tKe1SVR3LTFJ0qhbTXJ0PFs+gs9ug4n/B0c2wf4VJlGe8pxJZHYtgZRvwVFtvqa/+l3w79a6mDa8DsvngrJCv/NMQtT/Qvjqd7B1gamanvv7hgkSmMQsd09dUlVRCKH96pLTkD6NE3p7Nbx+LhQfhbt+BL8mbjd9ZCOs+ZtJ+MIT4NoPIPSYO99WFsGaF8z+hl5//OTXVgEfXW+S54FXmCQyZw+UZdct4+ZVl1iHJ7gqvPGmWpyf4jrGPVCeB0NmmepqzfkozYZ3LzPLXfMe9L+g6TiqSmDrR4Cq1wscBiVHTQV512JIXWuS5b6TzfMQP61xIqq16SmuOfeOatO/HNKnyd3WcjpMhTpzG5w188R9yJnbzDnesQjQpopcc156j4V+F7SszeN40jfC4ntNL/b9W4+fdLeTjkig3TAXEZ4HHMFcRHid1nrHMcslAMuBWN2CYJpKoA8ePIi/vz+hoaFd7z/UM5zWmry8PEpKSoiNje3ocIQ4Yzmcmn3ZJaTmllFld2J3mH7j8mpHg1shZxRVcKSgAmcT/5tbcDLBspUS7Y0Kj2fcoP5MGdiNxCj/Jv/vdjo1e7NL8PN0Izq4jfpeq8tg73LzNXMNr0CTEJ6owlicAev+AZvfr6sGJl4KIcf5v0lrk/B5BzdO8mpkbjeJ6K4lJlFQlrqK4uBr4ZwHIKxf4/XK8+GfIyE4Bn69wiRs2z6G5f9nEjkwCXjidPPvyqfMsV7zHkQ3ygcas1fBl7+Fn+ebr/Kv+Lc5jhpOJ3z5gLnIbMzdcOGzkLnFtArsWmLaD2q4+5qv+ouP1E3zDIDzn4QRN9ed+1VPm6Ts2g8g4eLjx5fyHSycY1oUrnwT+p9vpu/+0sRdctQ87n0OTH+56fNfVQofXgup38Olf4cRNzY8v/WrqjVJcuHhpuOxuJs+4qpi6DkGJjwEEQNM8lx8BGYtMNXfX6KiwHyQ6UztK6XZpqLdXm0WDhsc3QrRI9pn+ydwyhNo106nAS9hhrF7U2v9nFLqaSBZa73YtcxTgJfWem7zW6rTVAJts9lIT08/6ZuUiM7Ny8uL6Oho3N3dOzoUIbqcimoHuzKL2ZFRzI4jRRSUV7v6fE3Lg7mjXAHb0osoq3Y0uQ0Pq4XIQE9XT7E3sWHmznGxYb5EB3tTVuWgNG0LPVY/TGD+troVfSNMIurhWzfNYjW9lbHj2/5gtYYPrjY9nMeKHgXT/wERCY3nFaTC9y+ZxNnpgMRLzLSjrjvpdRtUl0yHJ9QNyrz3K1j9/+BIMqDM1/bjfwtRrrvRpm2ANc+bhN7iXneBVsLFpgK97h8mOXVUm4rghc+Cf2RdXIvvg5/fg9u/MzHUKMsz1coew6Hb4LpKaOZ2WHCdSSwv/hsMv6H5c1WcAR/dYGKf8DBMeqzpDxham+r0+n+BdwhU5JsEL+YcU2mNSDSV1IAeZv2qUpNY5+w15/Pgd9BrrElwKwrgzSkw5Dq4/JXmY2vw3ByCBbNNi8qkuZC90/TqRp4Fl75spv/v9+Z8TpoLI2+p+3BiKzfHmP4TXP4vGHJNy/ZZXV53DKWZprIbFm8+yDht5jn5/iXT6mL1NBffXf8x9BrTsu2LTqVDEuj20FQCLYQQZyqnU3OksIL92aUcyCnFolRt8uvv5cbRogp2HClme0YROzOKKamym35hi8LdzUJxha22Whzs4064vycllXaKKmyUVztwtyoSowJcw6kFERfpj5e7FQ+rBTerwsvdSrCPe/Pf/tmrTBL5/YumQnXhs6a/Msf19XLefpPc1Cg5CrZKuO2b5iu2J2vj27DkN3DekyaZrXH4R3PBWnUZjH/IVHzLss0FWruWwOF1YHGDYdfDuN+YRAlMEl2zTM3FWaH9TLX24GrI2mYqv2PvM8f1039MdbL/FHBUmdYK72DzgWHkLeAT0jjm0mz44Z/w47/A3QsufM7EkbbeJJtj7zXntKXK803V9uB3dT2xiZeaRLe61Hy42LUE9ro+ZMz4FwyYfvxtag1r/26S7bippq2gqWNpar3NH8BXj5k2Cu8gU8m8Y23rKqzV5bD4Htj+iUlYJz5inierq+hSkglLHzLHdSyLG1z5Bgy8vOX7awl7tWnH2PGp6RPvoOqp+OUkgRZCiNNYzZBtezJL2J9dyv6cUvZllZKS2/TtmevzdLOQEBXAwO4BhPp6YHNobA4nNoeTYB8PBnYPYGCPQLoHejVIhG0OJ1qb2x63mtNpqqDfuHpxB18LU/544r7KgkMwb6KpWP56RfNDltmrTZK6+wuThI5/8PgXk+WnwGvnmNaFGxY1rqaW5pjWh+2fmAS/pgUiYoBJMEfMMaMhNKck08SyawkcXGOqkuN/C4Nm1iVyFYUmif7xFVOVPPseM8pAS/pEc/eZivPhdebis9Jsk/Dfvb5hBb8lHHZIftMca03iH9TLDHHmqALfcDMywpg7G4780F5Kssy53/0l3PCZqV63ltZ1leem2l0A9q00Fer6eo2BnqNavz9xxpAEWgghTjNVdgc/puTz9a4sVu7K5khh3TipPYK86Rfh1+Cnb7gfCmpv+FFcYSfc35O+4b64WU8iCc5Pgezd5gIkSwvHMnbYYfvHpo81d6+pyE79S11/akvsWwnvzzSjFVz+Wl0LgtawfxVs+y/sWQ5VRaa31lZuEu5LXjRDcR3L6YC3ppkREO5aB4HRjZepsWe56fmNToKES5tPxo7HVmEqoc31VDvs5phaek5rOJ2w6W1Y8aSpZM9aAPEXtT6++koyTeK6f6WprCdONwlla2NrC7aKhmMRC9EJSAIthBCdlNaaH1LyWLrtKNnFVeSVVZNXWkVmcSWVNide7hbO6RfOuQkRDOoRSN8IX3w82nkYtj3L4dNbTaIW0te0NQy+xoyaoLUZ8WHXYjOkla5XAS9MM72fEQNhwm9hwOUnl4x9+2f49k+mV3fETWZfa14wY996B0P8xa4huSaZaZ/fYy7wGnSVaXOo3yu85m+w6g8wY17L+1w7s+IM08/c1IcFIUSbkgRaCCE6GZvDydJtR5m3OoUdGcX4ebrRI8ibUD8PQv08ifD3ZFy/UMb2DWv93ewcNlNZdNjM0Fuh/Vt2Bzen0ySq3zxnLkwbcyf8+JpJUgN7muGz9q8yowpY3KD7cNObW8PdF4b/yvTC/pJxc51Oc8FfyrdmlIvcvSaRH/8gDLq6ieHPqkyivOYFcyFXzZBaoX1h03wzhuxV7zQeak0IIY5DEmghhOggReU25v+Yytr9eeh6dwFLzS0ns7iSvuG+3DK+DzOG9WhZopyfUje+b3iCqcT2HG0qvbZKM7rB2peOGW5LQVDPuptD1Iwz6xdu5oFpdVj1lNn24GvMsF7u3qbivG+FGTHi6Bbo6xoLOG5Kyy4WO1nl+fDGBaZfePxvYeCME1ezc/aYDw71hx/zCoI71rRvrEKILkkSaCGEaAd2h5OvdmTx5tqD5JVWMa5fGBPjwhnbL4zyKjtvfH+Q9348RFm1g8HRgQ0S5AAvd2aN6snk+AgslmMqo0VHzBX89nq3qq4uNf3BWa6h4MLizEV3jiozJFzfc01SXZoJ0SPNiBJBvepuC1x7U4t9Zp2mKIsZ1WHMXU1Xa7U+tVVcp/OXVbK1Ni0mHdHTK4Q47TWXQHeRe5kKIUQbqyw21Vdr4/HHtdbkl1WzeEsGb649SFp+Bb1CfOgf4cdnPx/hg/Wp/MZtEYMsB9lqv4jzzjqPOyb1Y0B319Bc5fmmLeLwD5AzCcKmmzYLMNXl718yw3s5bcfsWZlRA6b80YySENzb3L2sZuixPcvMGMNXzDMjNdQkupEDGm7G6TC3Ac7Z2/iWvxGJ0H1o8+flVLdA/JLkGUy8SpJnIUTbkgq0EELUl7sfvn8RvXUBTp8IUuJuZrX/RezMcZBeYFouMosqqbKbC+dG9A7m1vGxXDCgG1aLorq0gNIPbybkyNdUWXzwdJab9ooJD5ue4h/+CRveBFuZaaHI3WP2GxYPYf1NEmxxMze5GHsv+NcbOk1ZwCp1DyGEOFWkAi2EEM04nFfO2nXfEb9vHkOLv8WGG5/pycQWpzF607ME6ZepsE4nIqAf8d5H6eOdRrfqNLz8QwgYNgNi+oFFQc5ePBbMIqQgFaY9j+ew681dydb+3QzLhjIV0bNmmovhIhLNiAq7vjCjTBz+wVy0N/Ze8O/W0adFCCFEM6QCLYQ4I1XaHCzfnsmGtSuZmPUOF1o3Uo4XX/lcwvrIWfiEdCc2zIcRajf99/wL94Pf1K3s181Ui4vSoeAgprXibMjcZkakuOodiBlXt7y92oxdnLvPjFDR1nfYE0II0S7kIkIhRNdjqzBDqu1aAlk7TN9v4qUNbgSx/UgRn6zdzu6dW3HY63qK/XUJN1qWMcG6jUq3AGxJt+I/4Z7mR2rI2mHu/BYWZ245DOYCtawdZv81d8Sb8a/j36hDCCHEaUMSaCFE11BZ7LpobjHOvf/DYq+gzBrAAUtvEm27ccdGuUcoWSGjKMk7Qrfqw0SowiY3Ve0Vitu4+7CM+vXxbwMthBDijCQ90EKI04bTqTmYV8a+rBL2ZJZyOOMosTmrGFO1liHVP+OOnTwVzFLbOJY5R7HPcxBxUSGUFxfSp3AtkyvWM/LoD1S6RVDUYwL+cUPxjowHt3o3/LBY8Og5pmU3FxFCCCHqkQRaCNEpaK35Oa2QJVsy+HLrUbJLqgimmJvdlvMHt//hRzk51khW+F1Gss85ZPidxcg+4fy+byjxkf614yhrPYX8smoKK2wkhPmi5M5zQggh2pgk0EKIU2rT4QL+vHQ3B/PKCPByI9DbnQBvd/Znl5JeUIGHm4XL+li4Jfor+qUtxGovN33N4+4nvMcIpinFtONsXylFqJ8noX6ep+yYhBBCnFkkgRZCtLmCsmocWhPq44Y6shH2fkWhf3+eTonn080ZRPh7cm58BKVVdooqbOSVVtM/wo/fjfXjvIIP8djyvrmJyKCr4JwHISKhow9JCCGEqCUJtBCi5cry4MdXYcsCOP9JGHx1o0U+33yE+R9/wqWsZqpbMpGYO90FAZc5hxI/9imunzIeX0/Xfz81I1msfw2+WQAoGHodnHM/hPQ5dccmhBBCtJAk0EKIEyvJhHX/gOQ3zdBxAT1g0Z3gGwZ9zwXMhX8vrdpHxrev81/3/+C0eLDXfxSfWM9mcdlAbg74iZmFbzJx22yIeAKiR5qbh+xaAvkHzAV+I28xNxGRYeCEEEJ0YjKMnRDi+Da9C0sfBodpqag6+zdsK/LmrP/NwrP0MOqmZVSEnsVDC7cQtHM+z7m/iTN2MpZr5zceGq7wMHzxAOxfaR5b3CBmPAyYDonTTUIuhBBCdBIyDrQQonXs1fDVo7DhdWy9J/J1v7ksOuTJd3tzKK92EEEBn3k+gYdycIvbnxhRuY4n3Oaj46agrnrX3JGvKVrDnmVQVQz9L2z+xiVCCCFEB5MEWgjRtOoyOLgaArpDaH8zLnJpDlUfzMYzYz1f+M3kwfzLqXZaiAzw5PzESCbHR1DtcFKStp3pG+dg024EOAtNFfnKN8DNo6OPSgghhPjF5EYqQojGKgpxzL8Ca8ZGADSKPLdIrI5KvJ1l3Ge7m12WKdw6MZILB3RjUI/A2vGWARgUBQMX4j3/Chh4NVz+GljlvxUhhBBdm/ylE+IMVV2cQ8l/LsG/ZD9zbbdRpr2IdzvKQJ1JmGclBwbdzwOjJxMb5nv8DfUeCw/vBw9fkJuWCCGEOANIAi1EF1dWZSe/rLrBtB179xL31Q10dx7lhdCnuOLi60iM8ifQ2732zn1DW7MTT7+2C1gIIYTo5CSBFqILcTo1izYf4evd2aQVVJCeX07eMclzJPl84PEcUZYCdp/7BnMnTJfbXQshhBCtIAm0EF3E+pQ8nvlyJ9uPFNMjyJs+4b5cOLAbPUO8CfPzRAEWRxWT1/2KgLJiLNcvYmjM2R0dthBCCHHakQRaiNNcWn45f1q2i6XbMokK9OKla4YyfUj3hhf71VjyGyjaAde8D5I8CyGEECdFEmghTlMllTb++c1+3vo+FatF8eAFcdw6vg/eHtamV/j5fdj4Noy7HxIvOaWxCiGEEF2JJNBCdHIHc8s4WlRBmJ8nob4eBHi78/HGdF743x5yS6u5cng0D0+Jp1tgMzcuATi6Fb580Nz179zfn7rghRBCiC5IEmghOrHVe3O45Z1kqh3ORvNGxgTz5pyRDI4OOv5GKgrgo+vBOwRmviXjNAshhBC/kPwlFaKT+ulgPrfNT6ZfhB+PTUukoLyavNIq8sqqGdg9gCkDu5149IzCNPhoNhRnwE1LwS/81AQvhBBCdGGSQAvRgcqr7cz9ZBvx3fy5dmRPQv08AdiSVsjNb2+gR5A38389qnZ6q6R+D/+9EexVcM170HNUG0cvhBBCnJkkgRaiA/11+R4Wb8mALfD3Vfu4bEh3zk2IYO6n2wj2def9W8YcP3kuPgp7voTKYgiLg/B4CI6F5Dfhq0fN79d+AOFxp+6ghBBCiC5OEmghOsiG1Hze+SGVOWNjmD26F+/8kMqnm46wcGM63QK8+OCWMU1fGFiUDjs+g11LIG194/kWN3DaIW4qXDEPvALb+1CEEEKIM4rSWnd0DK2SlJSkk5OTOzoMIX6RSpuDaX9fQ7XDyVf3T8DX03yWLaqwsXTbUcb1DaNXqE/DlXL3w/d/g60fmQS522BInA4DpoN/FOTug9w9kLMHAnrAyFvAYumAoxNCCCG6BqXURq110rHTpQItRAd4ccVeUnLLeP+W0bXJM0Bg5o/M2vx72OQw7Rhh8RASC7u/NFVnNy8YeSuMvg1C+jTcaPQI8yOEEEKIdiUJtBCn2Oa0Qv6zJoVZo3oyrl+YmVhRCCuegE3vQHAMhPSFwz/CtoVmvoc/nHM/jLlbRtIQQgghOpgk0EKcQnuzSnh44RYi/L149KIEM7xc6lr43+NQlgPjfgMT54KHq32jqhTyD0BQb/A+wXjPQgghhDglJIEWop1V2R0s357J+z8epuzQJm5xX8lF4XkEvHQQqorNQt0GwXUfQfehDVf29IOoIac+aCGEEEI0SxJoIdrRip1ZPPrpVnqVbechny8Y65mM9vBDBQyHvte6hp5LgF5jwOre0eEKIYQQogUkgRaiHTidmpdW7WPhqh953f91hnpuQXuEwNmPo0beKu0YQgghxGlMEmgh2lhRhY0HPtrMvj3b+NL/LwRbyuDC51BJN4GHb0eHJ4QQQohfSBJoIdrQlrRCfrPgZ9wLDrA84C/4WGyoG5ZA92EdHZoQQggh2ogk0EK0gfJqO3/7317eXHuQMb5ZvBPwJ9wtwK++gG5ndXR4QgghhGhDkkAL8Qt9vy+XRz/bSlp+BfcMtfLgoWewWD3gxsXmZihCCCGE6FLkPr9CnKRKm4PHF23j+jfW426x8NFtY3goZC2WqmK4aakkz0IIIUQXJRVoIU7C3qwS7v3gZ/ZklXDr+Fh+e2E8XlYFiz6FvudBaN+ODlEIIYQQ7UQSaCFaQWvNhz+l8fQXO/DzdOOdm0cxMc51a+3DP0JxOpz3RMcGKYQQQoh2JQm0EPUUVdgor7YTFejdaF5uaRWPfbqN/+3MYnz/MF64eggR/l51C2z7GNy8IGHaKYxYCCGEEKeaJNBCuBSUVXPla+s4lF/OZUO7c8/kfvQJ9wNg+fZMfvfZNkoq7fxuWiK/PicWi0XVreyww85FEDcFPP076AiEEEIIcSpIAi0E5oLAW95NJr2wgpnDo/l8yxEW/XyES4d0x6oUn/58hIHdA/jwtqHERTaRIKeuhrIcOGvmqQ9eCCGEEKeUJNDijOdwau5fsJlNhwt45brhTBsUxcNT4/nPmhTm/3CIKruT+87txz3n9sfDrZmBa7Z/Ah7+0P+CUxu8EEIIIU45SaDFGe/ZL3eyfEcmv79kANMGRQEQ5ufJoxclcufEvlTYHE32RNeyV8GuJZB4CbgfZzkhhBBCdAmSQIsz2ltrD/LW2lRuHhfLr8+JbTQ/yMeDoBNtZP8qqCyCs65slxiFEEII0bnIjVTEGetQXhl/Wrab8xMjePzixJPf0PZPwDsE+kxqq9CEEEII0YlJAi3OWE8v2Ym7RfHs5YMajqjRGtVlsGcpDLgMrO5tG6AQQgghOiVJoMUZadWuLFbtzua+8/rTLdDrxCs0pSgdvnwIbOXSviGEEEKcQdo1gVZKTVVK7VFK7VdKzW1mmauVUjuVUjuUUh+0ZzxCgBmy7g9LdtI33JebxjXuez6hvAPw+T3w96Gw7b8w8lboPa7tAxVCCCFEp9RuFxEqpazAK8AFQDqwQSm1WGu9s94y/YFHgXFa6wKlVER7xSNEjX9/l8Lh/HLev2V088PSNSV7F6x5wfQ8W9xhxBwYdx8E9Wq3WIUQQgjR+bTnKByjgP1a6xQApdQC4DJgZ71lbgVe0VoXAGits9sxHiFIyy/n1W/3c/GgKMb1C2vZShk/w+rnYfcX4O4LZ98NZ98D/t3aN1ghhBBCdErtmUD3ANLqPU4HRh+zTByAUmotYAWe0lovb8eYxBms0ubg0U+3YVGK312cCBWFkLsPAntAQPfGK9gq4Mvfwub3wTMQJjwCY+4En5BTH7wQQgghOo2OHgfaDegPTAKigdVKqUFa68L6CymlbgNuA+jVS74uF62XVVzJbe8m0//oYr7ttpnI1++D0iwz080LJj8GY+4Gq+stUZQOC2bD0c1wzgPmxyuw4w5ACCGEEJ1GeybQR4Ce9R5Hu6bVlw6s11rbgINKqb2YhHpD/YW01vOAeQBJSUm63SIWXdL2I0Xc8k4y3pWZ/NXjDSzEQN/zIDweQvvClgWw4gnT2zz9n1BVAv/9lbnD4LUfQsK0jj4EIYQQQnQi7ZlAbwD6K6ViMYnztcB1xyyzCJgFvKWUCsO0dKS0Y0ziDFJtd7JkSwa/W7SNUF9PFg7fjmWLE67/FIJ71y2YcAns/ByWPgzzJoFSEBxjkufwuI4KXwghhBCdVLsl0Fpru1LqHuArTH/zm1rrHUqpp4FkrfVi17wLlVI7AQfwsNY6r71iEl2fw6lZn5LHkq0ZLNueSWG5jeG9gvj3NQmE/WcOJE5vmDyDSZgHXg6xE2DV01BdChe/IC0bQgghhGiS0vr06ohISkrSycnJHR2G6IRKq+xM/+f3pOSU4eth5YIBkVw6pDsT4sJxT34dlj0Mv14BPUd1dKhCCCGEOA0opTZqrZOOnd7RFxEK0WbmrU4hJaeMv84czKWDu+PtYTUznA5Y/xpEj5TkWQghhBC/mNzKW3QJ2SWVvL4mhYsHRXF1Us+65Blg73LITzHjNwshhBBC/EKSQIsu4e8r91Ftd/LwlPjGM394BQJ7QcKlpz4wIYQQQnQ5kkCL096BnFIWbEjjutG9iAnzbTgz42c4tBZG3143xrMQQgghxC8gCbQ47f2/5XvwcrNw33n9G8/84VXw8IfhN5z6wIQQQgjRJUkCLU4b6QXljP7jSm59N5mVO7OwO5xsPFTA8h2Z3DahL2F+ng1XKM2BHZ/BsOtlSDohhBBCtBn5TlucNpZvzySruIpNhwpYsTOLcH9PfDyshPl5csv42MYrbF0AThuMmHPKYxVCCCFE1yUVaHHa+Hp3NnGRfvz42HnMu2EEQ6IDSS+o4JEp8fh6HvNZUGvYNB+iR0FEQscELIQQQoguSSrQ4rRQUmnjp4P53DK+D+5WCxcO7MaFA7tRbXfi4dbE58C0nyB3D0z/x6kPVgghhBBdmlSgxWlhzb5c7E7NuQkRDaY3mTwD/PwuePjBwCtOQXRCCCGEOJNIAi1OC1/vzibQ253hvYJOvHBlMWz/FM66Ajz92j84IYQQQpxRJIEWnZ7TqflmdzYT48Jxs7bgJbvjU7CVw7BftX9wQgghhDjjSAItOr0t6YXklVVzXmLEiRcGc/FgeCJEJ7VvYEII8f/bu/PwuOr73uPvryTvO7bkHWxs4w0wi1kSIGFLCgmxswea/aZZ2pCmTdqGpL25bdp7e5vctmlu0zRkadObhezBSRwoGFMgYbEB7wvIxru1eLe8S/rdP2YMirHxh+V3VAAAIABJREFUjNHozEjv1/Po0ZzfHI8+nOeAPhz/zu9I6pEs0Cp7C9c0URXw6vNqX/zmznVw9MAL242rYOvi3INTIroupCRJ6jFchUNlb8GaJi49ZxhD+/f+7Te2LIav3wg1fWHyDTB9Tu6x3VW94MJbswkrSZK6PQu0ylrD3sOs3LaPT910wlrOKcE9n4YBtTBjLqz5Re4LYMYbYcDwrg8rSZJ6BAu0ytrCtU0AL1q+jpU/gS1P5NZ5vuQ9cPPnYeuTsG4BXPC2DJJKkqSewgKtsrZgdRNjh/bjvJEdlqM7dhju+0sYeQFc9M7cWFUVjL8s9yVJklRCFmiVrcPH2vh1/Q7eeuk4ouMNgY/9C+zdBHPnQVV1dgElSVKP5CocKlsPP9PMha0reM2kfi8MtjTBw/8AU18H5746u3CSJKnH8gq0ytaWB+7k+33+nvTT/w1Lr4UZc2DDr6H1ELzmr7OOJ0mSeigLtMrSlp37uG7Ht2kaMJm6WTfB6p/DvI/l3rzi92HE5GwDSpKkHssCrbK09J5/5/XRyM7r/xZmvwVe+zfQsBw2PQYX3ZZ1PEmS1INZoFV2jrW2MvXZr7G11zmMveRNucEIGH1h7kuSJClD3kSosrNswfeZzCb2XHJ7bnk6SZKkMmI7UXlJiSGL/4mtjGTaa96fdRpJkqQXsUCrrGxfci+Tj61l7eT/RnVNr6zjSJIkvYgFWmXlyMIv0JiGcv7rPpJ1FEmSpJOyQKtsHN34BBP2LebhEbdRd9bQrONIkiSdlKtwKDNt7YlfrdjO8i17WbltHzdt+Sfelnox5oYPZx1NkiTplCzQysxXHqzn//znM/SurmLqyIG8rtdT7B5+Fa+YPiHraJIkSadkgVZm7l6yjcsmDOM7v3clvXeshH/dDpd/JrfmsyRJUplyDrQy8Wzjfp5tauENs8bQu6YK1swHAs67KetokiRJL8kCrUzMX95ABNw0c1RuYM0vYPwVMLAu22CSJEmnYYFWJuYv385l55xF3eC+sGcTNCyDaa/POpYkSdJpWaDV5eqbWljbuJ+bL8hffV77q9x3C7QkSaoAFmh1uV8t3w7AzeePzg2s+QXUToPhkzJMJUmSVBgLtLrcL5dvZ/Y5wxg1pC8c3AUbfu3VZ0mSVDEs0OpS65tbWNOwn5svyF99fvY+SG0w1QItSZIqgwVaXepXKxoAeN0FHVbfGDQaxlycYSpJkqTCWaDVpX65bDuXnD2U0UP6wbHDUL8Apt4MVZ6KkiSpMtha1GU27DjAqu37eN3x6RvP3APHDjj/WZIkVRQLtLpEW3vinxfWA+TmP2/8Ddz9UThrEky4JuN0kiRJhavJOoC6vwNHWvn4XU9z/+omPvzqcxm78zG463dhyDh4z91Q0yfriJIkSQWzQKukGvYe5gPfWsTq7fv43NyZvGf4Wvjuu2H4ZHjPz3x0tyRJqjgWaJXM2ob9vPebT7D/8DG+8d7LuK73avj2O2HkTHj3T6H/WVlHlCRJKppzoFUy//3uFbS2t/PDj7yS66bVweJvQP/huWkblmdJklShLNAqibUN+3niuV186FXnMmPMYEgp98TBSddBv6FZx5MkSTpjFmiVxLcf20jvmiredun43EDzWji4A865KttgkiRJL5MFWp2u5UgrP316K7dcOJphA3rnBjc8nPs+4ersgkmSJHUCC7Q63c+e3krLkVbedeU5Lwxu/DUMHgfDJmSWS5IkqTNYoNWpUkp8+7GNzBwzmIvHDz0+CBsegQlXQUS2ASVJkl4mC7Q61ZMbd7OmYT/vvvIc4nhZ3vEMHGh2+oYkSeoWLNDqVP/vsY0M6lvDnIvGvDC44ZHcd28glCRJ3YAFWp1mR8sR5i/fzlsuGUf/3h2e0bPhERg0Bs46N7twkiRJncQCrU7zg8WbOdaWfvvmwefnP1/t/GdJktQtWKDVKVJK/GjxFq6YeBaT6wa+8MbOejjQlLuBUJIkqRsoaYGOiJsiYm1E1EfEHSd5/30R0RwRS/Jfv1fKPCqdldv2sX7HAd548djffuP59Z+v6fpQkiRJJVBz+l3OTERUA18GXgNsARZFxLyU0qoTdv1+Sun2UuVQ15i3dBu9qoObzx/1229seAQGjXb+syRJ6jZKeQX6cqA+pbQ+pXQUuAuYW8Kfp4y0tyd+vnQbr5pSy9D+vV94IyXY8Ovc6hvOf5YkSd1EKQv0WGBzh+0t+bETvSUilkXEjyJifAnzqEQWbdjF9r2Hf3vpOoCd66ClwfWfJUlSt5L1TYQ/ByaklC4E7gO+dbKdIuJDEbE4IhY3Nzd3aUCd3ryl2+jbq4obp4/87Teen/9sgZYkSd1HKQv0VqDjFeVx+bHnpZR2ppSO5De/Dlx6sg9KKd2ZUpqdUppdW1tbkrA6M8fa2pm/fDs3Th/JgD75KfV7t8D8P4N77oChZ8PwydmGlCRJ6kQlu4kQWARMiYiJ5IrzrcDvdtwhIkanlLbnN+cAq0uYRyXwSP0Odh88xpxZY2DfNnjwb2HJ94AEs26Fa/7E+c+SJKlbKVmBTim1RsTtwL1ANfDNlNLKiPgcsDilNA/4w4iYA7QCu4D3lSqPSuPnS7YxuG8Nr55aC9+eC5ufgEvfB1f9Ye7qsyRJUjdTyivQpJTmA/NPGPtsh9efBj5dygwqncPH2rh3ZQO3XDiGPoeac0vWXftpuPZTWUeTJEkqmaxvIlQFe2BNEweOtuVW31j9cyDBjDlZx5IkSSopC7TO2Lwl26gd1Icrzx0Oq+6GEedB7bSsY0mSJJWUBVpn5NDRNh58pombZo6i+tBO2PhrmDHXGwYlSVK3Z4HWGXmkfgeHj7Xz2pkjYc0vILXnCrQkSVI3Z4HWGblvVQOD+tRwxcT89I2zzoWR52cdS5IkqeQs0CpaW3tiweomrp1WR++je2D9fzl9Q5Ik9RgWaBXt6U272XngKK+ZMRLWzofUBtNdfUOSJPUMFmgV7b5VjfSqDq6dWgur5sGQs2HMxVnHkiRJ6hIWaBXtvlWNXHnucAZzENY9kFv72ekbkiSph7BAqyj1TS2s33EgP33jHmg/BjPemHUsSZKkLmOBVlHuW9UIwI3TR8KKH8PgsTD20oxTSZIkdR0LtIpy36oGLhg7hDH7lsGz98Il74EqTyNJktRz2HxUsOb9R3h68x5eM70W7v00DBwFr/xY1rEkSZK6VE3WAVQ5FqxuJCV4S+/HYOuTMPdfoPeArGNJkiR1Ka9Aq2D3rWpk0tAqxiz+PIyeBbNuyzqSJElSl/MKtAqy68BRHnq2ma+ds5DYtgXefKdznyVJUo9kA1JB7l6ylaFtu3hV07dh+htgwlVZR5IkScqEBVoF+emi5/j7wXdR1X4MbvyrrONIkiRlxikcOq31Ty/kC7s+xtSqLXDtZ2D4pKwjSZIkZcYCrVM70gIP/A0TH/9XGmIYLW/+DgMvvCXrVJIkSZmyQOvkUoJ/uxkalvF9fodFkz/G3194TdapJEmSMuccaJ1cSyM0LGPt+Z/gjsPv5Q2XT806kSRJUlmwQOvkGlcA8LPmMYwa3JdrptRmHEiSJKk8WKB1co2rAPj+pkG8+ZKxVFdFxoEkSZLKgwVaJ9e4kgO9a9mVBvHWS8dlnUaSJKlsnLZAR8QbIsKi3cOkppWsaBvP7HOGcW7twKzjSJIklY1CivE7gGcj4vMRMa3UgVQG2lppb1zD00fG8P6rJmadRpIkqayctkCnlN4FXAysA/49Ih6NiA9FxKCSp1Mm9m5ZTXU6RuuI6bzuglFZx5EkSSorBU3NSCntA34E3AWMBt4EPBURHythNmXkVw8sAOD1N95IhDcPSpIkdVTIHOg5EfFT4EGgF3B5SulmYBbwydLGU1dbuW0vO9c9RRvVTJx2cdZxJEmSyk4hTyJ8C/CPKaWHOg6mlA5GxAdKE0tZSCnxl/NWcnvNVhgxBWr6ZB1JkiSp7BQyheMvgSeOb0REv4iYAJBSWlCSVMrE3Uu2sWjDbmb320b1qPOzjiNJklSWCinQPwTaO2y35cfUjRxtbedvf7WaK8fUMODQNhg5I+tIkiRJZamQAl2TUjp6fCP/unfpIikLizbsonHfEf54VmtuYKRXoCVJkk6mkALdHBFzjm9ExFxgR+kiKQsPrGmid3UVF/Xelhuo8wq0JEnSyRRyE+FHgO9ExD8DAWwG3lPSVOpyC9c0ceWk4fTZeR/0GQJDfHy3JEnSyZy2QKeU1gFXRsTA/HZLyVOpS23YcYD1Ow7wnlecA2tX5eY/u/6zJEnSSRVyBZqIeD0wE+h7/MEaKaXPlTCXutADa5oAuH5qHTy0Ci58W8aJJEmSylchD1L5V+AdwMfITeF4G3BOiXOpCy1c28Sk2gGcXbMLjux1/rMkSdJLKOQmwlemlN4D7E4p/RXwCuC80sZSVzlwpJXH1+/i+ml10LgyN+gKHJIkSadUSIE+nP9+MCLGAMeA0aWLpK70SP0Ojra1c920OmjKF+i66dmGkiRJKmOFFOifR8RQ4AvAU8AG4LulDKWus3BNE4P61HDZhLNyV6CHnA19B2cdS5IkqWy95E2EEVEFLEgp7QF+HBG/APqmlPZ2STqVVEqJhWubuOa8EfSqroLGVTByZtaxJEmSytpLXoFOKbUDX+6wfcTy3H2s3LaPxn1HuG5qHWx8FHY+6yO8JUmSTqOQKRwLIuItES4M3N0sXNMEJG46PB++dQsMPQcufX/WsSRJkspaIetAfxj4BNAaEYfJLWWXUkpOlK1wD63ZyleH/AeD7r8XprwW3vw16Dc061iSJEllrZAnEQ7qiiDqWjv27ufPGv+Uy6qegWv+BK77DFRVZx1LkiSp7J22QEfEq042nlJ6qPPjqKuseOSXXFv1DNuu/l+MueGjWceRJEmqGIVM4fjTDq/7ApcDTwLXlySRusShtfdxlBpGv+p9WUeRJEmqKIVM4XhDx+2IGA98sWSJVHJ7Dx1jwt4n2DbkIib0HpB1HEmSpIpSyCocJ9oC+Ki6CvabJauYHpuomeJfIkiSJBWrkDnQ/xdI+c0q4CJyTyRUhdr+9D0AjLn4dRknkSRJqjyFzIFe3OF1K/C9lNKvS5RHJXbwaCtnNTzCgV5DGDBmVtZxJEmSKk4hBfpHwOGUUhtARFRHRP+U0sHSRlMpPLS2iVfEMg6Nu4oBVWcyg0eSJKlnK+hJhEC/Dtv9gPtLE0el9vRTjzEy9jDsgpuyjiJJklSRCinQfVNKLcc38q/7ly6SSuVIaxtV6x8EoHqyNxBKkiSdiUIK9IGIuOT4RkRcChwq5MMj4qaIWBsR9RFxx0vs95aISBExu5DP1Zn5zbqdXNa+lAODJsLQ8VnHkSRJqkiFzIH+I+CHEbENCGAU8I7T/aGIqAa+DLyG3NJ3iyJiXkpp1Qn7DQI+DjxeZHYV6b6lm/iLqtX0mfrurKNIkiRVrEIepLIoIqYBU/NDa1NKxwr47MuB+pTSeoCIuAuYC6w6Yb+/Bv6O337ioTpZa1s7zWsepn8cgck3ZB1HkiSpYp12CkdEfBQYkFJakVJaAQyMiD8o4LPHAps7bG/Jj3X87EuA8SmlXxaRWWdg0YbdzDr6NO1RDROuzjqOJElSxSpkDvQHU0p7jm+klHYDH3y5PzgiqoB/AD5ZwL4fiojFEbG4ubn55f7oHumeFdt5VfUK0tjZ0Hdw1nEkSZIqViEFujoi4vhGfm5z7wL+3Fag451q4/Jjxw0CzgcejIgNwJXAvJPdSJhSujOlNDulNLu2traAH62O2tsTj66o5/xY7+obkiRJL1MhNxHeA3w/Ir6a3/4w8KsC/twiYEpETCRXnG8Ffvf4mymlvcCI49sR8SDwJymlxahTLd2yhykHnqSqd4JJFmhJkqSXo5AC/SngQ8BH8tvLyK3E8ZJSSq0RcTtwL1ANfDOltDIiPgcsTinNO8PMKtI9Kxq4rnop7X2HUjX20qzjSJIkVbRCVuFoj4jHgUnA28ldNf5xIR+eUpoPzD9h7LOn2PfaQj5TxUkpcc+K7fx+r+VUTboeqqqzjiRJklTRTlmgI+I84Lb81w7g+wAppeu6Jpo6w+rt++m/ew1D++yCyTdmHUeSJKnivdQV6DXAw8AtKaV6gIj44y5JpU5zz8oGrq1emttw/WdJkqSX7aVW4XgzsB1YGBFfi4gbyD2JUBXk3hUN3NJ/JYy6AAadduq6JEmSTuOUBTql9LOU0q3ANGAhuUd610XEVyLitV0VUGdufXMLWxsbmX5stdM3JEmSOslp14FOKR1IKX03pfQGcms5P01uZQ6VuXtWNnBV1UqqUqsFWpIkqZMU8iCV56WUducfauJk2gpw74oG3jR4NfQeBOOvyDqOJElSt1BUgVbl2LrnEEu37OGqtATOfTVU98o6kiRJUrdgge6m5i/bzuTYyqAjDU7fkCRJ6kQW6G5q3tJt3DrsmdyGBVqSJKnTWKC7oed2HGD51r3c1GcF1E6DoeOzjiRJktRtWKC7oXlLttE/DjN231NefZYkSepkFuhuJqXEvKVbee+ojUTbUZ8+KEmS1Mks0N3Mqu37WNd8gLf3XQT9hsE5V2cdSZIkqVuxQHcz85ZuY2DVUSbseBCmz4Ga3llHkiRJ6lYs0N1Ie3viF0u38wdj6oljB+GCt2YdSZIkqduxQHcjT23azdY9h3hjr8dg4Cg456qsI0mSJHU7FuhuZN7SbQyvOczopodh5pugqjrrSJIkSd2OBbqbaG1rZ/7y7Xx87Fqi7Qic/5asI0mSJHVLFuhu4jfrdrKj5Sg38xsYejaMm511JEmSpG7JAt1N3LeqkTG9DjCi6Te5q88RWUeSJEnqlizQ3UBKiQfWNPEHI1cSqQ3Od/UNSZKkUrFAdwPPNLawdc8hXtv+MIyYCiNnZh1JkiSp27JAdwML1jQyip3U7noqt/az0zckSZJKxgLdDSxc08Qnhj1EkFx9Q5IkqcQs0BVu94GjbN/4DG8+fDdc8HYYPinrSJIkSd2aBbrCPfRsM39WcxdVVVVw4//IOo4kSVK3Z4GucOueWsic6keJV34MhozLOo4kSVK3Z4GuYK2tbdyw6YvsrRlOXP1HWceRJEnqESzQFWzDf/0/ZvEsG2d9AvoMzDqOJElSj2CBrlTHDlH7+P9iZfsEJt74wazTSJIk9RgW6Eq15DsMOdrIT+v+gEH9+mSdRpIkqceoyTqAzkzLhic5nAYzatZrso4iSZLUo1igK9SBbWvYmEZz/bS6rKNIkiT1KE7hqFB99z1HY6/xnFvrzYOSJEldyQJdgdKhPQxp2+1TByVJkjJgga5AW+qXAzB0/IyMk0iSJPU8FugKtPnZpQBMnHZRxkkkSZJ6Hgt0Bdq/dTWtVDF24vSso0iSJPU4FugKk1KiZtc6dvUaQ9S4/rMkSVJXs0BXmM27DjGmbStHh56bdRRJkqQeyQJdYR5b38yEaKD/mGlZR5EkSeqRfJBKhXn2mTX0i6P0dQUOSZKkTHgFusLs2rQSgBgxJeMkkiRJPZMFuoJs33uIgS0bchvDLdCSJElZsEBXkCee28XE2E5br4EwsC7rOJIkST2SBbqCPLZ+F+fVNFBVOwUiso4jSZLUI1mgK8gTz+3kvOoGwukbkiRJmbFAV4jm/UfY2ryLEW1N4A2EkiRJmbFAV4hFG3YxMRpyG8MnZxtGkiSpB7NAV4jfrNvBtF6NuQ0LtCRJUmYs0BUgpcQDq5u4dsTe3MDwSdkGkiRJ6sEs0BVg1fZ9bNt7mFn9mmHwOOg9IOtIkiRJPZYFugLcv6qJCBjbthVGOH1DkiQpSxboCrBgTSMXjxtCr93rfAKhJElSxizQZa5h72GWbdnLGybXwJF93kAoSZKUMQt0mVuwJrfyxo11+3MDTuGQJEnKlAW6zC1Y3cTZZ/VnXNvW3IBTOCRJkjJV0gIdETdFxNqIqI+IO07y/kciYnlELImIRyJiRinzVJqDR1t5pH4HN0yvIxqWQk0/GDI+61iSJEk9WskKdERUA18GbgZmALedpCB/N6V0QUrpIuDzwD+UKk8leuTZHRxtbed3pgyC5T+C6W+AKv/SQJIkKUulbGOXA/UppfUppaPAXcDcjjuklPZ12BwApBLmqTj3r25kUN8aZu9fkLuB8LLfyzqSJElSj1dTws8eC2zusL0FuOLEnSLio8AngN7A9SXMU1Ha2xMPrGni2vNqqXnyr2HkBTD+8qxjSZIk9XiZzwdIKX05pTQJ+BTwFyfbJyI+FBGLI2Jxc3Nz1wbMyJIte9jRcpS3jdoODcvhsg9ARNaxJEmSerxSFuitQMc73sblx07lLuCNJ3sjpXRnSml2Sml2bW1tJ0YsXwtWN1JdFVy54yfQZzBc8LasI0mSJInSFuhFwJSImBgRvYFbgXkdd4iIjmuyvR54toR5Ksr9q5q4YXzQe+08mHUb9BmYdSRJkiRRwjnQKaXWiLgduBeoBr6ZUloZEZ8DFqeU5gG3R8SNwDFgN/DeUuWpJJt3HWRt437+euaj0Hg0N31DkiRJZaGUNxGSUpoPzD9h7LMdXn+8lD+/Ut2/upEq2rmk6acw4RqonZp1JEmSJOVlfhOhXmzB6iZuG7aWmv1bXLpOkiSpzFigy8y+w8d4bP1O3tnvURhQB9Nen3UkSZIkdWCBLjMPPdNMa3ti8uGVMPEaqO6VdSRJkiR1YIEuM/evamRa//30PrgdxvngFEmSpHJjgS4jrW3tLFzbzG1jGnID4y/LNpAkSZJexAJdRhZv3M3eQ8d4db/1UNM39/huSZIklRULdBlZsLqR3tVVjD+wEsZcDDW9s44kSZKkE1igy0RKiftWNXLNuYOoblwG45y+IUmSVI4s0GViXfMBNuw8yFvH7IK2oxZoSZKkMmWBLhMLVjcC8Mo+63MD412BQ5IkqRxZoMvEvSsbmDF6MEN2PA1DzoZBo7KOJEmSpJOwQJeBzbsO8tSmPdwyazRsWeTydZIkSWXMAl0G5i3dBsAbJwL7tvoAFUmSpDJmgS4D85ZsY/Y5wxjTsjw34BVoSZKksmWBztiahn2sbdzP3IvGwOZFPkBFkiSpzFmgMzZvyTaqq4LXXTAatjzhA1QkSZLKnAU6Qykl7l6yjasnj2B4X2D7Utd/liRJKnMW6Aw9tWk3W/ccyk3f2L7MB6hIkiRVAAt0hu5eso0+NVW8duao3PQN8AEqkiRJZc4CnZHWtnZ+uWw7N84YycA+NbD5cR+gIkmSVAEs0Bn59bqd7DxwlDmzxkB7Gzz3EEy4OutYkiRJOg0LdEbuXrKVQX1ruHZqLWx9Cg7thik3Zh1LkiRJp2GBzkDLkVbuWdHA6y8YTZ+aaqi/H6IKzr0u62iSJEk6DQt0Bn65bBsHj7bxttnjcwP198PYS6H/WdkGkyRJ0mlZoDPw/UWbmVw3kEvOHgoHdsLWJ2Hya7KOJUmSpAJYoLtYfdN+ntq0h3fMHk9EwPqFQILJzn+WJEmqBBboLvaDxVuoqQredMnY3ED9/dDvLBhzUbbBJEmSVBALdBc61tbOT57awg3T6xgxsA+0t+cK9OQboKo663iSJEkqgAW6Cz2wpokdLUd5x2X5mwcblsGBZqdvSJIkVRALdBf6waLN1A3qw6um1OYG6u/LfZ90fXahJEmSVBQLdBdp3HeYhWubeOul46ipzh/2+gUw+iIYWJdtOEmSJBXMAt1FfvzUFtoTvP342s+H9sDmJ5y+IUmSVGEs0F0gpcSPntzC5RPPYsKIAbnB9Q9CarNAS5IkVRgLdBdY13yA9c0HeMOsMS8M1t8PfYbAuMuyCyZJkqSiWaC7wILVjQDcMC0/1/noQVjzi9zyddU1GSaTJElSsSzQXWDB6iZmjB7MmKH9cgNLvweHdsPlH8w2mCRJkopmgS6x3QeOsnjjLm6cnr/63N4Oj30FxlwMZ78i23CSJEkqmgW6xB58pon2BDdMH5kbqL8Pdj4LV34UIrINJ0mSpKJZoEvs/lVN1A7qwwVjh+QGHv1nGDQGZr4x22CSJEk6IxboEjra2s5/PdPMDdPqqKoKaFgOzz0EV3wYqntlHU+SJElnwAJdQk88t4uWI60vTN949F+gV3+49L3ZBpMkSdIZs0CX0P2rG+lTU8XVk0fA/gZY/kO4+F3Qb1jW0SRJknSGLNAlklJiwZpGrpo8gn69q2HR16G9Fa74SNbRJEmS9DJYoEvk2aYWNu86xA3T6+DgLnjiazD1dTB8UtbRJEmS9DJYoEvk/uefPjgSHvoCHNkH130m41SSJEl6uSzQJbJgdRPnjx3MqGNb4Ik74eJ3w6jzs44lSZKkl8kCXQJ7Dx3j6U27uX5qHdz336GmL1z/F1nHkiRJUiewQJfAkxt30Z7gtf3Xwtr5cM0nYGBd1rEkSZLUCSzQJfD4+l30qU7MWPa/YcjZucd2S5IkqVuoyTpAd/T4c7v4o7OeoKppJbz1m9Crb9aRJEmS1Em8At3JDhxpZefWet5z6D9g3OUw881ZR5IkSVInskB3smXPPsc3a/6OPtEKc74EEVlHkiRJUidyCkdnOnaY8fd+gNpo5NjbfkxN3fSsE0mSJKmTeQW6s7S3wU8+yLj9S/nS4E/S77xrs04kSZKkEvAKdGe5989h9Tz+tu3dtE97Y9ZpJEmSVCJege4Mzc/A41+hYeq7+eqxm7li4vCsE0mSJKlELNCdYdXdAPxyyO8SAZdNOCvjQJIkSSqVkhboiLgpItZGRH1E3HGS9z8REasiYllELIiIc0qZp2RW3Q3jr+CBbVVMGzWYIf17ZZ1IkiRJJVKyAh0R1cCXgZuBGcBtETHjhN2eBmanlC4EfgR8vlR5SmbnOmhcTuu0OTy5cTdXTPTqsyRJUndWyivQlwP1KaX1KaWjwF3A3I47pJQWppQO5jcfA8aVME9prJ4HwKqh13L4WLsFWpIkqZsrZYEeC2zusL0lP3ZROXkEAAAN60lEQVQqHwB+VcI8pbHqbhh7Kb9u7gfAZRZoSZKkbq0sbiKMiHcBs4EvnOL9D0XE4ohY3Nzc3LXhXsrujbDtaZgxl8ef28nkuoGMGNgn61SSJEkqoVIW6K3A+A7b4/JjvyUibgT+HJiTUjpysg9KKd2ZUpqdUppdW1tbkrBnJD99o23aHBZv2M3lXn2WJEnq9kpZoBcBUyJiYkT0Bm4F5nXcISIuBr5Krjw3lTBLaay6G0ZdyHNtI2g50solZw/LOpEkSZJKrGQFOqXUCtwO3AusBn6QUloZEZ+LiDn53b4ADAR+GBFLImLeKT6u/OzdClsWwYy5rGnYD8C0UYMyDiVJkqRSK+mjvFNK84H5J4x9tsPrG0v580tq9c9z32e8kbVP7ae6KphcNzDbTJIkSSq5sriJsCKtuhvqZsKIyaxp2M+E4f3p26s661SSJEkqMQv0mWhphk2PwozcstZrG/YzbdTgjENJkiSpK1igz8T2JUCCiddw4Egrm3YdZKrznyVJknoEC/SZaFyZ+143g2caczcQWqAlSZJ6Bgv0mWhcCYPHQb+hrHUFDkmSpB7FAn0mmlbByJkArGnYT//e1Ywf1j/jUJIkSeoKFuhitR2D5rUwcgaQu4FwyshBVFVFxsEkSZLUFSzQxdrxLLQfg7qZpJRY07CPaSOdviFJktRTWKCLdfwGwpEzad5/hN0HjzFttAVakiSpp7BAF6tpJVT1ghFTnn+EtytwSJIk9RwW6GI1roTaqVDdq8MKHD5ERZIkqaewQBercRXU5W4gXNOwn9pBfThrQO+MQ0mSJKmrWKCLcWg37Nvy/BJ2axv3uf6zJElSD2OBLkbT6tz3kTNpa08829jCVFfgkCRJ6lEs0MXosALHhp0HONLa7g2EkiRJPYwFuhiNK6HvUBg02hsIJUmSeigLdDEaV8LI8yGCNQ37qQqYMnJg1qkkSZLUhSzQhWpvz82Bfv4R3vuYMHwAfXtVZxxMkiRJXckCXai9m+Do/hdW4GjY7/xnSZKkHsgCXajGVbnvdTM5eLSVjbsOWqAlSZJ6IAt0oY6vwFE3nfqmFlLCJewkSZJ6IAt0oZpWwrAJ0Gcg9U0tgDcQSpIk9UQW6EIdX4EDWNfcQnVVcPZZAzIOJUmSpK5mgS7EscOwsx7qcitw1De1cM7w/vSu8fBJkiT1NDbAQjSvgdT+/Aoc65oPMLnW6RuSJEk9kQW6EL36w6XvhzEXc6ytnQ07DjCpzgItSZLUE9VkHaAi1J4Hb/giAJuaW2htT16BliRJ6qG8Al2k4ytwTPYKtCRJUo9kgS7S8QJ9bq0rcEiSJPVEFugirWtuYdTgvgzq2yvrKJIkScqABbpI65pamFTn1WdJkqSeygJdhJSSS9hJkiT1cBboIjTuO0LLkVZvIJQkSerBLNBFOH4D4SSvQEuSJPVYFugirGt2CTtJkqSezgJdhPqmFgb1qaF2UJ+so0iSJCkjFugirGtuYVLdQCIi6yiSJEnKiAW6CPVNLU7fkCRJ6uEs0AXad/gYTfuPeAOhJElSD2eBLtC6Jm8glCRJkgW6YPUWaEmSJGGBLti65gP0rq5i/LB+WUeRJElShizQBapvamHCiP7UVHvIJEmSejLbYIHWNbd4A6EkSZIs0IU40trGpl0Hnf8sSZIkC3QhNu48SFt7skBLkiTJAl2IQ0fbmDVuCOeNHJR1FEmSJGWsJusAlWDW+KHcffvVWceQJElSGfAKtCRJklQEC7QkSZJUBAu0JEmSVAQLtCRJklQEC7QkSZJUBAu0JEmSVAQLtCRJklQEC7QkSZJUBAu0JEmSVISSFuiIuCki1kZEfUTccZL3XxURT0VEa0S8tZRZJEmSpM5QsgIdEdXAl4GbgRnAbREx44TdNgHvA75bqhySJElSZ6op4WdfDtSnlNYDRMRdwFxg1fEdUkob8u+1lzCHJEmS1GlKOYVjLLC5w/aW/FjRIuJDEbE4IhY3Nzd3SjhJkiTpTFTETYQppTtTSrNTSrNra2uzjiNJkqQerJQFeiswvsP2uPyYJEmSVLFKWaAXAVMiYmJE9AZuBeaV8OdJkiRJJVeyAp1SagVuB+4FVgM/SCmtjIjPRcQcgIi4LCK2AG8DvhoRK0uVR5IkSeoMpVyFg5TSfGD+CWOf7fB6EbmpHZIkSVJFiJRS1hmKEhHNwMYu+FEjgB1d8HO6O49j5/A4dg6P48vnMewcHsfO4XF8+TyGL+2clNKLVrCouALdVSJicUppdtY5Kp3HsXN4HDuHx/Hl8xh2Do9j5/A4vnwewzNTEcvYSZIkSeXCAi1JkiQVwQJ9andmHaCb8Dh2Do9j5/A4vnwew87hcewcHseXz2N4BpwDLUmSJBXBK9CSJElSESzQJxERN0XE2oioj4g7ss5TKSJifEQsjIhVEbEyIj6eHz8rIu6LiGfz34dlnbXcRUR1RDwdEb/Ib0+MiMfz5+T380/31EuIiKER8aOIWBMRqyPiFZ6LxYuIP87/+7wiIr4XEX09H08vIr4ZEU0RsaLD2EnPv8j5Uv54LouIS7JLXj5OcQy/kP93ellE/DQihnZ479P5Y7g2In4nm9Tl52THscN7n4yIFBEj8tueiwWyQJ8gIqqBLwM3AzOA2yJiRrapKkYr8MmU0gzgSuCj+WN3B7AgpTQFWJDf1kv7OLkneB73d8A/ppQmA7uBD2SSqrL8E3BPSmkaMIvc8fRcLEJEjAX+EJidUjofqAZuxfOxEP8O3HTC2KnOv5uBKfmvDwFf6aKM5e7fefExvA84P6V0IfAM8GmA/O+aW4GZ+T/zL/nf5zr5cSQixgOvBTZ1GPZcLJAF+sUuB+pTSutTSkeBu4C5GWeqCCml7Smlp/Kv95MrLGPJHb9v5Xf7FvDGbBJWhogYB7we+Hp+O4DrgR/ld/EYnkZEDAFeBXwDIKV0NKW0B8/FM1ED9IuIGqA/sB3Px9NKKT0E7Dph+FTn31zgP1LOY8DQiBjdNUnL18mOYUrpP1NKrfnNx3jhacZzgbtSSkdSSs8B9eR+n/d4pzgXAf4R+DOg481wnosFskC/2Fhgc4ftLfkxFSEiJgAXA48DI1NK2/NvNQAjM4pVKb5I7j9q7fnt4cCeDr80PCdPbyLQDPxbfirM1yNiAJ6LRUkpbQX+D7krVNuBvcCTeD6eqVOdf/7eOTP/DfhV/rXHsAgRMRfYmlJaesJbHscCWaDV6SJiIPBj4I9SSvs6vpdyy7649MspRMQtQFNK6cmss1S4GuAS4CsppYuBA5wwXcNz8fTyc3TnkvsfkjHAAE7yV8EqnuffyxMRf05u2uB3ss5SaSKiP/AZ4LNZZ6lkFugX2wqM77A9Lj+mAkREL3Ll+TsppZ/khxuP/xVQ/ntTVvkqwFXAnIjYQG760PXk5vIOzf8VOnhOFmILsCWl9Hh++0fkCrXnYnFuBJ5LKTWnlI4BPyF3jno+nplTnX/+3ilCRLwPuAV4Z3phLV6PYeEmkfuf4qX53zXjgKciYhQex4JZoF9sETAlf5d5b3I3JczLOFNFyM/V/QawOqX0Dx3emge8N//6vcDdXZ2tUqSUPp1SGpdSmkDu3HsgpfROYCHw1vxuHsPTSCk1AJsjYmp+6AZgFZ6LxdoEXBkR/fP/fh8/jp6PZ+ZU59884D35FRCuBPZ2mOqhDiLiJnJT3OaklA52eGsecGtE9ImIieRugnsii4zlLqW0PKVUl1KakP9dswW4JP/fTc/FAvkglZOIiNeRm4daDXwzpfQ/M45UESLiauBhYDkvzN/9DLl50D8AzgY2Am9PKZ3shgZ1EBHXAn+SUrolIs4ld0X6LOBp4F0ppSNZ5it3EXERuRsxewPrgfeTu2jguViEiPgr4B3k/rr8aeD3yM2J9Hx8CRHxPeBaYATQCPwP4Gec5PzL/8/JP5ObHnMQeH9KaXEWucvJKY7hp4E+wM78bo+llD6S3//Pyc2LbiU3hfBXJ35mT3Sy45hS+kaH9zeQW2lnh+di4SzQkiRJUhGcwiFJkiQVwQItSZIkFcECLUmSJBXBAi1JkiQVwQItSZIkFcECLUllLiLaImJJh687Tv+nCv7sCRGxorM+T5J6gprT7yJJytihlNJFWYeQJOV4BVqSKlREbIiIz0fE8oh4IiIm58cnRMQDEbEsIhZExNn58ZER8dOIWJr/emX+o6oj4msRsTIi/jMi+uX3/8OIWJX/nLsy+seUpLJjgZak8tfvhCkc7+jw3t6U0gXknh72xfzY/wW+lVK6EPgO8KX8+JeA/0opzQIuAVbmx6cAX04pzQT2AG/Jj98BXJz/nI+U6h9OkiqNTyKUpDIXES0ppYEnGd8AXJ9SWh8RvYCGlNLwiNgBjE4pHcuPb08pjYiIZmBcx8duR8QE4L6U0pT89qeAXimlv4mIe4AWco+g/llKqaXE/6iSVBG8Ai1JlS2d4nUxjnR43cYL98e8HvgyuavViyLC+2YkCQu0JFW6d3T4/mj+9W+AW/Ov3wk8nH+9APh9gIiojoghp/rQiKgCxqeUFgKfAoYAL7oKLkk9kVcTJKn89YuIJR2270kpHV/KblhELCN3Ffm2/NjHgH+LiD8FmoH358c/DtwZER8gd6X594Htp/iZ1cC38yU7gC+llPZ02j+RJFUw50BLUoXKz4GenVLakXUWSepJnMIhSZIkFcEr0JIkSVIRvAItSZIkFcECLUmSJBXBAi1JkiQVwQItSZIkFcECLUmSJBXBAi1JkiQV4f8DM44hzFkYdfkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "L1_model_dict = L1_model_val.history\n",
        "\n",
        "acc_values = L1_model_dict['acc'] \n",
        "val_acc_values = L1_model_dict['val_acc']\n",
        "\n",
        "epochs = range(1, len(acc_values) + 1)\n",
        "ax.plot(epochs, acc_values, label='Training acc L1')\n",
        "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
        "ax.set_title('Training & validation accuracy with L1 regularization')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di0qqVWi6z6v"
      },
      "source": [
        "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy isn't still that good. Next, experiment with dropout regularization to see if it offers any advantages. \n",
        "\n",
        "\n",
        "## Dropout Regularization \n",
        "\n",
        "It's time to try another technique: applying dropout to layers. As discussed in the earlier lesson, this involves setting a certain proportion of units in each layer to zero. In the following cell: \n",
        "\n",
        "- Apply a dropout rate of 30% to the input layer \n",
        "- Add a first hidden layer with 50 units and `'relu'` activation \n",
        "- Apply a dropout rate of 30% to the first hidden layer \n",
        "- Add a second hidden layer with 25 units and `'relu'` activation \n",
        "- Apply a dropout rate of 30% to the second hidden layer \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAv4_WkV6z6v",
        "outputId": "77c54b1d-93dd-4232-fb31-fd148d6de27f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 1.9856 - acc: 0.1444 - val_loss: 1.9371 - val_acc: 0.1610\n",
            "Epoch 2/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.9562 - acc: 0.1639 - val_loss: 1.9236 - val_acc: 0.2010\n",
            "Epoch 3/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.9374 - acc: 0.1849 - val_loss: 1.9142 - val_acc: 0.2160\n",
            "Epoch 4/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.9237 - acc: 0.2001 - val_loss: 1.9065 - val_acc: 0.2150\n",
            "Epoch 5/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.9197 - acc: 0.1960 - val_loss: 1.8975 - val_acc: 0.2250\n",
            "Epoch 6/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.9090 - acc: 0.2105 - val_loss: 1.8873 - val_acc: 0.2260\n",
            "Epoch 7/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.8985 - acc: 0.2231 - val_loss: 1.8761 - val_acc: 0.2390\n",
            "Epoch 8/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.8925 - acc: 0.2243 - val_loss: 1.8643 - val_acc: 0.2580\n",
            "Epoch 9/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.8766 - acc: 0.2407 - val_loss: 1.8501 - val_acc: 0.2640\n",
            "Epoch 10/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.8672 - acc: 0.2404 - val_loss: 1.8342 - val_acc: 0.2830\n",
            "Epoch 11/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.8573 - acc: 0.2544 - val_loss: 1.8160 - val_acc: 0.3020\n",
            "Epoch 12/150\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 1.8375 - acc: 0.2597 - val_loss: 1.7975 - val_acc: 0.3210\n",
            "Epoch 13/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.8273 - acc: 0.2653 - val_loss: 1.7757 - val_acc: 0.3450\n",
            "Epoch 14/150\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 1.8114 - acc: 0.2787 - val_loss: 1.7520 - val_acc: 0.3740\n",
            "Epoch 15/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.7900 - acc: 0.2895 - val_loss: 1.7280 - val_acc: 0.3920\n",
            "Epoch 16/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.7740 - acc: 0.3093 - val_loss: 1.7013 - val_acc: 0.4300\n",
            "Epoch 17/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.7624 - acc: 0.3049 - val_loss: 1.6777 - val_acc: 0.4370\n",
            "Epoch 18/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.7400 - acc: 0.3148 - val_loss: 1.6520 - val_acc: 0.4640\n",
            "Epoch 19/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.7220 - acc: 0.3297 - val_loss: 1.6247 - val_acc: 0.4730\n",
            "Epoch 20/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.7043 - acc: 0.3340 - val_loss: 1.5998 - val_acc: 0.4820\n",
            "Epoch 21/150\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 1.6786 - acc: 0.3496 - val_loss: 1.5723 - val_acc: 0.4940\n",
            "Epoch 22/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.6629 - acc: 0.3597 - val_loss: 1.5466 - val_acc: 0.5130\n",
            "Epoch 23/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.6543 - acc: 0.3567 - val_loss: 1.5241 - val_acc: 0.5280\n",
            "Epoch 24/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.6323 - acc: 0.3721 - val_loss: 1.4985 - val_acc: 0.5400\n",
            "Epoch 25/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.6098 - acc: 0.3823 - val_loss: 1.4735 - val_acc: 0.5420\n",
            "Epoch 26/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.5874 - acc: 0.3928 - val_loss: 1.4463 - val_acc: 0.5540\n",
            "Epoch 27/150\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 1.5689 - acc: 0.3913 - val_loss: 1.4228 - val_acc: 0.5630\n",
            "Epoch 28/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.5614 - acc: 0.3961 - val_loss: 1.4009 - val_acc: 0.5810\n",
            "Epoch 29/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.5395 - acc: 0.4108 - val_loss: 1.3793 - val_acc: 0.5830\n",
            "Epoch 30/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.5297 - acc: 0.4140 - val_loss: 1.3600 - val_acc: 0.5820\n",
            "Epoch 31/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.5112 - acc: 0.4208 - val_loss: 1.3382 - val_acc: 0.5870\n",
            "Epoch 32/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.4932 - acc: 0.4252 - val_loss: 1.3187 - val_acc: 0.6020\n",
            "Epoch 33/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.4664 - acc: 0.4391 - val_loss: 1.2972 - val_acc: 0.6010\n",
            "Epoch 34/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.4611 - acc: 0.4337 - val_loss: 1.2804 - val_acc: 0.6130\n",
            "Epoch 35/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.4414 - acc: 0.4403 - val_loss: 1.2596 - val_acc: 0.6140\n",
            "Epoch 36/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.4151 - acc: 0.4559 - val_loss: 1.2386 - val_acc: 0.6190\n",
            "Epoch 37/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.4327 - acc: 0.4367 - val_loss: 1.2278 - val_acc: 0.6200\n",
            "Epoch 38/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.4068 - acc: 0.4665 - val_loss: 1.2090 - val_acc: 0.6230\n",
            "Epoch 39/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.3990 - acc: 0.4636 - val_loss: 1.1949 - val_acc: 0.6300\n",
            "Epoch 40/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.3809 - acc: 0.4732 - val_loss: 1.1781 - val_acc: 0.6400\n",
            "Epoch 41/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.3774 - acc: 0.4737 - val_loss: 1.1636 - val_acc: 0.6510\n",
            "Epoch 42/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.3707 - acc: 0.4805 - val_loss: 1.1538 - val_acc: 0.6570\n",
            "Epoch 43/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.3412 - acc: 0.4911 - val_loss: 1.1352 - val_acc: 0.6640\n",
            "Epoch 44/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.3301 - acc: 0.4937 - val_loss: 1.1222 - val_acc: 0.6680\n",
            "Epoch 45/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.3299 - acc: 0.4917 - val_loss: 1.1112 - val_acc: 0.6710\n",
            "Epoch 46/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.3108 - acc: 0.4999 - val_loss: 1.0932 - val_acc: 0.6710\n",
            "Epoch 47/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.3070 - acc: 0.5008 - val_loss: 1.0805 - val_acc: 0.6780\n",
            "Epoch 48/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.2944 - acc: 0.5039 - val_loss: 1.0718 - val_acc: 0.6780\n",
            "Epoch 49/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.2902 - acc: 0.5045 - val_loss: 1.0595 - val_acc: 0.6810\n",
            "Epoch 50/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.2779 - acc: 0.5172 - val_loss: 1.0481 - val_acc: 0.6810\n",
            "Epoch 51/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.2626 - acc: 0.5140 - val_loss: 1.0359 - val_acc: 0.6810\n",
            "Epoch 52/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.2605 - acc: 0.5160 - val_loss: 1.0297 - val_acc: 0.6910\n",
            "Epoch 53/150\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 1.2601 - acc: 0.5217 - val_loss: 1.0209 - val_acc: 0.6890\n",
            "Epoch 54/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.2469 - acc: 0.5241 - val_loss: 1.0152 - val_acc: 0.6910\n",
            "Epoch 55/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.2386 - acc: 0.5272 - val_loss: 1.0039 - val_acc: 0.6940\n",
            "Epoch 56/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.2195 - acc: 0.5435 - val_loss: 0.9944 - val_acc: 0.6970\n",
            "Epoch 57/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.2199 - acc: 0.5355 - val_loss: 0.9889 - val_acc: 0.6950\n",
            "Epoch 58/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.2126 - acc: 0.5328 - val_loss: 0.9761 - val_acc: 0.6980\n",
            "Epoch 59/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.2005 - acc: 0.5384 - val_loss: 0.9680 - val_acc: 0.6990\n",
            "Epoch 60/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.1992 - acc: 0.5392 - val_loss: 0.9591 - val_acc: 0.6950\n",
            "Epoch 61/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.1787 - acc: 0.5573 - val_loss: 0.9512 - val_acc: 0.7010\n",
            "Epoch 62/150\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 1.1766 - acc: 0.5492 - val_loss: 0.9446 - val_acc: 0.7010\n",
            "Epoch 63/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.1800 - acc: 0.5497 - val_loss: 0.9393 - val_acc: 0.7050\n",
            "Epoch 64/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.1704 - acc: 0.5556 - val_loss: 0.9401 - val_acc: 0.7010\n",
            "Epoch 65/150\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 1.1732 - acc: 0.5511 - val_loss: 0.9280 - val_acc: 0.7100\n",
            "Epoch 66/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.1494 - acc: 0.5736 - val_loss: 0.9213 - val_acc: 0.7100\n",
            "Epoch 67/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.1460 - acc: 0.5689 - val_loss: 0.9136 - val_acc: 0.7070\n",
            "Epoch 68/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.1377 - acc: 0.5704 - val_loss: 0.9068 - val_acc: 0.7130\n",
            "Epoch 69/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.1379 - acc: 0.5691 - val_loss: 0.9053 - val_acc: 0.7120\n",
            "Epoch 70/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.1425 - acc: 0.5636 - val_loss: 0.8942 - val_acc: 0.7130\n",
            "Epoch 71/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.1236 - acc: 0.5740 - val_loss: 0.8901 - val_acc: 0.7140\n",
            "Epoch 72/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.1237 - acc: 0.5720 - val_loss: 0.8872 - val_acc: 0.7080\n",
            "Epoch 73/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.1142 - acc: 0.5727 - val_loss: 0.8808 - val_acc: 0.7140\n",
            "Epoch 74/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.1268 - acc: 0.5695 - val_loss: 0.8768 - val_acc: 0.7150\n",
            "Epoch 75/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.0900 - acc: 0.5871 - val_loss: 0.8724 - val_acc: 0.7100\n",
            "Epoch 76/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.1054 - acc: 0.5781 - val_loss: 0.8658 - val_acc: 0.7160\n",
            "Epoch 77/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.1055 - acc: 0.5864 - val_loss: 0.8640 - val_acc: 0.7180\n",
            "Epoch 78/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.0910 - acc: 0.5871 - val_loss: 0.8601 - val_acc: 0.7120\n",
            "Epoch 79/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.0869 - acc: 0.5829 - val_loss: 0.8529 - val_acc: 0.7130\n",
            "Epoch 80/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.0809 - acc: 0.5951 - val_loss: 0.8480 - val_acc: 0.7150\n",
            "Epoch 81/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.0756 - acc: 0.5947 - val_loss: 0.8436 - val_acc: 0.7210\n",
            "Epoch 82/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.0711 - acc: 0.5925 - val_loss: 0.8382 - val_acc: 0.7160\n",
            "Epoch 83/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.0637 - acc: 0.5971 - val_loss: 0.8352 - val_acc: 0.7190\n",
            "Epoch 84/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.0621 - acc: 0.5980 - val_loss: 0.8306 - val_acc: 0.7150\n",
            "Epoch 85/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.0767 - acc: 0.6039 - val_loss: 0.8303 - val_acc: 0.7180\n",
            "Epoch 86/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.0473 - acc: 0.6045 - val_loss: 0.8240 - val_acc: 0.7170\n",
            "Epoch 87/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.0479 - acc: 0.6005 - val_loss: 0.8198 - val_acc: 0.7190\n",
            "Epoch 88/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.0490 - acc: 0.6012 - val_loss: 0.8145 - val_acc: 0.7160\n",
            "Epoch 89/150\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 1.0474 - acc: 0.6033 - val_loss: 0.8137 - val_acc: 0.7200\n",
            "Epoch 90/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.0235 - acc: 0.6160 - val_loss: 0.8095 - val_acc: 0.7220\n",
            "Epoch 91/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.0234 - acc: 0.6107 - val_loss: 0.8037 - val_acc: 0.7210\n",
            "Epoch 92/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.0282 - acc: 0.6193 - val_loss: 0.8003 - val_acc: 0.7220\n",
            "Epoch 93/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.0196 - acc: 0.6200 - val_loss: 0.7950 - val_acc: 0.7200\n",
            "Epoch 94/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.0237 - acc: 0.6133 - val_loss: 0.7940 - val_acc: 0.7230\n",
            "Epoch 95/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.0228 - acc: 0.6055 - val_loss: 0.7922 - val_acc: 0.7220\n",
            "Epoch 96/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.0088 - acc: 0.6195 - val_loss: 0.7892 - val_acc: 0.7240\n",
            "Epoch 97/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 1.0131 - acc: 0.6180 - val_loss: 0.7867 - val_acc: 0.7210\n",
            "Epoch 98/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 1.0111 - acc: 0.6191 - val_loss: 0.7847 - val_acc: 0.7230\n",
            "Epoch 99/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 1.0079 - acc: 0.6169 - val_loss: 0.7816 - val_acc: 0.7250\n",
            "Epoch 100/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.9926 - acc: 0.6239 - val_loss: 0.7793 - val_acc: 0.7240\n",
            "Epoch 101/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.9922 - acc: 0.6269 - val_loss: 0.7758 - val_acc: 0.7180\n",
            "Epoch 102/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.9796 - acc: 0.6312 - val_loss: 0.7735 - val_acc: 0.7230\n",
            "Epoch 103/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.9939 - acc: 0.6279 - val_loss: 0.7699 - val_acc: 0.7230\n",
            "Epoch 104/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.9891 - acc: 0.6301 - val_loss: 0.7663 - val_acc: 0.7250\n",
            "Epoch 105/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9931 - acc: 0.6265 - val_loss: 0.7661 - val_acc: 0.7250\n",
            "Epoch 106/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9820 - acc: 0.6299 - val_loss: 0.7650 - val_acc: 0.7260\n",
            "Epoch 107/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.9775 - acc: 0.6356 - val_loss: 0.7634 - val_acc: 0.7260\n",
            "Epoch 108/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.9784 - acc: 0.6280 - val_loss: 0.7619 - val_acc: 0.7240\n",
            "Epoch 109/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.9741 - acc: 0.6287 - val_loss: 0.7604 - val_acc: 0.7220\n",
            "Epoch 110/150\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.9655 - acc: 0.6369 - val_loss: 0.7556 - val_acc: 0.7290\n",
            "Epoch 111/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9673 - acc: 0.6369 - val_loss: 0.7526 - val_acc: 0.7240\n",
            "Epoch 112/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9643 - acc: 0.6407 - val_loss: 0.7500 - val_acc: 0.7260\n",
            "Epoch 113/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9669 - acc: 0.6369 - val_loss: 0.7460 - val_acc: 0.7290\n",
            "Epoch 114/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.9500 - acc: 0.6425 - val_loss: 0.7446 - val_acc: 0.7210\n",
            "Epoch 115/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.9489 - acc: 0.6417 - val_loss: 0.7391 - val_acc: 0.7300\n",
            "Epoch 116/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.9512 - acc: 0.6448 - val_loss: 0.7394 - val_acc: 0.7270\n",
            "Epoch 117/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9570 - acc: 0.6363 - val_loss: 0.7405 - val_acc: 0.7260\n",
            "Epoch 118/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9455 - acc: 0.6465 - val_loss: 0.7387 - val_acc: 0.7280\n",
            "Epoch 119/150\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.9521 - acc: 0.6451 - val_loss: 0.7367 - val_acc: 0.7330\n",
            "Epoch 120/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9437 - acc: 0.6444 - val_loss: 0.7340 - val_acc: 0.7270\n",
            "Epoch 121/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9449 - acc: 0.6440 - val_loss: 0.7335 - val_acc: 0.7260\n",
            "Epoch 122/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9308 - acc: 0.6523 - val_loss: 0.7292 - val_acc: 0.7320\n",
            "Epoch 123/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9235 - acc: 0.6529 - val_loss: 0.7268 - val_acc: 0.7280\n",
            "Epoch 124/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9303 - acc: 0.6577 - val_loss: 0.7259 - val_acc: 0.7330\n",
            "Epoch 125/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.9332 - acc: 0.6515 - val_loss: 0.7223 - val_acc: 0.7320\n",
            "Epoch 126/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9169 - acc: 0.6580 - val_loss: 0.7196 - val_acc: 0.7320\n",
            "Epoch 127/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9255 - acc: 0.6596 - val_loss: 0.7196 - val_acc: 0.7310\n",
            "Epoch 128/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9082 - acc: 0.6619 - val_loss: 0.7147 - val_acc: 0.7320\n",
            "Epoch 129/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9016 - acc: 0.6620 - val_loss: 0.7105 - val_acc: 0.7300\n",
            "Epoch 130/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9179 - acc: 0.6557 - val_loss: 0.7115 - val_acc: 0.7300\n",
            "Epoch 131/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9168 - acc: 0.6623 - val_loss: 0.7118 - val_acc: 0.7360\n",
            "Epoch 132/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9100 - acc: 0.6613 - val_loss: 0.7130 - val_acc: 0.7350\n",
            "Epoch 133/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9108 - acc: 0.6563 - val_loss: 0.7075 - val_acc: 0.7320\n",
            "Epoch 134/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.9063 - acc: 0.6701 - val_loss: 0.7096 - val_acc: 0.7310\n",
            "Epoch 135/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.8975 - acc: 0.6609 - val_loss: 0.7054 - val_acc: 0.7340\n",
            "Epoch 136/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.8939 - acc: 0.6644 - val_loss: 0.7062 - val_acc: 0.7330\n",
            "Epoch 137/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.8830 - acc: 0.6737 - val_loss: 0.7000 - val_acc: 0.7340\n",
            "Epoch 138/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.8939 - acc: 0.6640 - val_loss: 0.7019 - val_acc: 0.7330\n",
            "Epoch 139/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.8914 - acc: 0.6633 - val_loss: 0.6997 - val_acc: 0.7300\n",
            "Epoch 140/150\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.8828 - acc: 0.6729 - val_loss: 0.6999 - val_acc: 0.7330\n",
            "Epoch 141/150\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.8914 - acc: 0.6624 - val_loss: 0.6966 - val_acc: 0.7360\n",
            "Epoch 142/150\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.8677 - acc: 0.6803 - val_loss: 0.6955 - val_acc: 0.7310\n",
            "Epoch 143/150\n",
            "30/30 [==============================] - 1s 39ms/step - loss: 0.8717 - acc: 0.6696 - val_loss: 0.6936 - val_acc: 0.7350\n",
            "Epoch 144/150\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.8847 - acc: 0.6668 - val_loss: 0.6934 - val_acc: 0.7350\n",
            "Epoch 145/150\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 0.8771 - acc: 0.6677 - val_loss: 0.6917 - val_acc: 0.7360\n",
            "Epoch 146/150\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.8750 - acc: 0.6751 - val_loss: 0.6900 - val_acc: 0.7360\n",
            "Epoch 147/150\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 0.8769 - acc: 0.6681 - val_loss: 0.6890 - val_acc: 0.7350\n",
            "Epoch 148/150\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.8741 - acc: 0.6731 - val_loss: 0.6890 - val_acc: 0.7310\n",
            "Epoch 149/150\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.8635 - acc: 0.6739 - val_loss: 0.6867 - val_acc: 0.7340\n",
            "Epoch 150/150\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.8709 - acc: 0.6767 - val_loss: 0.6858 - val_acc: 0.7370\n"
          ]
        }
      ],
      "source": [
        "# ⏰ This cell may take about a minute to run\n",
        "random.seed(123)\n",
        "dropout_model = models.Sequential()\n",
        "\n",
        "# Implement dropout to the input layer\n",
        "# NOTE: This is where you define the number of units in the input layer\n",
        "dropout_model.add(layers.Dropout(0.3, input_shape=(2000,)))\n",
        "\n",
        "# Add the first hidden layer\n",
        "dropout_model.add(layers.Dense(50,activation='relu'))\n",
        "\n",
        "# Implement dropout to the first hidden layer \n",
        "dropout_model.add(layers.Dropout(.3))\n",
        "\n",
        "# Add the second hidden layer\n",
        "dropout_model.add(layers.Dense(25,activation='relu'))\n",
        "\n",
        "# Implement dropout to the second hidden layer \n",
        "dropout_model.add(layers.Dropout(.3))\n",
        "\n",
        "# Add the output layer\n",
        "dropout_model.add(layers.Dense(7, activation='softmax'))\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "dropout_model.compile(optimizer='SGD', \n",
        "                      loss='categorical_crossentropy', \n",
        "                      metrics=['acc'])\n",
        "\n",
        "# Train the model\n",
        "dropout_model_val = dropout_model.fit(X_train_tokens, \n",
        "                                      y_train_lb, \n",
        "                                      epochs=150, \n",
        "                                      batch_size=256, \n",
        "                                      validation_data=(X_val_tokens, y_val_lb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX5Ur6Ju6z6v",
        "outputId": "fc579e22-a991-4ad4-f4d2-5c5b463908dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235/235 [==============================] - 1s 6ms/step - loss: 0.5720 - acc: 0.7988\n",
            "Training Loss: 0.572 \n",
            "Training Accuracy: 0.799\n",
            "----------\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.6351 - acc: 0.7767\n",
            "Test Loss: 0.635 \n",
            "Test Accuracy: 0.777\n"
          ]
        }
      ],
      "source": [
        "results_train = dropout_model.evaluate(X_train_tokens, y_train_lb)\n",
        "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
        "\n",
        "print('----------')\n",
        "\n",
        "results_test = dropout_model.evaluate(X_test_tokens, y_test_lb)\n",
        "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZXkjdY56z6v"
      },
      "source": [
        "You can see here that the validation performance has improved again, and the training and test accuracy are very close!  \n",
        "\n",
        "## Bigger Data? \n",
        "\n",
        "Finally, let's examine if we can improve the model's performance just by adding more data. We've quadrapled the sample dataset from 10,000 to 40,000 observations, and all you need to do is run the code! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "KLRcQWGV6z6v"
      },
      "outputs": [],
      "source": [
        "df_bigger_sample = df.sample(40000, random_state=123)\n",
        "\n",
        "X = df['Consumer complaint narrative']\n",
        "y = df['Product']\n",
        "\n",
        "# Train-test split\n",
        "X_train_bigger, X_test_bigger, y_train_bigger, y_test_bigger = train_test_split(X, \n",
        "                                                                                y, \n",
        "                                                                                test_size=6000, \n",
        "                                                                                random_state=42)\n",
        "\n",
        "# Validation set\n",
        "X_train_final_bigger, X_val_bigger, y_train_final_bigger, y_val_bigger = train_test_split(X_train_bigger, \n",
        "                                                                                          y_train_bigger, \n",
        "                                                                                          test_size=4000, \n",
        "                                                                                          random_state=42)\n",
        "\n",
        "\n",
        "# One-hot encoding of the complaints\n",
        "tokenizer = Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(X_train_final_bigger)\n",
        "\n",
        "X_train_tokens_bigger = tokenizer.texts_to_matrix(X_train_final_bigger, mode='binary')\n",
        "X_val_tokens_bigger = tokenizer.texts_to_matrix(X_val_bigger, mode='binary')\n",
        "X_test_tokens_bigger = tokenizer.texts_to_matrix(X_test_bigger, mode='binary')\n",
        "\n",
        "# One-hot encoding of products\n",
        "lb = LabelBinarizer()\n",
        "lb.fit(y_train_final_bigger)\n",
        "\n",
        "y_train_lb_bigger = to_categorical(lb.transform(y_train_final_bigger))[:, :, 1]\n",
        "y_val_lb_bigger = to_categorical(lb.transform(y_val_bigger))[:, :, 1]\n",
        "y_test_lb_bigger = to_categorical(lb.transform(y_test_bigger))[:, :, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgOhN47U6z6v",
        "outputId": "cb0592cb-0d84-42ec-80db-8fa0cab1dfb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 1.9109 - acc: 0.1966 - val_loss: 1.8547 - val_acc: 0.2797\n",
            "Epoch 2/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.7438 - acc: 0.3852 - val_loss: 1.6164 - val_acc: 0.4875\n",
            "Epoch 3/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.4506 - acc: 0.5521 - val_loss: 1.2991 - val_acc: 0.6102\n",
            "Epoch 4/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.1555 - acc: 0.6477 - val_loss: 1.0522 - val_acc: 0.6685\n",
            "Epoch 5/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.9574 - acc: 0.6935 - val_loss: 0.9065 - val_acc: 0.6990\n",
            "Epoch 6/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.8386 - acc: 0.7181 - val_loss: 0.8185 - val_acc: 0.7128\n",
            "Epoch 7/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.7638 - acc: 0.7364 - val_loss: 0.7629 - val_acc: 0.7253\n",
            "Epoch 8/150\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.7135 - acc: 0.7489 - val_loss: 0.7232 - val_acc: 0.7362\n",
            "Epoch 9/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.6770 - acc: 0.7598 - val_loss: 0.6949 - val_acc: 0.7527\n",
            "Epoch 10/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.6493 - acc: 0.7669 - val_loss: 0.6733 - val_acc: 0.7590\n",
            "Epoch 11/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.6269 - acc: 0.7733 - val_loss: 0.6560 - val_acc: 0.7617\n",
            "Epoch 12/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.6085 - acc: 0.7802 - val_loss: 0.6418 - val_acc: 0.7678\n",
            "Epoch 13/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.5931 - acc: 0.7857 - val_loss: 0.6316 - val_acc: 0.7778\n",
            "Epoch 14/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.5798 - acc: 0.7905 - val_loss: 0.6199 - val_acc: 0.7760\n",
            "Epoch 15/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.5678 - acc: 0.7948 - val_loss: 0.6119 - val_acc: 0.7768\n",
            "Epoch 16/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.5573 - acc: 0.7988 - val_loss: 0.6054 - val_acc: 0.7815\n",
            "Epoch 17/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.5479 - acc: 0.8015 - val_loss: 0.6005 - val_acc: 0.7862\n",
            "Epoch 18/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.5393 - acc: 0.8063 - val_loss: 0.5950 - val_acc: 0.7880\n",
            "Epoch 19/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.5313 - acc: 0.8082 - val_loss: 0.5896 - val_acc: 0.7850\n",
            "Epoch 20/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.5239 - acc: 0.8120 - val_loss: 0.5843 - val_acc: 0.7905\n",
            "Epoch 21/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.5171 - acc: 0.8140 - val_loss: 0.5793 - val_acc: 0.7935\n",
            "Epoch 22/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.5105 - acc: 0.8175 - val_loss: 0.5758 - val_acc: 0.7922\n",
            "Epoch 23/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.5043 - acc: 0.8202 - val_loss: 0.5722 - val_acc: 0.7962\n",
            "Epoch 24/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.4991 - acc: 0.8216 - val_loss: 0.5706 - val_acc: 0.7962\n",
            "Epoch 25/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4933 - acc: 0.8243 - val_loss: 0.5665 - val_acc: 0.7980\n",
            "Epoch 26/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.4884 - acc: 0.8254 - val_loss: 0.5640 - val_acc: 0.8008\n",
            "Epoch 27/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.4838 - acc: 0.8277 - val_loss: 0.5614 - val_acc: 0.8012\n",
            "Epoch 28/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.4789 - acc: 0.8297 - val_loss: 0.5606 - val_acc: 0.8043\n",
            "Epoch 29/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4747 - acc: 0.8313 - val_loss: 0.5570 - val_acc: 0.8025\n",
            "Epoch 30/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4701 - acc: 0.8323 - val_loss: 0.5578 - val_acc: 0.8060\n",
            "Epoch 31/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.4663 - acc: 0.8345 - val_loss: 0.5542 - val_acc: 0.8058\n",
            "Epoch 32/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.4626 - acc: 0.8359 - val_loss: 0.5523 - val_acc: 0.8060\n",
            "Epoch 33/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.4589 - acc: 0.8373 - val_loss: 0.5555 - val_acc: 0.8045\n",
            "Epoch 34/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4554 - acc: 0.8381 - val_loss: 0.5517 - val_acc: 0.8065\n",
            "Epoch 35/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4521 - acc: 0.8399 - val_loss: 0.5485 - val_acc: 0.8083\n",
            "Epoch 36/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4489 - acc: 0.8409 - val_loss: 0.5487 - val_acc: 0.8090\n",
            "Epoch 37/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4455 - acc: 0.8426 - val_loss: 0.5492 - val_acc: 0.8080\n",
            "Epoch 38/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.4427 - acc: 0.8439 - val_loss: 0.5489 - val_acc: 0.8065\n",
            "Epoch 39/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4399 - acc: 0.8447 - val_loss: 0.5487 - val_acc: 0.8108\n",
            "Epoch 40/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4368 - acc: 0.8460 - val_loss: 0.5463 - val_acc: 0.8100\n",
            "Epoch 41/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4343 - acc: 0.8471 - val_loss: 0.5447 - val_acc: 0.8095\n",
            "Epoch 42/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.4313 - acc: 0.8485 - val_loss: 0.5467 - val_acc: 0.8135\n",
            "Epoch 43/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.4291 - acc: 0.8492 - val_loss: 0.5419 - val_acc: 0.8102\n",
            "Epoch 44/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4265 - acc: 0.8499 - val_loss: 0.5437 - val_acc: 0.8095\n",
            "Epoch 45/150\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.4241 - acc: 0.8508 - val_loss: 0.5417 - val_acc: 0.8110\n",
            "Epoch 46/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4220 - acc: 0.8516 - val_loss: 0.5411 - val_acc: 0.8102\n",
            "Epoch 47/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4196 - acc: 0.8526 - val_loss: 0.5416 - val_acc: 0.8110\n",
            "Epoch 48/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4172 - acc: 0.8533 - val_loss: 0.5438 - val_acc: 0.8148\n",
            "Epoch 49/150\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.4150 - acc: 0.8549 - val_loss: 0.5406 - val_acc: 0.8100\n",
            "Epoch 50/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4130 - acc: 0.8549 - val_loss: 0.5420 - val_acc: 0.8112\n",
            "Epoch 51/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.4112 - acc: 0.8557 - val_loss: 0.5408 - val_acc: 0.8152\n",
            "Epoch 52/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4090 - acc: 0.8566 - val_loss: 0.5401 - val_acc: 0.8125\n",
            "Epoch 53/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.4069 - acc: 0.8576 - val_loss: 0.5433 - val_acc: 0.8080\n",
            "Epoch 54/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.4052 - acc: 0.8582 - val_loss: 0.5410 - val_acc: 0.8140\n",
            "Epoch 55/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.4029 - acc: 0.8587 - val_loss: 0.5431 - val_acc: 0.8095\n",
            "Epoch 56/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.4013 - acc: 0.8601 - val_loss: 0.5409 - val_acc: 0.8155\n",
            "Epoch 57/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3992 - acc: 0.8595 - val_loss: 0.5443 - val_acc: 0.8123\n",
            "Epoch 58/150\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.3976 - acc: 0.8605 - val_loss: 0.5405 - val_acc: 0.8123\n",
            "Epoch 59/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3959 - acc: 0.8605 - val_loss: 0.5420 - val_acc: 0.8098\n",
            "Epoch 60/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3941 - acc: 0.8626 - val_loss: 0.5415 - val_acc: 0.8145\n",
            "Epoch 61/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3925 - acc: 0.8624 - val_loss: 0.5415 - val_acc: 0.8117\n",
            "Epoch 62/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3911 - acc: 0.8628 - val_loss: 0.5412 - val_acc: 0.8105\n",
            "Epoch 63/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.3895 - acc: 0.8626 - val_loss: 0.5410 - val_acc: 0.8100\n",
            "Epoch 64/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.3879 - acc: 0.8640 - val_loss: 0.5468 - val_acc: 0.8120\n",
            "Epoch 65/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3864 - acc: 0.8638 - val_loss: 0.5432 - val_acc: 0.8142\n",
            "Epoch 66/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3845 - acc: 0.8656 - val_loss: 0.5454 - val_acc: 0.8117\n",
            "Epoch 67/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3830 - acc: 0.8661 - val_loss: 0.5433 - val_acc: 0.8140\n",
            "Epoch 68/150\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.3819 - acc: 0.8657 - val_loss: 0.5426 - val_acc: 0.8090\n",
            "Epoch 69/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3803 - acc: 0.8668 - val_loss: 0.5497 - val_acc: 0.8092\n",
            "Epoch 70/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3789 - acc: 0.8677 - val_loss: 0.5459 - val_acc: 0.8120\n",
            "Epoch 71/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3779 - acc: 0.8674 - val_loss: 0.5496 - val_acc: 0.8133\n",
            "Epoch 72/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3763 - acc: 0.8681 - val_loss: 0.5468 - val_acc: 0.8100\n",
            "Epoch 73/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.3746 - acc: 0.8696 - val_loss: 0.5446 - val_acc: 0.8135\n",
            "Epoch 74/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.3737 - acc: 0.8689 - val_loss: 0.5447 - val_acc: 0.8120\n",
            "Epoch 75/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.3723 - acc: 0.8693 - val_loss: 0.5457 - val_acc: 0.8150\n",
            "Epoch 76/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.3713 - acc: 0.8706 - val_loss: 0.5461 - val_acc: 0.8108\n",
            "Epoch 77/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3699 - acc: 0.8713 - val_loss: 0.5456 - val_acc: 0.8125\n",
            "Epoch 78/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3684 - acc: 0.8709 - val_loss: 0.5493 - val_acc: 0.8150\n",
            "Epoch 79/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3671 - acc: 0.8725 - val_loss: 0.5484 - val_acc: 0.8125\n",
            "Epoch 80/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3663 - acc: 0.8720 - val_loss: 0.5496 - val_acc: 0.8127\n",
            "Epoch 81/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3649 - acc: 0.8726 - val_loss: 0.5501 - val_acc: 0.8117\n",
            "Epoch 82/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3640 - acc: 0.8716 - val_loss: 0.5513 - val_acc: 0.8142\n",
            "Epoch 83/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3624 - acc: 0.8739 - val_loss: 0.5507 - val_acc: 0.8117\n",
            "Epoch 84/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3612 - acc: 0.8737 - val_loss: 0.5518 - val_acc: 0.8120\n",
            "Epoch 85/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3605 - acc: 0.8730 - val_loss: 0.5525 - val_acc: 0.8125\n",
            "Epoch 86/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3591 - acc: 0.8739 - val_loss: 0.5539 - val_acc: 0.8115\n",
            "Epoch 87/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3583 - acc: 0.8738 - val_loss: 0.5522 - val_acc: 0.8115\n",
            "Epoch 88/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3569 - acc: 0.8742 - val_loss: 0.5537 - val_acc: 0.8080\n",
            "Epoch 89/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3562 - acc: 0.8750 - val_loss: 0.5532 - val_acc: 0.8083\n",
            "Epoch 90/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3548 - acc: 0.8750 - val_loss: 0.5548 - val_acc: 0.8083\n",
            "Epoch 91/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3534 - acc: 0.8753 - val_loss: 0.5512 - val_acc: 0.8090\n",
            "Epoch 92/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3527 - acc: 0.8770 - val_loss: 0.5570 - val_acc: 0.8080\n",
            "Epoch 93/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3515 - acc: 0.8764 - val_loss: 0.5532 - val_acc: 0.8102\n",
            "Epoch 94/150\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.3507 - acc: 0.8770 - val_loss: 0.5547 - val_acc: 0.8115\n",
            "Epoch 95/150\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.3499 - acc: 0.8770 - val_loss: 0.5575 - val_acc: 0.8080\n",
            "Epoch 96/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3483 - acc: 0.8778 - val_loss: 0.5543 - val_acc: 0.8087\n",
            "Epoch 97/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3475 - acc: 0.8781 - val_loss: 0.5554 - val_acc: 0.8095\n",
            "Epoch 98/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3469 - acc: 0.8777 - val_loss: 0.5626 - val_acc: 0.8067\n",
            "Epoch 99/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3456 - acc: 0.8790 - val_loss: 0.5825 - val_acc: 0.7922\n",
            "Epoch 100/150\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.3447 - acc: 0.8785 - val_loss: 0.5564 - val_acc: 0.8090\n",
            "Epoch 101/150\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.3438 - acc: 0.8799 - val_loss: 0.5576 - val_acc: 0.8092\n",
            "Epoch 102/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3428 - acc: 0.8792 - val_loss: 0.5619 - val_acc: 0.8140\n",
            "Epoch 103/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3420 - acc: 0.8800 - val_loss: 0.5598 - val_acc: 0.8067\n",
            "Epoch 104/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3410 - acc: 0.8801 - val_loss: 0.5600 - val_acc: 0.8095\n",
            "Epoch 105/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3397 - acc: 0.8804 - val_loss: 0.5591 - val_acc: 0.8062\n",
            "Epoch 106/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3390 - acc: 0.8807 - val_loss: 0.5591 - val_acc: 0.8087\n",
            "Epoch 107/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3377 - acc: 0.8816 - val_loss: 0.5614 - val_acc: 0.8085\n",
            "Epoch 108/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3370 - acc: 0.8822 - val_loss: 0.5614 - val_acc: 0.8130\n",
            "Epoch 109/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3361 - acc: 0.8821 - val_loss: 0.5646 - val_acc: 0.8152\n",
            "Epoch 110/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.3354 - acc: 0.8822 - val_loss: 0.5646 - val_acc: 0.8073\n",
            "Epoch 111/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3343 - acc: 0.8824 - val_loss: 0.5622 - val_acc: 0.8095\n",
            "Epoch 112/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.3336 - acc: 0.8829 - val_loss: 0.5656 - val_acc: 0.8083\n",
            "Epoch 113/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3328 - acc: 0.8831 - val_loss: 0.5670 - val_acc: 0.8100\n",
            "Epoch 114/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3314 - acc: 0.8841 - val_loss: 0.5680 - val_acc: 0.8077\n",
            "Epoch 115/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3307 - acc: 0.8847 - val_loss: 0.5711 - val_acc: 0.8080\n",
            "Epoch 116/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3300 - acc: 0.8840 - val_loss: 0.5717 - val_acc: 0.8030\n",
            "Epoch 117/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3288 - acc: 0.8858 - val_loss: 0.5696 - val_acc: 0.8105\n",
            "Epoch 118/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3282 - acc: 0.8850 - val_loss: 0.5665 - val_acc: 0.8102\n",
            "Epoch 119/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3273 - acc: 0.8860 - val_loss: 0.5695 - val_acc: 0.8110\n",
            "Epoch 120/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3263 - acc: 0.8861 - val_loss: 0.5710 - val_acc: 0.8085\n",
            "Epoch 121/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3257 - acc: 0.8861 - val_loss: 0.5743 - val_acc: 0.8040\n",
            "Epoch 122/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3248 - acc: 0.8863 - val_loss: 0.5705 - val_acc: 0.8112\n",
            "Epoch 123/150\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.3238 - acc: 0.8865 - val_loss: 0.5783 - val_acc: 0.8080\n",
            "Epoch 124/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3230 - acc: 0.8870 - val_loss: 0.5765 - val_acc: 0.8075\n",
            "Epoch 125/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3227 - acc: 0.8874 - val_loss: 0.5717 - val_acc: 0.8075\n",
            "Epoch 126/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3214 - acc: 0.8871 - val_loss: 0.5704 - val_acc: 0.8100\n",
            "Epoch 127/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3201 - acc: 0.8886 - val_loss: 0.5748 - val_acc: 0.8058\n",
            "Epoch 128/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3195 - acc: 0.8887 - val_loss: 0.5743 - val_acc: 0.8095\n",
            "Epoch 129/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.3190 - acc: 0.8887 - val_loss: 0.5744 - val_acc: 0.8062\n",
            "Epoch 130/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3177 - acc: 0.8892 - val_loss: 0.5733 - val_acc: 0.8098\n",
            "Epoch 131/150\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.3170 - acc: 0.8890 - val_loss: 0.5757 - val_acc: 0.8083\n",
            "Epoch 132/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3161 - acc: 0.8901 - val_loss: 0.6047 - val_acc: 0.7925\n",
            "Epoch 133/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3155 - acc: 0.8906 - val_loss: 0.5792 - val_acc: 0.8060\n",
            "Epoch 134/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3144 - acc: 0.8899 - val_loss: 0.5758 - val_acc: 0.8108\n",
            "Epoch 135/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3137 - acc: 0.8913 - val_loss: 0.5838 - val_acc: 0.8077\n",
            "Epoch 136/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3130 - acc: 0.8905 - val_loss: 0.5798 - val_acc: 0.8065\n",
            "Epoch 137/150\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.3120 - acc: 0.8914 - val_loss: 0.5857 - val_acc: 0.8052\n",
            "Epoch 138/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3113 - acc: 0.8921 - val_loss: 0.5847 - val_acc: 0.8102\n",
            "Epoch 139/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3103 - acc: 0.8910 - val_loss: 0.5821 - val_acc: 0.8117\n",
            "Epoch 140/150\n",
            "196/196 [==============================] - 2s 9ms/step - loss: 0.3096 - acc: 0.8920 - val_loss: 0.5870 - val_acc: 0.8048\n",
            "Epoch 141/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.3085 - acc: 0.8927 - val_loss: 0.5973 - val_acc: 0.7990\n",
            "Epoch 142/150\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 0.3079 - acc: 0.8934 - val_loss: 0.5867 - val_acc: 0.8095\n",
            "Epoch 143/150\n",
            "196/196 [==============================] - 1s 7ms/step - loss: 0.3068 - acc: 0.8931 - val_loss: 0.5934 - val_acc: 0.8012\n",
            "Epoch 144/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3060 - acc: 0.8941 - val_loss: 0.5916 - val_acc: 0.8055\n",
            "Epoch 145/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3055 - acc: 0.8935 - val_loss: 0.5850 - val_acc: 0.8080\n",
            "Epoch 146/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3044 - acc: 0.8941 - val_loss: 0.5913 - val_acc: 0.8015\n",
            "Epoch 147/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3035 - acc: 0.8947 - val_loss: 0.5868 - val_acc: 0.8052\n",
            "Epoch 148/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3023 - acc: 0.8958 - val_loss: 0.6136 - val_acc: 0.7945\n",
            "Epoch 149/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3020 - acc: 0.8961 - val_loss: 0.5922 - val_acc: 0.8073\n",
            "Epoch 150/150\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 0.3011 - acc: 0.8967 - val_loss: 0.5947 - val_acc: 0.8120\n"
          ]
        }
      ],
      "source": [
        "# ⏰ This cell may take several minutes to run\n",
        "random.seed(123)\n",
        "bigger_data_model = models.Sequential()\n",
        "bigger_data_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
        "bigger_data_model.add(layers.Dense(25, activation='relu'))\n",
        "bigger_data_model.add(layers.Dense(7, activation='softmax'))\n",
        "\n",
        "bigger_data_model.compile(optimizer='SGD', \n",
        "                          loss='categorical_crossentropy', \n",
        "                          metrics=['acc'])\n",
        "\n",
        "bigger_data_model_val = bigger_data_model.fit(X_train_tokens_bigger,  \n",
        "                                              y_train_lb_bigger,  \n",
        "                                              epochs=150,  \n",
        "                                              batch_size=256,  \n",
        "                                              validation_data=(X_val_tokens_bigger, y_val_lb_bigger))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XquXH35S6z6v",
        "outputId": "29b99125-e513-4244-d4e0-b7876cfbc5b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3037 - acc: 0.8907\n",
            "Training Loss: 0.304 \n",
            "Training Accuracy: 0.891\n",
            "----------\n",
            "125/125 [==============================] - 1s 3ms/step - loss: 0.5947 - acc: 0.8120\n",
            "Test Loss: 0.595 \n",
            "Test Accuracy: 0.812\n"
          ]
        }
      ],
      "source": [
        "results_train = bigger_data_model.evaluate(X_train_tokens_bigger, y_train_lb_bigger)\n",
        "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
        "\n",
        "print('----------')\n",
        "\n",
        "results_test = bigger_data_model.evaluate(X_val_tokens_bigger, y_val_lb_bigger)\n",
        "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I7nbMZ26z6w"
      },
      "source": [
        "With the same amount of epochs and no regularization technique, you were able to get both better test accuracy and loss. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance! \n",
        "\n",
        "\n",
        "## Additional Resources\n",
        "\n",
        "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
        "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
        "* https://catalog.data.gov/dataset/consumer-complaint-database \n",
        "\n",
        "\n",
        "## Summary  \n",
        "\n",
        "In this lesson, you built deep learning models using a validation set and used several techniques such as L2 and L1 regularization, dropout regularization, and early stopping to improve the accuracy of your models. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "index.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}